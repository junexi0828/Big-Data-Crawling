"""
Scrapyì™€ Selenium í†µí•© ì˜ˆì œ

ì´ ì˜ˆì œëŠ” Seleniumì„ Scrapyì˜ Downloader Middlewareë¡œ í†µí•©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
ìŠ¬ë¼ì´ë“œì˜ "Modify ExchangeRateDownloaderMiddleware" ë‚´ìš©ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import scrapy
from scrapy import signals
from scrapy.http import HtmlResponse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time


class SeleniumDownloaderMiddleware:
    """
    Seleniumì„ ì‚¬ìš©í•˜ì—¬ ë™ì  ì½˜í…ì¸ ë¥¼ ë¡œë“œí•˜ëŠ” Downloader Middleware
    """
    
    def __init__(self):
        """ë¯¸ë“¤ì›¨ì–´ ì´ˆê¸°í™”"""
        self.driver = None
    
    @classmethod
    def from_crawler(cls, crawler):
        """
        Scrapy í¬ë¡¤ëŸ¬ì—ì„œ ë¯¸ë“¤ì›¨ì–´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        
        Args:
            crawler: Scrapy Crawler ì¸ìŠ¤í„´ìŠ¤
            
        Returns:
            SeleniumDownloaderMiddleware: ë¯¸ë“¤ì›¨ì–´ ì¸ìŠ¤í„´ìŠ¤
        """
        middleware = cls()
        crawler.signals.connect(middleware.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(middleware.spider_closed, signal=signals.spider_closed)
        return middleware
    
    def spider_opened(self, spider):
        """
        ìŠ¤íŒŒì´ë” ì‹œì‘ ì‹œ WebDriver ì´ˆê¸°í™”
        
        Args:
            spider: Scrapy Spider ì¸ìŠ¤í„´ìŠ¤
        """
        spider.logger.info("ğŸš€ Selenium WebDriver ì´ˆê¸°í™” ì¤‘...")
        
        chrome_options = Options()
        
        # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ì„ íƒì‚¬í•­)
        # chrome_options.add_argument('--headless')
        
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--window-size=1920,1080')
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.implicitly_wait(10)
        
        spider.logger.info("âœ… Selenium WebDriver ì´ˆê¸°í™” ì™„ë£Œ")
    
    def spider_closed(self, spider):
        """
        ìŠ¤íŒŒì´ë” ì¢…ë£Œ ì‹œ WebDriver ì •ë¦¬
        
        Args:
            spider: Scrapy Spider ì¸ìŠ¤í„´ìŠ¤
        """
        if self.driver:
            self.driver.quit()
            spider.logger.info("âœ… Selenium WebDriver ì¢…ë£Œ")
    
    def process_request(self, request, spider):
        """
        ìš”ì²­ ì²˜ë¦¬: Seleniumìœ¼ë¡œ í˜ì´ì§€ ë¡œë“œ
        
        Args:
            request: Scrapy Request ê°ì²´
            spider: Scrapy Spider ì¸ìŠ¤í„´ìŠ¤
            
        Returns:
            HtmlResponse: Seleniumìœ¼ë¡œ ë¡œë“œí•œ í˜ì´ì§€ì˜ ì‘ë‹µ
        """
        spider.logger.info(f"ğŸŒ Seleniumìœ¼ë¡œ í˜ì´ì§€ ë¡œë“œ: {request.url}")
        
        # Seleniumìœ¼ë¡œ í˜ì´ì§€ ë¡œë“œ
        self.driver.get(request.url)
        
        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
        time.sleep(2)
        
        # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
        body = self.driver.page_source
        
        # HtmlResponse ê°ì²´ ìƒì„±í•˜ì—¬ ë°˜í™˜
        return HtmlResponse(
            url=request.url,
            body=body,
            encoding='utf-8',
            request=request
        )


class NaverExchangeSpider(scrapy.Spider):
    """
    Selenium Middlewareë¥¼ ì‚¬ìš©í•˜ëŠ” Naver Finance ìŠ¤íŒŒì´ë”
    """
    
    name = 'n_exchange_with_middleware'
    allowed_domains = ['finance.naver.com']
    start_urls = ['https://finance.naver.com/marketindex/']
    
    custom_settings = {
        # Selenium Middleware í™œì„±í™”
        'DOWNLOADER_MIDDLEWARES': {
            '__main__.SeleniumDownloaderMiddleware': 543,
        },
        # ROBOTSTXT_OBEY ì„¤ì •
        'ROBOTSTXT_OBEY': False,
        # UTF-8 ì¸ì½”ë”© ì„¤ì •
        'FEED_EXPORT_ENCODING': 'utf-8',
    }
    
    def parse(self, response):
        """
        ë©”ì¸ í˜ì´ì§€ íŒŒì‹±
        
        Args:
            response: Scrapy Response ê°ì²´
            
        Yields:
            dict: í™˜ìœ¨ ì •ë³´
        """
        self.logger.info(f"{'='*60}")
        self.logger.info(f"[parse] ì‹œì‘: {response.url}")
        self.logger.info(f"{'='*60}")
        
        # í™˜ìœ¨ê³ ì‹œ ë‚ ì§œ ì¶”ì¶œ
        date = response.xpath("//div[@class='exchange_info']/span[1]/text()").get()
        self.logger.info(f"[parse] í™˜ìœ¨ê³ ì‹œ ë‚ ì§œ: {date}")
        
        # iframe URL ì¶”ì¶œ
        iframe_url = response.xpath('//iframe[@id="frame_ex1"]/@src').get()
        
        # ìƒëŒ€ URLì¸ ê²½ìš° ì ˆëŒ€ URLë¡œ ë³€í™˜
        if iframe_url and not iframe_url.startswith("http"):
            iframe_url = "https://finance.naver.com" + iframe_url
        
        self.logger.info(f"[parse] iframe URL: {iframe_url}")
        
        # iframe í˜ì´ì§€ë¡œ ìš”ì²­ ì „ì†¡ (metaë¡œ ë‚ ì§œ ì „ë‹¬)
        if iframe_url:
            yield scrapy.Request(
                url=iframe_url,
                callback=self.parse_iframe,
                meta={'date': date}
            )
    
    def parse_iframe(self, response):
        """
        iframe ë‚´ë¶€ ë°ì´í„° íŒŒì‹±
        
        Args:
            response: Scrapy Response ê°ì²´
            
        Yields:
            dict: í™˜ìœ¨ ì •ë³´
        """
        self.logger.info(f"{'='*60}")
        self.logger.info("[parse_iframe] ì‹œì‘")
        self.logger.info(f"{'='*60}")
        
        # metaì—ì„œ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        date = response.meta['date']
        
        # í…Œì´ë¸” í–‰ ì¶”ì¶œ
        rows = response.xpath("//html/body/div/table/tbody/tr")
        
        self.logger.info(f"[parse_iframe] ì°¾ì€ í…Œì´ë¸” í–‰ ê°œìˆ˜: {len(rows)}")
        
        # ê° í–‰ì—ì„œ ë°ì´í„° ì¶”ì¶œ
        item = {"date": date}
        
        for i, row in enumerate(rows):
            # êµ­ê°€/í†µí™”ëª… ì¶”ì¶œ
            title = row.xpath(".//td[@class='tit']/a/text()").get()
            
            # í™˜ìœ¨ (ë§¤ë§¤ê¸°ì¤€ìœ¨) ì¶”ì¶œ
            rate = row.xpath(".//td[@class='sale']/text()").get()
            
            if title and rate:
                title = title.strip()
                rate = rate.strip()
                item[title] = rate
                self.logger.info(f"  {i+1}. {title}: {rate}")
        
        self.logger.info(f"âœ… [parse_iframe] ì™„ë£Œ: {len(item)-1}ê°œ í™˜ìœ¨ ì •ë³´ ìˆ˜ì§‘")
        
        yield item


def run_spider():
    """
    ìŠ¤íŒŒì´ë”ë¥¼ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰
    """
    from scrapy.crawler import CrawlerProcess
    from scrapy.utils.project import get_project_settings
    
    print("\n" + "=" * 60)
    print("ğŸš€ Selenium Middlewareë¥¼ ì‚¬ìš©í•œ Naver Finance ìŠ¤í¬ë˜í•‘")
    print("=" * 60)
    
    # Scrapy ì„¤ì •
    settings = {
        'DOWNLOADER_MIDDLEWARES': {
            '__main__.SeleniumDownloaderMiddleware': 543,
        },
        'ROBOTSTXT_OBEY': False,
        'FEED_EXPORT_ENCODING': 'utf-8',
        'FEEDS': {
            'outputs/json/exchange_rates_middleware.json': {
                'format': 'json',
                'encoding': 'utf-8',
                'overwrite': True,
            }
        }
    }
    
    # CrawlerProcess ìƒì„± ë° ì‹¤í–‰
    process = CrawlerProcess(settings)
    process.crawl(NaverExchangeSpider)
    process.start()


if __name__ == "__main__":
    # ìŠ¤íŒŒì´ë” ì‹¤í–‰
    run_spider()

