#!/usr/bin/env python3
"""
response.follow() ë°©ì‹ ìƒì„¸ ì„¤ëª… ë° ì˜ˆì œ
"""


# 1. ê¸°ì¡´ ë°©ì‹ (Manual Request Creation)
def old_way_example(response):
    """ê¸°ì¡´ ë°©ì‹: ìˆ˜ë™ìœ¼ë¡œ Request ê°ì²´ ìƒì„±"""
    print("=== ê¸°ì¡´ ë°©ì‹ ===")

    # 1ë‹¨ê³„: href ì†ì„± ì¶”ì¶œ
    next_page = response.css("li.next a::attr(href)").get()
    print(f"1. href ì¶”ì¶œ: {next_page}")

    # 2ë‹¨ê³„: ìƒëŒ€ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ë³€í™˜
    if next_page is not None:
        full_url = response.urljoin(next_page)
        print(f"2. ì ˆëŒ€ê²½ë¡œ ë³€í™˜: {full_url}")

        # 3ë‹¨ê³„: Request ê°ì²´ ìˆ˜ë™ ìƒì„±
        request = scrapy.Request(full_url, callback=self.parse)
        print(f"3. Request ê°ì²´ ìƒì„±: {request}")

        yield request


# 2. ìƒˆë¡œìš´ ë°©ì‹ (response.follow())
def new_way_example(response):
    """ìƒˆë¡œìš´ ë°©ì‹: response.follow() ì‚¬ìš©"""
    print("=== ìƒˆë¡œìš´ ë°©ì‹ ===")

    # í•œ ë²ˆì— ì²˜ë¦¬!
    for a in response.css("ul.pager a"):
        print(f"ë§í¬ ìš”ì†Œ: {a.get()}")
        yield response.follow(a, callback=self.parse)
        print("âœ… response.follow()ê°€ ëª¨ë“  ê²ƒì„ ìë™ ì²˜ë¦¬!")


# 3. response.follow()ê°€ ìë™ìœ¼ë¡œ í•´ì£¼ëŠ” ì¼ë“¤
def what_follow_does():
    """response.follow()ì˜ ë‚´ë¶€ ë™ì‘"""

    print("\nğŸ¤– response.follow()ê°€ ìë™ìœ¼ë¡œ í•´ì£¼ëŠ” ì¼ë“¤:")
    print("1ï¸âƒ£ href ì†ì„± ìë™ ì¶”ì¶œ")
    print("2ï¸âƒ£ ìƒëŒ€ê²½ë¡œ â†’ ì ˆëŒ€ê²½ë¡œ ìë™ ë³€í™˜")
    print("3ï¸âƒ£ Request ê°ì²´ ìë™ ìƒì„±")
    print("4ï¸âƒ£ ì ì ˆí•œ HTTP í—¤ë” ìë™ ì„¤ì •")
    print("5ï¸âƒ£ ì¸ì½”ë”© ë¬¸ì œ ìë™ ì²˜ë¦¬")


# 4. ë‹¤ì–‘í•œ ì‚¬ìš© ë°©ë²•
def follow_usage_examples():
    """response.follow() ì‚¬ìš© ë°©ë²•ë“¤"""

    print("\nğŸ“š response.follow() ì‚¬ìš© ë°©ë²•ë“¤:")

    # ë°©ë²• 1: CSS ì…€ë ‰í„°ë¡œ ì§ì ‘ ì„ íƒ
    print("ë°©ë²• 1: CSS ì…€ë ‰í„° ì§ì ‘ ì‚¬ìš©")
    print("yield response.follow('li.next a', callback=self.parse)")

    # ë°©ë²• 2: ìš”ì†Œ ê°ì²´ ì „ë‹¬
    print("\në°©ë²• 2: ìš”ì†Œ ê°ì²´ ì „ë‹¬")
    print("link = response.css('li.next a').get()")
    print("yield response.follow(link, callback=self.parse)")

    # ë°©ë²• 3: ì—¬ëŸ¬ ë§í¬ ì¼ê´„ ì²˜ë¦¬
    print("\në°©ë²• 3: ì—¬ëŸ¬ ë§í¬ ì¼ê´„ ì²˜ë¦¬")
    print("for link in response.css('ul.pager a'):")
    print("    yield response.follow(link, callback=self.parse)")

    # ë°©ë²• 4: URL ë¬¸ìì—´ ì§ì ‘ ì „ë‹¬
    print("\në°©ë²• 4: URL ë¬¸ìì—´ ì§ì ‘ ì „ë‹¬")
    print("yield response.follow('/page/2/', callback=self.parse)")


# 5. ì‹¤ì œ ë™ì‘ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜
def simulate_follow_process():
    """response.follow() ë™ì‘ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜"""

    print("\nğŸ”„ response.follow() ë™ì‘ ê³¼ì •:")

    # ê°€ìƒì˜ HTML ìš”ì†Œ
    html_element = '<a href="/page/2/">Next</a>'
    base_url = "http://quotes.toscrape.com/page/1/"

    print(f"ì…ë ¥: {html_element}")
    print(f"í˜„ì¬ í˜ì´ì§€: {base_url}")

    print("\në‹¨ê³„ë³„ ì²˜ë¦¬:")
    print("1ï¸âƒ£ href ì¶”ì¶œ: '/page/2/'")
    print("2ï¸âƒ£ ì ˆëŒ€ê²½ë¡œ ë³€í™˜: 'http://quotes.toscrape.com/page/2/'")
    print("3ï¸âƒ£ Request ìƒì„±: GET http://quotes.toscrape.com/page/2/")
    print("4ï¸âƒ£ ì½œë°± í•¨ìˆ˜ ì—°ê²°: callback=self.parse")
    print("5ï¸âƒ£ ìŠ¤ì¼€ì¤„ëŸ¬ì— ë“±ë¡: í¬ë¡¤ë§ ëŒ€ê¸°ì—´ì— ì¶”ê°€")


if __name__ == "__main__":
    print("ğŸš€ response.follow() ë°©ì‹ ì™„ì „ ë¶„ì„")
    print("=" * 50)

    what_follow_does()
    follow_usage_examples()
    simulate_follow_process()

    print("\nâœ¨ ê²°ë¡ :")
    print("response.follow()ëŠ” ë³µì¡í•œ ë§í¬ ì²˜ë¦¬ë¥¼ í•œ ì¤„ë¡œ ê°„ë‹¨í•˜ê²Œ!")
    print("ê°œë°œìëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
