#!/usr/bin/env python3
"""
USER-AGENT ì‚¬ìš©ë²• ì™„ì „ ë°ëª¨ - ì´ë¯¸ì§€ ìŠ¬ë¼ì´ë“œ êµ¬í˜„
- Some sites block crawlers with User-agent headers!
- Web-server simply ignores requests from a specific useragent
- Identify S/W agent that sends HTTP(S) request
"""
import subprocess
import os
import requests


def demo_useragent_blocking():
    """User-Agentë¡œ ì¸í•œ ì°¨ë‹¨ ë°ëª¨"""
    print("ğŸš« USER-AGENT usage - Some sites block crawlers with User-agent headers!")
    print("=" * 80)
    print("Web-server simply ignores requests from a specific useragent.")
    print()

    print("ğŸŒ ì´ë¯¸ì§€ì—ì„œ ë³´ì—¬ì¤€ ì‹œë‚˜ë¦¬ì˜¤:")
    print("â€¢ scrapy shell http://www.todayhumor.co.kr/")
    print("â€¢ ì„±ê³µì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥ (response = <200 http://www.todayhumor.co.kr/>)")
    print("â€¢ í•˜ì§€ë§Œ ì¼ë¶€ ì‚¬ì´íŠ¸ëŠ” íŠ¹ì • User-Agentë¥¼ ì°¨ë‹¨í•¨")
    print()


def demo_well_known_useragents():
    """ì˜ ì•Œë ¤ì§„ User-Agent ëª©ë¡"""
    print("ğŸŒ Several well-known useragents such as web browsers")
    print("=" * 60)

    useragents = [
        ("Mozilla/5.0 (Windows NT 6.2; WOW64)", "Old Windows"),
        ("AppleWebKit/537.36 (KHTML, like Gecko)", "WebKit ê¸°ë°˜"),
        ("Chrome/27.0.1453.93, Safari/537.36", "Chrome/Safari"),
    ]

    for ua, description in useragents:
        print(f"â€¢ {ua}")
        print(f"  â†’ {description}")
    print()


def demo_scrapy_useragent_change():
    """Scrapyì—ì„œ User-Agent ë³€ê²½ ë°©ë²•"""
    print('ğŸ”§ Change setting â† default: "Scrapy/VERSION (+https://scrapy.org)"')
    print("=" * 70)

    print("ğŸ“‹ ì´ë¯¸ì§€ì—ì„œ ë³´ì—¬ì¤€ ë°©ë²•ë“¤:")
    print()

    # 1. Command line ë°©ë²•
    print("1ï¸âƒ£ Command line ì˜µì…˜:")
    print('   scrapy shell http://www.todayhumor.co.kr/ -s USER_AGENT="Safari/537.36"')
    print()

    # 2. settings.py ë°©ë²•
    print("2ï¸âƒ£ settings.py íŒŒì¼ ìˆ˜ì •:")
    print(
        "   # Crawl responsibly by identifying yourself (and your website) on the user-agent"
    )
    print('   #USER_AGENT = "quotes (+http://www.yourdomain.com)"')
    print('   USER_AGENT = "Safari/537.36"  # Set to some proper values!')
    print()

    print('ğŸ’¡ ì´ë¯¸ì§€ì˜ ì£¼ìš” ë©”ì‹œì§€: "Set to some proper values!"')


def demo_practical_useragent_rotation():
    """ì‹¤ìš©ì ì¸ User-Agent íšŒì „ ë°ëª¨"""
    print("\nğŸ”„ ì‹¤ìš©ì ì¸ User-Agent íšŒì „ ê¸°ë²•")
    print("=" * 50)

    useragent_list = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0",
    ]

    print("ğŸ“± ë‹¤ì–‘í•œ User-Agent ëª©ë¡:")
    for i, ua in enumerate(useragent_list, 1):
        browser_type = (
            "Chrome" if "Chrome" in ua else "Firefox" if "Firefox" in ua else "ê¸°íƒ€"
        )
        os_type = "Windows" if "Windows" in ua else "Mac" if "Mac" in ua else "Linux"
        print(f"{i}. {browser_type} on {os_type}")
        print(f"   {ua[:60]}...")
    print()


def create_useragent_spider():
    """User-Agentë¥¼ ì‚¬ìš©í•˜ëŠ” ìŠ¤íŒŒì´ë” ìƒì„±"""
    print("ğŸ•·ï¸ User-Agent íšŒì „ ìŠ¤íŒŒì´ë” ì˜ˆì œ")
    print("=" * 50)

    spider_code = """
import scrapy
import random

class UserAgentSpider(scrapy.Spider):
    name = 'useragent_spider'

    # ë‹¤ì–‘í•œ User-Agent ëª©ë¡
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
    ]

    def start_requests(self):
        urls = ['http://quotes.toscrape.com']
        for url in urls:
            # ëœë¤í•œ User-Agent ì„ íƒ
            user_agent = random.choice(self.user_agents)
            yield scrapy.Request(
                url=url,
                headers={'User-Agent': user_agent},
                callback=self.parse,
                meta={'user_agent': user_agent}
            )

    def parse(self, response):
        used_ua = response.meta.get('user_agent', 'Unknown')
        self.logger.info(f"ì‚¬ìš©ëœ User-Agent: {used_ua}")

        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'user_agent_used': used_ua,
            }
"""

    print("ğŸ“„ User-Agent íšŒì „ ìŠ¤íŒŒì´ë” ì½”ë“œ:")
    print(spider_code)

    # íŒŒì¼ë¡œ ì €ì¥
    with open(
        "/Users/juns/bigdata/tutorial/tutorial/spiders/useragent_spider.py",
        "w",
        encoding="utf-8",
    ) as f:
        f.write(spider_code.strip())

    print("ğŸ’¾ íŒŒì¼ ì €ì¥: tutorial/tutorial/spiders/useragent_spider.py")


def demo_scrapy_shell_useragent():
    """Scrapy Shellì—ì„œ User-Agent í…ŒìŠ¤íŠ¸"""
    print("\nğŸš Scrapy Shellì—ì„œ User-Agent í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    print("ğŸ“‹ ì´ë¯¸ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì¬í˜„:")
    print("1ï¸âƒ£ ê¸°ë³¸ Scrapy User-Agentë¡œ ì ‘ì†:")
    print("   scrapy shell http://www.todayhumor.co.kr/")
    print("   â†’ response = <200 http://www.todayhumor.co.kr/>")
    print()

    print("2ï¸âƒ£ Safari User-Agentë¡œ ì ‘ì†:")
    print('   scrapy shell http://www.todayhumor.co.kr/ -s USER_AGENT="Safari/537.36"')
    print("   â†’ User-Agent í—¤ë”ê°€ ë³€ê²½ë˜ì–´ ì ‘ì†")
    print()

    print("3ï¸âƒ£ Chrome User-Agentë¡œ ì ‘ì†:")
    print(
        '   scrapy shell http://www.todayhumor.co.kr/ -s USER_AGENT="Chrome/91.0.4472.124"'
    )
    print("   â†’ ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ìœ„ì¥í•˜ì—¬ ì ‘ì†")
    print()

    print("ğŸ’¡ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´:")
    print("   cd /Users/juns/bigdata/tutorial")
    print('   scrapy shell "http://quotes.toscrape.com" -s USER_AGENT="Safari/537.36"')
    print("   ê·¸ í›„ response.request.headersë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!")


if __name__ == "__main__":
    print("ğŸ¯ USER-AGENT ì‚¬ìš©ë²• ì™„ì „ ë°ëª¨")
    print("=" * 80)
    print("Identify S/W agent that sends HTTP(S) request")
    print()

    # 1. User-Agent ì°¨ë‹¨ ë°ëª¨
    demo_useragent_blocking()

    # 2. ì˜ ì•Œë ¤ì§„ User-Agent ì†Œê°œ
    demo_well_known_useragents()

    # 3. Scrapyì—ì„œ User-Agent ë³€ê²½ ë°©ë²•
    demo_scrapy_useragent_change()

    # 4. ì‹¤ìš©ì ì¸ User-Agent íšŒì „
    demo_practical_useragent_rotation()

    # 5. User-Agent ìŠ¤íŒŒì´ë” ìƒì„±
    create_useragent_spider()

    # 6. Scrapy Shell í…ŒìŠ¤íŠ¸
    demo_scrapy_shell_useragent()

    print("\nâœ… USER-AGENT ë°ëª¨ ì™„ë£Œ!")
    print(
        "ì›¹ ì„œë²„ê°€ íŠ¹ì • User-Agentë¥¼ ì°¨ë‹¨í•˜ëŠ” ê²½ìš°, ë¸Œë¼ìš°ì €ë¡œ ìœ„ì¥í•˜ì—¬ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸŒ"
    )
