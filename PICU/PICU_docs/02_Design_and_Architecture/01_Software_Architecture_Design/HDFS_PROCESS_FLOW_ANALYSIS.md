# HDFS í”„ë¡œì„¸ìŠ¤ íë¦„ ë¶„ì„ ë° ë¬¸ì œì 

## í˜„ì¬ íë¦„ë„

```
_check_and_start_hdfs()
  â†“
1. HDFS ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ (_check_hdfs_running)
   â”œâ”€ ì‹¤í–‰ ì¤‘ â†’ return ì„±ê³µ
   â””â”€ ì‹¤í–‰ ì•ˆ ë¨ â†’ ê³„ì†
  â†“
2. í´ëŸ¬ìŠ¤í„° ì„¤ì • í™•ì¸ (_get_cluster_config)
  â†“
3. HADOOP_HOME ìë™ ê°ì§€
  â†“
4. ë©€í‹°ë…¸ë“œ/ë‹¨ì¼ ë…¸ë“œ ëª¨ë“œ ê²°ì •
   â”œâ”€ has_cluster_config == True
   â”‚   â”œâ”€ _setup_cluster_mode() ì„±ê³µ
   â”‚   â”‚   â””â”€ ssh_available = _test_ssh_connection("localhost")  # [ìˆ˜ì •] localhost SSH í™•ì¸ ì¶”ê°€
   â”‚   â””â”€ _setup_cluster_mode() ì‹¤íŒ¨
   â”‚       â”œâ”€ ì‚¬ìš©ì í™•ì¸ â†’ ë‹¨ì¼ ë…¸ë“œ ëª¨ë“œ
   â”‚       â”‚   â”œâ”€ _setup_single_node_mode()
   â”‚       â”‚   â””â”€ ssh_available = _test_ssh_connection("localhost")
   â”‚       â””â”€ ì‚¬ìš©ì ê±°ë¶€ â†’ return ì‹¤íŒ¨
   â””â”€ has_cluster_config == False
       â”œâ”€ _setup_single_node_mode()
       â””â”€ ssh_available = _test_ssh_connection("localhost")
  â†“
5. SSH ì‹¤íŒ¨ ì‹œ ë¡œì»¬ SSH ì„¤ì • ì‹œë„ (ëª¨ë“  ê²½ìš°ì— ì‹¤í–‰)
   â”œâ”€ _setup_local_ssh() ì„±ê³µ â†’ ssh_available ì¬í…ŒìŠ¤íŠ¸
   â””â”€ _setup_local_ssh() ì‹¤íŒ¨ â†’ ssh_available = False
  â†“
6. HDFS ì‹œì‘
   â”œâ”€ ssh_available == False
   â”‚   â””â”€ _start_hdfs_daemons_direct() â†’ return (ì—¬ê¸°ì„œ ì¢…ë£Œë˜ì–´ì•¼ í•¨)
   â””â”€ ssh_available == True
       â”œâ”€ subprocess.Popen(start-dfs.sh) â†’ process ë³€ìˆ˜ ìƒì„±
       â””â”€ í¬íŠ¸ í™•ì¸ ë¡œì§ ì‹¤í–‰ (else ë¸”ë¡ ì•ˆì—ì„œ process ë³€ìˆ˜ ì‚¬ìš©)  # [ìˆ˜ì • ì™„ë£Œ]
```

## ë°œê²¬ëœ ë¬¸ì œì 

### ğŸ”´ ì¹˜ëª…ì  ë²„ê·¸ 1: process ë³€ìˆ˜ ìŠ¤ì½”í”„ ì˜¤ë¥˜

**ìœ„ì¹˜**: 645-702ì¤„

**ë¬¸ì œ**:

```python
if not ssh_available:
    return self._start_hdfs_daemons_direct(...)  # ì—¬ê¸°ì„œ return
else:
    process = subprocess.Popen(...)  # process ë³€ìˆ˜ ìƒì„±

# [ë¬¸ì œ] ë“¤ì—¬ì“°ê¸°ê°€ ì˜ëª»ë˜ì–´ if-else ë¸”ë¡ ë°–ì— ìˆìŒ
for attempt in range(max_retries):
    if process.poll() is not None:  # âŒ processê°€ ì •ì˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ!
```

**ì˜í–¥**:

- `_start_hdfs_daemons_direct()`ê°€ í˜¸ì¶œë˜ë©´ `return`ìœ¼ë¡œ í•¨ìˆ˜ê°€ ì¢…ë£Œë˜ì–´ì•¼ í•˜ëŠ”ë°, ë§Œì•½ `return`ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•Šê±°ë‚˜ ì½”ë“œê°€ ìˆ˜ì •ë˜ë©´ `process` ë³€ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ `process.poll()`ì´ ì‹¤í–‰ë˜ì–´ `NameError` ë°œìƒ

### ğŸ”´ ì¹˜ëª…ì  ë²„ê·¸ 2: ì¤‘ë³µëœ í¬íŠ¸ í™•ì¸ ë¡œì§

**ìœ„ì¹˜**:

- `_check_and_start_hdfs()`: 661-702ì¤„
- `_start_hdfs_daemons_direct()`: 949-952ì¤„

**ë¬¸ì œ**:

- `_start_hdfs_daemons_direct()`ëŠ” ì´ë¯¸ ë‚´ë¶€ì—ì„œ í¬íŠ¸ í™•ì¸ì„ í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•¨
- ê·¸ëŸ°ë° `_check_and_start_hdfs()`ì—ì„œë„ í¬íŠ¸ í™•ì¸ ë¡œì§ì´ ìˆìŒ
- í•˜ì§€ë§Œ `return`ìœ¼ë¡œ ì¸í•´ ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ”ë°, ì½”ë“œ êµ¬ì¡°ìƒ í˜¼ë€ìŠ¤ëŸ¬ì›€

### ğŸŸ¡ ë¡œì§ ë¬¸ì œ 3: ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜

**ìœ„ì¹˜**: 661ì¤„ ì´í›„

**ë¬¸ì œ**:

- í¬íŠ¸ í™•ì¸ ë¡œì§(661-702ì¤„)ì´ `if-else` ë¸”ë¡ ë°–ì— ìˆì–´ì„œ í•­ìƒ ì‹¤í–‰ë˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì„
- í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” `if not ssh_available:` ë¸”ë¡ì—ì„œ `return`ë˜ë¯€ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
- ì½”ë“œ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± ì €í•˜

### ğŸŸ¡ ë¡œì§ ë¬¸ì œ 4: \_wait_for_hdfs_ports í˜¸ì¶œ ë°©ì‹ ë¶ˆì¼ì¹˜

**ìœ„ì¹˜**: 693-695ì¤„

**ë¬¸ì œ**:

```python
port_check_result = self._wait_for_hdfs_ports(
    namenode_ports, max_retries=1, retry_interval=0
)
```

- `max_retries=1, retry_interval=0`ìœ¼ë¡œ í˜¸ì¶œí•˜ë©´ ì‹¤ì œë¡œëŠ” í¬íŠ¸ í™•ì¸ì´ 1ë²ˆë§Œ ì´ë£¨ì–´ì§
- í•˜ì§€ë§Œ ìœ„ì˜ `for attempt in range(max_retries):` ë£¨í”„ì—ì„œ ì´ë¯¸ ì¬ì‹œë„í•˜ê³  ìˆìŒ
- ì¤‘ë³µëœ ì¬ì‹œë„ ë¡œì§

## ìˆ˜ì • ë°©ì•ˆ

### ìˆ˜ì • 1: ë“¤ì—¬ì“°ê¸° ìˆ˜ì • ë° process ë³€ìˆ˜ ìŠ¤ì½”í”„ ë³´ì¥

```python
if not ssh_available:
    # SSH ì—†ì´ ë°ëª¬ ì§ì ‘ ì‹œì‘ (ë‹¨ì¼ ë…¸ë“œ ëª¨ë“œ)
    logger.info("SSH ì—†ì´ HDFS ë°ëª¬ì„ ì§ì ‘ ì‹œì‘í•©ë‹ˆë‹¤...")
    return self._start_hdfs_daemons_direct(
        hadoop_home, hdfs_env, namenode_ports
    )
else:
    # SSHë¥¼ í†µí•œ ì¼ë°˜ ì‹œì‘ (í´ëŸ¬ìŠ¤í„° ëª¨ë“œ)
    logger.info("HDFS ì‹œì‘ ì¤‘...")
    process = subprocess.Popen(
        ["bash", str(start_dfs_script)],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        start_new_session=True,
        env=hdfs_env,
    )

    # HDFS ì‹œì‘ ëŒ€ê¸° ë° í¬íŠ¸ í™•ì¸ (ì¬ì‹œë„ ë¡œì§)
    import time
    max_retries = 15
    retry_interval = 2

    for attempt in range(max_retries):
        time.sleep(retry_interval)

        # í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if process.poll() is not None:
            # ... ì—ëŸ¬ ì²˜ë¦¬ ...
            break

        # í¬íŠ¸ í™•ì¸
        port_check_result = self._wait_for_hdfs_ports(
            namenode_ports, max_retries=1, retry_interval=0
        )
        if port_check_result.get("success"):
            return port_check_result

    return {
        "success": False,
        "error": f"HDFS ì‹œì‘ í›„ í¬íŠ¸ í™•ì¸ ì‹¤íŒ¨ (ìµœëŒ€ {max_retries * retry_interval}ì´ˆ ëŒ€ê¸°)",
    }
```

### ìˆ˜ì • 2: \_wait_for_hdfs_ports í˜¸ì¶œ ë°©ì‹ ê°œì„ 

`_wait_for_hdfs_ports`ë¥¼ í˜¸ì¶œí•  ë•Œ `max_retries=1`ì´ ì•„ë‹ˆë¼ ì‹¤ì œ ì¬ì‹œë„ ë¡œì§ì„ ì œê±°í•˜ê³  ì§ì ‘ í¬íŠ¸ í™•ì¸ë§Œ í•˜ë„ë¡ ìˆ˜ì •í•˜ê±°ë‚˜, ì•„ë‹ˆë©´ `_wait_for_hdfs_ports`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ í¬íŠ¸ í™•ì¸ ë¡œì§ì„ ì‘ì„±
