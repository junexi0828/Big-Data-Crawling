# 로그 관리 가이드

**작성일**: 2025-12-07
**상태**: ✅ 현재 구조 정리 완료

---

## 📋 개요

PICU 프로젝트의 로그 파일 구조, 위치, 관리 방법을 정리한 문서입니다.

---

## 📁 로그 디렉토리 구조

### 1. 통합 로그 디렉토리 (메인)

**경로**: `/PICU/cointicker/logs/`

**용도**: GUI 실행 시 모든 모듈의 통합 로그 저장소

**파일 목록**:

```
logs/
├── backend_api.log          # Backend API 로그
├── gui.log                  # GUI 애플리케이션 로그
├── hdfs_client.log          # HDFS Client 로그
├── hdfs_upload_manager.log  # HDFS Upload Manager 로그
├── kafka_client.log         # Kafka Client 로그 (loguru, 자동 회전)
├── kafka_consumer.log       # Kafka Consumer 로그
├── kafka_pipeline.log       # Kafka Pipeline 로그
├── kafka.log                # Process Monitor가 생성하는 Kafka 로그
├── pipelines.log            # Scrapy Pipelines 로그
└── spider.log               # Process Monitor가 생성하는 Spider 로그
```

**특징**:

- 모든 모듈이 `get_cointicker_root() / "logs"` 경로 사용
- 자동 디렉토리 생성 (`mkdir(parents=True, exist_ok=True)`)
- UTF-8 인코딩

### 2. 워커 노드 로그 디렉토리 (활성)

**경로**: `/PICU/cointicker/worker-nodes/cointicker/logs/`

**용도**: Scrapy 스파이더 실행 시 생성되는 로그

**파일 목록**:

```
worker-nodes/cointicker/logs/
└── scrapy.log               # Scrapy 스파이더 로그 (2.2MB, 최근 사용)
```

**설정 위치**: `worker-nodes/cointicker/settings.py`

```python
LOG_FILE = "logs/scrapy.log"  # 상대 경로
```

**특징**:

- Scrapy가 `worker-nodes/cointicker/` 디렉토리에서 실행될 때 생성
- 현재 활발히 사용 중 (최근 업데이트됨)

### 3. 레거시 로그 디렉토리 (미사용)

**경로**: `/PICU/cointicker/worker-nodes/logs/`

**용도**: 이전 구조에서 사용하던 로그 디렉토리

**파일 목록**:

```
worker-nodes/logs/
└── scrapy.log               # 레거시 로그 (253KB, 11월 28일 이후 미사용)
```

**상태**: ⚠️ **정리 가능** (더 이상 사용되지 않음)

---

## 🔍 로그 파일별 상세 정보

### 현재 생성되는 로그

| 로그 파일                 | 모듈                | 생성 위치                       | 상태                  |
| ------------------------- | ------------------- | ------------------------------- | --------------------- |
| `scrapy.log`              | Scrapy              | `worker-nodes/cointicker/logs/` | ✅ 활성               |
| `kafka_pipeline.log`      | Kafka Pipeline      | `cointicker/logs/`              | ✅ 활성               |
| `kafka_consumer.log`      | Kafka Consumer      | `cointicker/logs/`              | ✅ 활성               |
| `kafka_client.log`        | Kafka Client        | `cointicker/logs/`              | ✅ 활성 (loguru 회전) |
| `hdfs_client.log`         | HDFS Client         | `cointicker/logs/`              | ✅ 활성               |
| `hdfs_upload_manager.log` | HDFS Upload Manager | `cointicker/logs/`              | ✅ 활성               |
| `backend_api.log`         | Backend API         | `cointicker/logs/`              | ✅ 활성               |
| `gui.log`                 | GUI                 | `cointicker/logs/`              | ✅ 활성               |
| `pipelines.log`           | Scrapy Pipelines    | `cointicker/logs/`              | ✅ 활성               |
| `orchestrator.log`        | Orchestrator        | `cointicker/logs/`              | ⚠️ 설정됨 (미실행)    |
| `scheduler.log`           | Scheduler           | `cointicker/logs/`              | ⚠️ 설정됨 (미실행)    |

### Orchestrator & Scheduler 상세 정보

**위치**: `master-node/orchestrator.py`, `master-node/scheduler.py`

**역할**:

- **Orchestrator**: 마스터 노드 역할, 파이프라인 스케줄링
  - 5분마다: 실시간 데이터 크롤링
  - 30분마다: 전체 파이프라인 실행
  - 매일 자정: 공포·탐욕 지수 수집
- **Scheduler**: Scrapyd를 통한 Spider 스케줄링
  - `spider_config.yaml`에서 Spider 스케줄 정보 로드
  - cron 형식 스케줄 파싱 및 실행

**GUI 구현 상태**:

- ✅ **백엔드 기능**: `PipelineModule`에 `start_orchestrator()`, `start_scheduler()` 메서드 구현됨
- ❌ **UI 버튼**: Control 탭에 실행/중지 버튼 없음
- ⚠️ **모니터링**: Process Monitor에 등록되지 않음 (로그 파일 생성 안 됨)
- ✅ **Systemd 관리**: Config 탭에서 systemd 서비스로 관리 가능 (tier1_orchestrator, tier2_scheduler)

**현재 상태**:

- 설정은 되어 있으나 GUI에서 직접 실행하는 UI가 없어 미실행 상태
- systemd 서비스로만 실행 가능 (Config 탭)
- GUI에서 실행하려면 `PipelineModule.execute("start_orchestrator")` 호출 필요

### Process Monitor가 생성하는 로그

**위치**: `cointicker/logs/`

**패턴**: `{process_name}.log`

**예시**:

- `kafka_consumer.log` (Process Monitor가 생성)
- `spider.log` (Process Monitor가 생성)

**주의**: 일부 로그는 Process Monitor와 모듈 자체 로그가 중복될 수 있음

---

## ⚠️ 발견된 문제점

### 1. 레거시 로그 디렉토리

**문제**: `worker-nodes/logs/` 디렉토리가 더 이상 사용되지 않음

**증거**:

- 마지막 업데이트: 2025-11-28
- 현재 활성 로그는 `worker-nodes/cointicker/logs/`에 저장됨

**조치**: ✅ **정리 가능** (삭제해도 무방)

### 2. Scrapy 로그 경로 불일치

**현재 상황**:

- Scrapy 설정: `LOG_FILE = "logs/scrapy.log"` (상대 경로)
- 실행 위치에 따라 다른 디렉토리에 저장됨

**권장 사항**:

- 통합 로그 디렉토리로 변경 고려
- 또는 현재 구조 유지 (워커 노드별 로그 분리)

### 3. 누락된 로그 파일

**설정은 되어 있으나 파일이 없는 경우**:

- `orchestrator.log`: Orchestrator 미실행
- `scheduler.log`: Scheduler 미실행

**조치**: 정상 (해당 모듈 실행 시 자동 생성)

---

## 🔧 로그 관리 권장 사항

### 1. 레거시 로그 정리

```bash
# 레거시 로그 디렉토리 삭제 (선택사항)
rm -rf PICU/cointicker/worker-nodes/logs/
```

**주의**: 삭제 전 백업 권장

### 2. 로그 로테이션

**현재 상태**:

- `kafka_client.log`: loguru 자동 회전 (10MB, 7일)
- 기타 로그: 수동 관리 필요

**권장 사항**:

- 외부 도구 사용 (예: `logrotate`)
- 또는 Python 로그 핸들러에 로테이션 추가

### 3. 로그 디렉토리 통합 (선택사항)

**현재**: 분산 구조

- `cointicker/logs/` (통합)
- `worker-nodes/cointicker/logs/` (Scrapy)

**통합 시 고려사항**:

- Scrapy 실행 위치에 따라 경로 변경 필요
- 또는 절대 경로 사용으로 변경

---

## 📊 로그 파일 크기 모니터링

### 현재 로그 파일 크기 (예시)

```
cointicker/logs/
├── kafka_client.log         # loguru 자동 회전
├── scrapy.log               # (없음, worker-nodes에 있음)
└── ...

worker-nodes/cointicker/logs/
└── scrapy.log               # 2.2MB (활성)

worker-nodes/logs/           # 레거시
└── scrapy.log               # 253KB (미사용)
```

---

## 🎯 정리 계획

### 즉시 조치 가능

1. ✅ **레거시 로그 디렉토리 삭제**
   - `worker-nodes/logs/` 디렉토리 삭제
   - 더 이상 사용되지 않음

### 검토 필요

2. ⚠️ **Scrapy 로그 경로 통합**

   - 현재: `worker-nodes/cointicker/logs/scrapy.log`
   - 통합 시: `cointicker/logs/scrapy.log`
   - **주의**: Scrapy 실행 위치 변경 필요

3. ⚠️ **로그 로테이션 설정**
   - 대용량 로그 파일 관리
   - 디스크 공간 절약

---

## 📝 참고 문서

- **파이프라인 로그 설정 점검 보고서**: [`파이프라인_로그_설정_점검_보고서.md`](파이프라인_로그_설정_점검_보고서.md)
- **로그 유틸리티**: `shared/logger.py`
- **경로 유틸리티**: `shared/path_utils.py`

---

## ✅ 결론

### 현재 상태

- ✅ 통합 로그 디렉토리 (`cointicker/logs/`) 정상 작동
- ✅ 워커 노드 로그 (`worker-nodes/cointicker/logs/`) 활성 사용
- ⚠️ 레거시 로그 (`worker-nodes/logs/`) 정리 가능

### 권장 조치

1. **레거시 로그 디렉토리 삭제** (즉시 가능)
2. **로그 로테이션 설정** (선택사항)
3. **Scrapy 로그 경로 통합** (검토 필요)

---

**작성자**: Juns AI Assistant
**최종 업데이트**: 2025-12-07
