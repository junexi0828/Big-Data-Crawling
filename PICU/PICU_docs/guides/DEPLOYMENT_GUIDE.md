# PICU í”„ë¡œì íŠ¸ ë°°í¬ ê°€ì´ë“œ

**ì‘ì„± ì¼ì‹œ**: 2025-11-29
**ëŒ€ìƒ**: ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° ë°°í¬ ë° Docker ë°°í¬
**ë²„ì „**: 1.0

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
3. [ì»´í¬ë„ŒíŠ¸ë³„ ì„¤ì¹˜ ë°©ì‹](#ì»´í¬ë„ŒíŠ¸ë³„-ì„¤ì¹˜-ë°©ì‹)
4. [ë°°í¬ ì „ëµ](#ë°°í¬-ì „ëµ)
5. [ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° ë°°í¬](#ë¼ì¦ˆë² ë¦¬íŒŒì´-í´ëŸ¬ìŠ¤í„°-ë°°í¬)
6. [Docker ë°°í¬](#docker-ë°°í¬)
7. [ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ](#ë°°í¬-ì‹œë‚˜ë¦¬ì˜¤-ë¹„êµ)
8. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## ê°œìš”

PICU í”„ë¡œì íŠ¸ëŠ” ë¼ì¦ˆë² ë¦¬íŒŒì´ 4ëŒ€ë¥¼ í™œìš©í•œ ë¶„ì‚° í´ëŸ¬ìŠ¤í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” í”„ë¡œì íŠ¸ë¥¼ ì‹¤ì œ í™˜ê²½ì— ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

### ë°°í¬ ëŒ€ìƒ í™˜ê²½

- **Tier 1**: ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° (4ëŒ€)
  - Master Node: Hadoop NameNode, YARN ResourceManager, Scrapyd Scheduler
  - Worker Nodes (3ëŒ€): Hadoop DataNode, Scrapy Spiders, MapReduce
- **Tier 2**: ì™¸ë¶€ ì„œë²„ (ì„ íƒì )
  - FastAPI Backend, MariaDB, React Frontend

---

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´

- **ë¼ì¦ˆë² ë¦¬íŒŒì´ 4ëŒ€** (ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 ê¶Œì¥)
  - RAM: 4GB ì´ìƒ
  - Storage: 32GB ì´ìƒ (SD ì¹´ë“œ)
  - ë„¤íŠ¸ì›Œí¬: ì´ë”ë„· ì—°ê²°

### ì†Œí”„íŠ¸ì›¨ì–´

- **OS**: Raspberry Pi OS (Debian ê¸°ë°˜) ë˜ëŠ” Ubuntu Server
- **Python**: 3.8 ì´ìƒ
- **Java**: JDK 8 ì´ìƒ (Hadoop, Kafkaìš©)
- **Maven**: 3.x (Kafka Java í”„ë¡œì íŠ¸ìš©, ì„ íƒì )

---

## ì»´í¬ë„ŒíŠ¸ë³„ ì„¤ì¹˜ ë°©ì‹

### ì„¤ì¹˜ ë°©ì‹ ìš”ì•½

| ì»´í¬ë„ŒíŠ¸     | ì„œë²„/ë°”ì´ë„ˆë¦¬ ìœ„ì¹˜                         | í´ë¼ì´ì–¸íŠ¸/ë¼ì´ë¸ŒëŸ¬ë¦¬ ìœ„ì¹˜   | ì„¤ì¹˜ ë°©ì‹               |
| ------------ | ------------------------------------------ | ---------------------------- | ----------------------- |
| **í•˜ë‘¡**     | `hadoop_project/hadoop-3.4.1/` (ì§ì ‘ ì„¤ì¹˜) | ê°€ìƒí™˜ê²½ (`pyarrow`, `hdfs`) | ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œ + pip |
| **ì¹´í”„ì¹´**   | ì‹œìŠ¤í…œ (`/opt/homebrew/opt/kafka` - brew)  | ê°€ìƒí™˜ê²½ (`kafka-python`)    | brew ì„¤ì¹˜ + pip         |
| **ìŠ¤í¬ë˜í”¼** | ì—†ìŒ (Python íŒ¨í‚¤ì§€)                       | ê°€ìƒí™˜ê²½ (`scrapy`)          | pip                     |
| **ì…€ë ˆë‹ˆì›€** | ì—†ìŒ (Python íŒ¨í‚¤ì§€)                       | ê°€ìƒí™˜ê²½ (`selenium`)        | pip                     |

### ìƒì„¸ ì„¤ëª…

#### 1. í•˜ë‘¡ (Hadoop)

**ë°”ì´ë„ˆë¦¬ ìœ„ì¹˜**: `bigdata/hadoop_project/hadoop-3.4.1/` (1.7GB)

- **ì„¤ì¹˜ ë°©ì‹**: Apache ê³µì‹ ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
- **ê°€ìƒí™˜ê²½ ì—¬ë¶€**: âŒ ì•„ë‹˜ (Java ê¸°ë°˜ ë°”ì´ë„ˆë¦¬ ì§ì ‘ ì„¤ì¹˜)
- **Python í´ë¼ì´ì–¸íŠ¸**: ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜ (`pyarrow>=14.0.0`, `hdfs>=2.7.0`)
- **ìë™ ê°ì§€**: PICUì˜ `HDFSManager`ê°€ `hadoop_project/hadoop-3.4.1` ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ê²€ìƒ‰

**ì„¤ì¹˜ í™•ì¸**:

```bash
# hadoop_projectì— í•˜ë‘¡ ì¡´ì¬ í™•ì¸
ls -la hadoop_project/hadoop-3.4.1/bin/hadoop

# HADOOP_HOME ìë™ ê°ì§€ í™•ì¸
python -c "from PICU.cointicker.gui.modules.managers.hdfs_manager import HDFSManager; print(HDFSManager().check_and_start())"
```

#### 2. ì¹´í”„ì¹´

**ì„œë²„ ìœ„ì¹˜**: ì‹œìŠ¤í…œì— brew/aptë¡œ ì„¤ì¹˜

- **macOS**: `brew install kafka` â†’ `/opt/homebrew/opt/kafka`
- **Linux**: `apt install kafka` â†’ ì‹œìŠ¤í…œ ê²½ë¡œ
- **Python í´ë¼ì´ì–¸íŠ¸**: ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜ (`kafka-python>=2.0.2`)

**ì„¤ì¹˜ í™•ì¸**:

```bash
# Kafka ì„œë²„ í™•ì¸
which kafka-server-start

# Python í´ë¼ì´ì–¸íŠ¸ í™•ì¸
pip list | grep kafka-python
```

#### 3. ìŠ¤í¬ë˜í”¼ & ì…€ë ˆë‹ˆì›€

**ì„¤ì¹˜ ìœ„ì¹˜**: ê°€ìƒí™˜ê²½ì— pipë¡œ ì„¤ì¹˜

- **ê°€ìƒí™˜ê²½**:
  - `scrapy_env/` (í”„ë¡œì íŠ¸ ë£¨íŠ¸)
  - `PICU/venv/` (PICU í”„ë¡œì íŠ¸)
  - `PICU/cointicker/venv/` (ì½”ì¸í‹°ì»¤ í”„ë¡œì íŠ¸)
- **ì„¤ì¹˜ ë°©ë²•**: `pip install -r requirements.txt`

**ì„¤ì¹˜ í™•ì¸**:

```bash
source venv/bin/activate
scrapy version
python -c "import selenium; print(selenium.__version__)"
```

---

## ë°°í¬ ì „ëµ

### ì „ëµ ë¹„êµ

#### ì˜µì…˜ 1: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ (ê¶Œì¥) â­

**ê° ì»´í¬ë„ŒíŠ¸ë³„ ë°°í¬ ë°©ì‹**:

| ì»´í¬ë„ŒíŠ¸              | ë°°í¬ ë°©ì‹             | ì´ìœ                                    |
| --------------------- | --------------------- | -------------------------------------- |
| **í•˜ë‘¡**              | ì§ì ‘ ë°°í¬ (í˜„ì¬ ë°©ì‹) | í´ëŸ¬ìŠ¤í„° êµ¬ì„± í•„ìš”, ë„¤íŠ¸ì›Œí¬ ì„¤ì • ë³µì¡ |
| **ì¹´í”„ì¹´**            | Docker ë˜ëŠ” ì§ì ‘ ë°°í¬ | í´ëŸ¬ìŠ¤í„° êµ¬ì„± ê°€ëŠ¥, Dockerë¡œ ê´€ë¦¬ ìš©ì´ |
| **ìŠ¤í¬ë˜í”¼/ì…€ë ˆë‹ˆì›€** | Docker (ê¶Œì¥)         | ê°€ìƒí™˜ê²½ ì˜ì¡´ì„± ê´€ë¦¬ ê°„í¸              |
| **PICU ì• í”Œë¦¬ì¼€ì´ì…˜** | Docker (ê¶Œì¥)         | ì¼ê´€ëœ í™˜ê²½, ë°°í¬ ê°„í¸                 |

**ì¥ì **:

- ê° ì»´í¬ë„ŒíŠ¸ì˜ íŠ¹ì„±ì— ë§ëŠ” ìµœì ì˜ ë°°í¬ ë°©ì‹ ì„ íƒ
- í•˜ë‘¡ í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì˜ ë³µì¡ë„ ìµœì†Œí™”
- PICU ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì˜ì¡´ì„± ê´€ë¦¬ ê°„í¸

**ë‹¨ì **:

- ë°°í¬ ë°©ì‹ì´ í˜¼ì¬ë˜ì–´ ê´€ë¦¬ ë³µì¡ë„ ì¦ê°€
- Dockerì™€ ì§ì ‘ ë°°í¬ì˜ í˜¼ìš©

#### ì˜µì…˜ 2: ì „ì²´ Dockerí™”

**ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ Dockerë¡œ ë°°í¬**

**ì¥ì **:

- ì¼ê´€ëœ í™˜ê²½
- ì˜ì¡´ì„± ê´€ë¦¬ ê°„í¸
- ë°°í¬ ìë™í™” ìš©ì´

**ë‹¨ì **:

- í•˜ë‘¡ í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë³µì¡ (ë„¤íŠ¸ì›Œí¬, ë³¼ë¥¨ ì„¤ì •)
- ë¦¬ì†ŒìŠ¤ ì˜¤ë²„í—¤ë“œ
- ë””ë²„ê¹… ì–´ë ¤ì›€

### ê¶Œì¥ ë°°í¬ ì „ëµ

**í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ (ì˜µì…˜ 1) ê¶Œì¥**

1. **í•˜ë‘¡**: ì§ì ‘ ë°°í¬ (í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë³µì¡ë„)
2. **PICU ì• í”Œë¦¬ì¼€ì´ì…˜**: Docker (ì˜ì¡´ì„± ê´€ë¦¬)
3. **ì¹´í”„ì¹´**: í™˜ê²½ì— ë”°ë¼ ì„ íƒ (ì‹œìŠ¤í…œ ì„¤ì¹˜ ë˜ëŠ” Docker)

---

## ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° ë°°í¬

### ì‚¬ì „ ì¤€ë¹„

#### 1. ë„¤íŠ¸ì›Œí¬ ì„¤ì •

ê° ë¼ì¦ˆë² ë¦¬íŒŒì´ì— ê³ ì • IPì™€ í˜¸ìŠ¤íŠ¸ëª… ì„¤ì •:

```bash
# /etc/hosts íŒŒì¼ ìˆ˜ì • (ê° ë…¸ë“œì—ì„œ)
192.168.1.100 raspberry-master
192.168.1.101 raspberry-worker1
192.168.1.102 raspberry-worker2
192.168.1.103 raspberry-worker3
```

#### 2. SSH í‚¤ ì„¤ì •

ê°œë°œ PCì—ì„œ ê° ë…¸ë“œë¡œ íŒ¨ìŠ¤ì›Œë“œ ì—†ëŠ” SSH ì ‘ì† ì„¤ì •:

```bash
# SSH í‚¤ ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ)
ssh-keygen -t rsa

# ê° ë…¸ë“œì— í‚¤ ë³µì‚¬
ssh-copy-id pi@raspberry-master
ssh-copy-id pi@raspberry-worker1
ssh-copy-id pi@raspberry-worker2
ssh-copy-id pi@raspberry-worker3
```

### ë°°í¬ ë‹¨ê³„

#### 1ë‹¨ê³„: í•˜ë‘¡ ë°°í¬

```bash
# ê°œë°œ PCì—ì„œ
cd hadoop_project

# í•˜ë‘¡ í´ëŸ¬ìŠ¤í„° ë°°í¬
./deployment/deploy_all.sh
```

**ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ í•˜ëŠ” ì¼**:

- NameNodeì— `/opt/hadoop` ì„¤ì¹˜
- ì„¤ì • íŒŒì¼ ë°°í¬ (`core-site.xml`, `hdfs-site.xml`)
- DataNodeì— rsyncë¡œ ë³µì‚¬
- í™˜ê²½ë³€ìˆ˜ ì„¤ì •

**ìˆ˜ë™ ë°°í¬ (ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© ë¶ˆê°€ ì‹œ)**:

```bash
# NameNodeì— í•˜ë‘¡ ì„¤ì¹˜
scp -r hadoop_project/hadoop-3.4.1 pi@raspberry-master:/opt/hadoop

# ê° ë…¸ë“œì— ì„¤ì • íŒŒì¼ ë°°í¬
scp hadoop_project/config/*.xml pi@raspberry-master:/opt/hadoop/etc/hadoop/
```

#### 2ë‹¨ê³„: ì¹´í”„ì¹´ ë°°í¬ (ì„ íƒ)

**ì˜µì…˜ A: ì‹œìŠ¤í…œì— ì§ì ‘ ì„¤ì¹˜**

```bash
# ê° ë…¸ë“œì—ì„œ
sudo apt update
sudo apt install kafka
```

**ì˜µì…˜ B: Dockerë¡œ ë°°í¬**

```bash
# docker-compose.kafka.yml ìƒì„± í›„
docker-compose -f docker-compose.kafka.yml up -d
```

#### 3ë‹¨ê³„: PICU ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬

**ë°©ë²• 1: ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¶Œì¥)**

```bash
# ê°œë°œ PCì—ì„œ
cd PICU

# Master Node ë°°í¬
./deployment/setup_master.sh

# Worker Nodes ë°°í¬
./deployment/setup_worker.sh raspberry-worker1 192.168.1.101
./deployment/setup_worker.sh raspberry-worker2 192.168.1.102
./deployment/setup_worker.sh raspberry-worker3 192.168.1.103

# ë˜ëŠ” ëª¨ë“  ë…¸ë“œ í•œ ë²ˆì—
./deployment/setup_all_nodes.sh
```

**ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ê°€ í•˜ëŠ” ì¼**:

1. ì½”ë“œ ì „ì†¡ (rsync)
2. ê°€ìƒí™˜ê²½ ìƒì„±
3. Python ì˜ì¡´ì„± ì„¤ì¹˜ (`pip install -r requirements.txt`)
4. systemd ì„œë¹„ìŠ¤ ë“±ë¡ (ì„ íƒì )

**ë°©ë²• 2: ìˆ˜ë™ ë°°í¬**

```bash
# Master Node
rsync -avz --exclude 'venv' --exclude '__pycache__' \
    PICU/cointicker/master-node/ \
    pi@raspberry-master:/home/pi/cointicker/master-node/

# Worker Node
rsync -avz --exclude 'venv' --exclude '__pycache__' \
    PICU/cointicker/worker-nodes/ \
    pi@raspberry-worker1:/home/pi/cointicker/worker-nodes/
```

#### 4ë‹¨ê³„: ì„œë¹„ìŠ¤ ì‹œì‘

**í•˜ë‘¡ ì‹œì‘**:

```bash
# NameNodeì—ì„œ
ssh pi@raspberry-master
cd /opt/hadoop
./sbin/start-dfs.sh
./sbin/start-yarn.sh
```

**PICU ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘**:

```bash
# Master Node
ssh pi@raspberry-master
cd /home/pi/cointicker
source venv/bin/activate
python master-node/orchestrator.py

# Worker Node
ssh pi@raspberry-worker1
cd /home/pi/cointicker
source venv/bin/activate
python worker-nodes/cointicker/spiders/run_spider.py
```

---

## Docker ë°°í¬

### Docker ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤

**ë‹¤ë¥¸ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ë•Œ Dockerë¡œ ë¬¶ì–´ì„œ ë°°í¬í•˜ë©´, ë¼ì¦ˆë² ë¦¬íŒŒì´ 4ëŒ€ë§Œ ì—°ê²°í•˜ë©´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.**

### Dockerfile ì˜ˆì‹œ

#### Master Node Dockerfile

```dockerfile
# docker/Dockerfile.master
FROM python:3.11-slim

WORKDIR /app

# hadoop_projectì˜ í•˜ë‘¡ì„ ì»¨í…Œì´ë„ˆì— ë³µì‚¬
COPY hadoop_project/hadoop-3.4.1 /opt/hadoop

# PICU ì½”ë“œ ë³µì‚¬
COPY PICU/cointicker/master-node /app/master-node
COPY PICU/cointicker/shared /app/shared
COPY PICU/cointicker/config /app/config

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY PICU/requirements/requirements-master.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
ENV HADOOP_HOME=/opt/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

CMD ["python", "master-node/orchestrator.py"]
```

#### Worker Node Dockerfile

```dockerfile
# docker/Dockerfile.worker
FROM python:3.11-slim

WORKDIR /app

# hadoop_projectì˜ í•˜ë‘¡ì„ ì»¨í…Œì´ë„ˆì— ë³µì‚¬
COPY hadoop_project/hadoop-3.4.1 /opt/hadoop

# PICU ì½”ë“œ ë³µì‚¬
COPY PICU/cointicker/worker-nodes /app/worker-nodes
COPY PICU/cointicker/shared /app/shared
COPY PICU/cointicker/config /app/config

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY PICU/requirements/requirements-worker.txt /app/requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
ENV HADOOP_HOME=/opt/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

CMD ["python", "worker-nodes/cointicker/spiders/run_spider.py"]
```

### Docker Compose ì˜ˆì‹œ

```yaml
# docker-compose.yml
version: "3.8"

services:
  # Hadoop NameNode
  hadoop-namenode:
    build:
      context: .
      dockerfile: docker/Dockerfile.hadoop-namenode
    networks:
      - hadoop-cluster
    volumes:
      - hadoop-namenode-data:/opt/hadoop/data

  # Hadoop DataNode
  hadoop-datanode:
    build:
      context: .
      dockerfile: docker/Dockerfile.hadoop-datanode
    networks:
      - hadoop-cluster
    depends_on:
      - hadoop-namenode

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    networks:
      - kafka-cluster
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092

  # PICU Master
  picu-master:
    build:
      context: .
      dockerfile: docker/Dockerfile.master
    depends_on:
      - hadoop-namenode
      - kafka
    networks:
      - hadoop-cluster
      - kafka-cluster

  # PICU Worker
  picu-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.worker
    depends_on:
      - hadoop-datanode
      - kafka
    networks:
      - hadoop-cluster
      - kafka-cluster

networks:
  hadoop-cluster:
  kafka-cluster:

volumes:
  hadoop-namenode-data:
```

### Docker ë°°í¬ ì‚¬ìš©ë²•

**ì´ë¯¸ì§€ ë¹Œë“œ**:

```bash
# Master Node ì´ë¯¸ì§€
docker build -t picu-master:latest -f docker/Dockerfile.master .

# Worker Node ì´ë¯¸ì§€
docker build -t picu-worker:latest -f docker/Dockerfile.worker .
```

**ë°°í¬ ë° ì‹¤í–‰**:

```bash
# Docker Composeë¡œ ì „ì²´ ì‹¤í–‰
docker-compose up -d

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
docker run -d --name picu-master picu-master:latest
docker run -d --name picu-worker picu-worker:latest
```

**ì‚¬ìš©ìê°€ í•´ì•¼ í•  ì¼**:

```bash
# 1. Docker ì´ë¯¸ì§€ ë°›ê¸°
docker pull your-registry/picu-cluster:latest

# 2. docker-compose ì‹¤í–‰
docker-compose up -d

# ë! ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
```

---

## ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° ì§ì ‘ ë°°í¬ (í˜„ì¬ ë°©ì‹)

**ëŒ€ìƒ**: ê°œë°œìê°€ ì§ì ‘ ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„°ì— ë°°í¬

**ë‹¨ê³„**:

1. í•˜ë‘¡ ë°°í¬ (`hadoop_project/deployment/deploy_all.sh`)
2. ì¹´í”„ì¹´ ë°°í¬ (ì‹œìŠ¤í…œ ì„¤ì¹˜ ë˜ëŠ” Docker)
3. PICU ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (`PICU/deployment/setup_all_nodes.sh`)

**ì¥ì **:

- ê° ë…¸ë“œì˜ ìƒíƒœë¥¼ ì§ì ‘ í™•ì¸ ê°€ëŠ¥
- ë””ë²„ê¹… ìš©ì´
- ë¦¬ì†ŒìŠ¤ ì˜¤ë²„í—¤ë“œ ì—†ìŒ

**ë‹¨ì **:

- ìˆ˜ë™ ì‘ì—… í•„ìš”
- í™˜ê²½ ì°¨ì´ ë°œìƒ ê°€ëŠ¥
- ë°°í¬ ì‹œê°„ ì†Œìš”

### ì‹œë‚˜ë¦¬ì˜¤ 2: Docker ë°°í¬ (ë‹¤ë¥¸ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬)

**ëŒ€ìƒ**: ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ë¼ì¦ˆë² ë¦¬íŒŒì´ 4ëŒ€ë§Œ ì—°ê²°í•˜ì—¬ ì‚¬ìš©

**ë‹¨ê³„**:

1. Docker ì´ë¯¸ì§€ ë¹Œë“œ (ê°œë°œìê°€ ìˆ˜í–‰)
2. Docker ì´ë¯¸ì§€ ë°°í¬ (ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë˜ëŠ” íŒŒì¼)
3. `docker-compose up -d` ì‹¤í–‰

**ì¥ì **:

- âœ… **ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥** (ì˜ì¡´ì„± ëª¨ë‘ í¬í•¨)
- í™˜ê²½ ì¼ê´€ì„±
- ë°°í¬ ê°„í¸

**ë‹¨ì **:

- Docker ì´ë¯¸ì§€ í¬ê¸° (í•˜ë‘¡ í¬í•¨ ì‹œ 2GB+)
- Docker ë¦¬ì†ŒìŠ¤ ì˜¤ë²„í—¤ë“œ
- í•˜ë‘¡ í´ëŸ¬ìŠ¤í„° êµ¬ì„± ë³µì¡ë„

### ì‹œë‚˜ë¦¬ì˜¤ 3: Git í´ë¡ 

**ëŒ€ìƒ**: ì†ŒìŠ¤ ì½”ë“œë¥¼ ê³µê°œí•˜ê³  ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì¹˜

**ë‹¨ê³„**:

1. `git clone <repository>`
2. í•˜ë‘¡ ì„¤ì¹˜
3. ì¹´í”„ì¹´ ì„¤ì¹˜
4. Python ì˜ì¡´ì„± ì„¤ì¹˜
5. ì„¤ì • íŒŒì¼ ìˆ˜ì •
6. ë„¤íŠ¸ì›Œí¬ ì„¤ì •

**ì¥ì **:

- ì†ŒìŠ¤ ì½”ë“œ ê³µê°œ/ê³µìœ  ìš©ì´
- ë²„ì „ ê´€ë¦¬ ê°€ëŠ¥
- ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥

**ë‹¨ì **:

- âŒ **ë°”ë¡œ ì‚¬ìš© ë¶ˆê°€** (ëª¨ë“  ê²ƒì„ ìˆ˜ë™ ì„¤ì¹˜)
- ì‚¬ìš©ì ê¸°ìˆ  ìˆ˜ì¤€ ìš”êµ¬
- í™˜ê²½ ì°¨ì´ ë°œìƒ ê°€ëŠ¥

### ë¹„êµí‘œ

| ì‹œë‚˜ë¦¬ì˜¤        | ì‚¬ìš©ì ì‘ì—…ëŸ‰             | ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥? | ì˜ì¡´ì„± í¬í•¨? | ê¶Œì¥ ëŒ€ìƒ                |
| --------------- | ------------------------- | --------------- | ------------ | ------------------------ |
| **ì§ì ‘ ë°°í¬**   | ì¤‘ê°„ (ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©) | âš ï¸ ë¶€ë¶„ì        | âŒ ë³„ë„ ì„¤ì¹˜ | ê°œë°œì                   |
| **Docker ë°°í¬** | ìµœì†Œ (docker-composeë§Œ)   | âœ… ì˜ˆ           | âœ… ëª¨ë‘ í¬í•¨ | ì¼ë°˜ ì‚¬ìš©ì              |
| **Git í´ë¡ **    | ë§ìŒ (ëª¨ë‘ ìˆ˜ë™ ì„¤ì¹˜)     | âŒ ì•„ë‹ˆì˜¤       | âŒ ë³„ë„ ì„¤ì¹˜ | ê°œë°œì/ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš” |

---

## ë¬¸ì œ í•´ê²°

### í•˜ë‘¡ ê´€ë ¨

**ë¬¸ì œ**: HADOOP_HOMEì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

**í•´ê²°**:

```bash
# HDFSManagerê°€ ìë™ìœ¼ë¡œ hadoop_project ê²½ë¡œë¥¼ ì°¾ìŒ
# ìˆ˜ë™ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°:
export HADOOP_HOME=/path/to/hadoop_project/hadoop-3.4.1
```

**ë¬¸ì œ**: HDFS ì—°ê²° ì‹¤íŒ¨

**í•´ê²°**:

```bash
# HDFS ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
jps | grep -E "NameNode|DataNode"

# HDFS ì‹œì‘
cd /opt/hadoop
./sbin/start-dfs.sh
```

### Python ì˜ì¡´ì„± ê´€ë ¨

**ë¬¸ì œ**: ê°€ìƒí™˜ê²½ì—ì„œ íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

**í•´ê²°**:

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
source venv/bin/activate

# ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install -r requirements.txt
```

### ë„¤íŠ¸ì›Œí¬ ê´€ë ¨

**ë¬¸ì œ**: SSH ì—°ê²° ì‹¤íŒ¨

**í•´ê²°**:

```bash
# SSH í‚¤ í™•ì¸
ssh-copy-id pi@raspberry-master

# í˜¸ìŠ¤íŠ¸ëª… í™•ì¸
cat /etc/hosts
```

### Docker ê´€ë ¨

**ë¬¸ì œ**: Docker ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ í¼

**í•´ê²°**:

- í•˜ë‘¡ì„ ë³¼ë¥¨ ë§ˆìš´íŠ¸ë¡œ ë¶„ë¦¬
- ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ ì‚¬ìš©
- ë¶ˆí•„ìš”í•œ íŒŒì¼ ì œì™¸

---

## ì°¸ê³  ìë£Œ

- [HDFS ì—°ë™ ë¬¸ì œ ë¶„ì„ ë³´ê³ ì„œ](../troubleshooting/HDFS_ì—°ë™_ë¬¸ì œ_ë¶„ì„_ë³´ê³ ì„œ.md)
- [ì‹¤ìŠµ í†µí•© í´ëŸ¬ìŠ¤í„° êµ¬ì„±](./ì‹¤ìŠµí†µí•©í´ëŸ¬ìŠ¤í„°êµ¬ì„±.md)
- [GUI ê°€ì´ë“œ](./GUI_GUIDE.md)
- [í†µí•© ê°€ì´ë“œ](./INTEGRATION_GUIDE.md)

---

**ì‘ì„±ì**: JUNS_AI_MCP
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-29
**ë²„ì „**: 1.0
