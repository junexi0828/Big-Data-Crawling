# [ì½”ë“œ] ì½”ì¸ í‹°ì»¤ ë³€ê²½ì„¤ê³„

ìƒíƒœ: ì™„ë£Œ

# ì½”ì¸í‹°ì»¤(CoinTicker) í”„ë¡œì íŠ¸ ì¬ì„¤ê³„

## ì•”í˜¸í™”í ì‹œì¥ ë™í–¥ ë¶„ì„ ë° ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ

---

## ğŸ“Œ **1. í”„ë¡œì íŠ¸ í•µì‹¬ ë°©í–¥ ì „í™˜**

### **ê¸°ì¡´ â†’ ë³€ê²½**

- **ì´ì „**: ì¢…í•©ì‹œí™© ì¤‘ì‹¬ì˜ ë‹¤ëª©ì  ì •ë³´ ìˆ˜ì§‘
- **í˜„ì¬**: **ì•”í˜¸í™”í ì‹œì¥ ë™í–¥ íŠ¹í™”** - ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì•”í˜¸í™”í ì‹œì¥ ê´€ì ìœ¼ë¡œ í•´ì„Â·ë¶„ì„

### **ìµœì¢… ëª©í‘œ**

> "ì•”í˜¸í™”í ì‹œì¥ì˜ ì‹¤ì‹œê°„ ì‹¬ë¦¬Â·ê¸°ìˆ ì  ë™í–¥ì„ ì •ëŸ‰í™”í•˜ì—¬, íˆ¬ììì—ê²Œ ìœ ì˜ë¯¸í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ëŒ€ì‹œë³´ë“œ í”Œë«í¼"
> 

---

## ğŸ—ï¸ **2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (2-Tier êµ¬ì¡°)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° (4ëŒ€)                 â”‚
â”‚          â”â”â” ë°ì´í„° ìˆ˜ì§‘ & ì €ì¥ ì „ë‹´ â”â”â”                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [Master Node]                                          â”‚
â”‚   - Hadoop NameNode (ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë¦¬)              â”‚
â”‚   - Scrapyd Scheduler (í¬ë¡¤ë§ ì‘ì—… ìŠ¤ì¼€ì¤„ë§)            â”‚
â”‚   - HDFS ë°ì´í„° ì €ì¥                                     â”‚
â”‚                                                          â”‚
â”‚  [Worker Nodes 1-3]                                     â”‚
â”‚   - Scrapy Spiders (ë³‘ë ¬ í¬ë¡¤ë§)                        â”‚
â”‚     â€¢ Upbit Trends                                      â”‚
â”‚     â€¢ Coinness News                                     â”‚
â”‚     â€¢ SaveTicker/Yahoo Finance                          â”‚
â”‚     â€¢ Perplexity Finance                                â”‚
â”‚     â€¢ CNN Fear & Greed Index                            â”‚
â”‚   - Hadoop DataNode (ë°ì´í„° ë¶„ì‚° ì €ì¥)                  â”‚
â”‚   - MapReduce (ê¸°ì´ˆ ì •ì œ: ì¤‘ë³µì œê±°, í˜•ì‹ í†µì¼)          â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HDFS â†’ SSH/REST API
                  â”‚ ì •ì œëœ ë°ì´í„° ì „ì†¡
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ì™¸ë¶€ ì„œë²„ (ì¼ë°˜ PC/í´ë¼ìš°ë“œ)              â”‚
â”‚          â”â”â” ë°ì´í„° ë¶„ì„ & ëŒ€ì‹œë³´ë“œ ìš´ì˜ â”â”â”            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  [ë°ì´í„° ì²˜ë¦¬ ê³„ì¸µ]                                      â”‚
â”‚   - HDFS ë°ì´í„° fetch (hdfs dfs -get ë˜ëŠ” REST)        â”‚
â”‚   - MariaDB/PostgreSQL ì ì¬                             â”‚
â”‚   - NLP ê°ì„±ë¶„ì„ (FinBERT/KoBERT)                       â”‚
â”‚   - ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ ë“±)         â”‚
â”‚   - ì•”í˜¸í™”í íŠ¹í™” íŠ¸ë Œë“œ ë¶„ì„                            â”‚
â”‚                                                          â”‚
â”‚  [ëŒ€ì‹œë³´ë“œ ê³„ì¸µ]                                         â”‚
â”‚   - Backend: Flask/FastAPI (REST API ì œê³µ)             â”‚
â”‚   - Frontend: React/Vue + Chart.js                     â”‚
â”‚   - ì‹¤ì‹œê°„ ì‹œê°í™”: WebSocket ì—°ë™                       â”‚
â”‚   - ì•Œë¦¼ ì‹œìŠ¤í…œ: Email/Slack/Telegram                   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸ¯ **3. í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸ ë° ìˆ˜ì§‘ ë°ì´í„°**

### **ì„ ì •ëœ 5ê°œ ì‚¬ì´íŠ¸**

| ì‚¬ì´íŠ¸ | ìˆ˜ì§‘ ë°ì´í„° | ì•”í˜¸í™”í ì‹œì¥ ì˜ë¯¸ | ì—…ë°ì´íŠ¸ ì£¼ê¸° |
| --- | --- | --- | --- |
| **Upbit Trends** | ê±°ë˜ëŸ‰ ê¸‰ì¦ ì½”ì¸, ì¸ê¸° ê²€ìƒ‰ì–´, ì‹œê°€ì´ì•¡ ìˆœìœ„ | í•œêµ­ ì‹œì¥ íˆ¬ìì ê´€ì‹¬ë„ | ì‹¤ì‹œê°„ (5ë¶„) |
| **Coinness** | ì•”í˜¸í™”í íŠ¹í™” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ | ê¸€ë¡œë²Œ ì‹œì¥ ì´ìŠˆ íŒŒì•… | ì‹¤ì‹œê°„ (10ë¶„) |
| **SaveTicker (Yahoo Finance)** | ì£¼ìš” ì½”ì¸ ê°€ê²©, ê±°ë˜ëŸ‰, ê¸°ìˆ ì  ì§€í‘œ | ì •ëŸ‰ì  ì‹œì¥ ë°ì´í„° | ì‹¤ì‹œê°„ (5ë¶„) |
| **Perplexity Finance** | AI ê¸°ë°˜ ê¸ˆìœµ ìš”ì•½, ì‹œì¥ ì „ë§ | ë§¥ë½ì  ì‹œì¥ ë¶„ì„ | ì¼ì¼ ì—…ë°ì´íŠ¸ |
| **CNN Fear & Greed Index** | ê³µí¬Â·íƒìš• ì§€ìˆ˜ (0-100) | ì „ì²´ ì‹œì¥ ì‹¬ë¦¬ ì •ëŸ‰í™” | ì¼ì¼ ì—…ë°ì´íŠ¸ |

### **ìˆ˜ì§‘ ë°ì´í„° êµ¬ì¡°**

```json
{
  "upbit_trends": {
    "timestamp": "2025-10-20T14:30:00",
    "top_volume": [
      {"symbol": "BTC", "volume_24h": "1.2B", "change_24h": "+3.2%"},
      {"symbol": "ETH", "volume_24h": "850M", "change_24h": "+2.1%"}
    ],
    "trending_searches": ["Bitcoin ETF", "Ethereum 2.0", "Ripple SEC"]
  },
  "coinness_news": {
    "timestamp": "2025-10-20T14:35:00",
    "articles": [
      {
        "title": "ë¹„íŠ¸ì½”ì¸, ì—°ì¤€ ë°œì–¸ í›„ ê¸‰ë“±ì„¸",
        "url": "https://...",
        "published": "2025-10-20T13:00:00",
        "keywords": ["Bitcoin", "Fed", "Interest Rate"]
      }
    ]
  },
  "technical_indicators": {
    "symbol": "BTCUSDT",
    "timestamp": "2025-10-20T14:30:00",
    "price": 67800,
    "rsi": 58.3,
    "macd": {"value": 120.5, "signal": "buy"},
    "volume": "2.3B"
  },
  "fear_greed_index": {
    "timestamp": "2025-10-20T00:00:00",
    "value": 65,
    "classification": "Greed"
  }
}

```

---

## ğŸ› ï¸ **4. ë¼ì¦ˆë² ë¦¬íŒŒì´ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤**

### **Phase 1: ë°ì´í„° ìˆ˜ì§‘ (Scrapy)**

```python
# scrapy_spiders/upbit_spider.py
import scrapy
import json
from datetime import datetime

class UpbitTrendsSpider(scrapy.Spider):
    name = "upbit_trends"
    start_urls = ["https://upbit.com/trends"]

    def parse(self, response):
        # ê±°ë˜ëŸ‰ ê¸‰ì¦ ì½”ì¸ ì¶”ì¶œ
        top_volume = response.css('.volume-rank-item')

        data = {
            'timestamp': datetime.now().isoformat(),
            'source': 'upbit',
            'top_volume': [],
            'trending_searches': []
        }

        for item in top_volume:
            data['top_volume'].append({
                'symbol': item.css('.coin-name::text').get(),
                'volume_24h': item.css('.volume::text').get(),
                'change_24h': item.css('.change::text').get()
            })

        # ê²€ìƒ‰ì–´ ì¶”ì¶œ
        searches = response.css('.trending-search-item::text').getall()
        data['trending_searches'] = searches[:10]

        # HDFSì— ì €ì¥
        filename = f"/raw/upbit/{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        yield data

```

### **Phase 2: ë°ì´í„° ì •ì œ (Hadoop MapReduce)**

```python
# mapreduce/cleaner_mapper.py
import sys
import json
from datetime import datetime

def mapper():
    """ì¤‘ë³µ ì œê±° ë° í˜•ì‹ í†µì¼"""
    for line in sys.stdin:
        try:
            data = json.loads(line)

            # ë°ì´í„° ê²€ì¦
            if not data.get('timestamp') or not data.get('source'):
                continue

            # í˜•ì‹ í†µì¼
            cleaned = {
                'timestamp': datetime.fromisoformat(data['timestamp']),
                'source': data['source'].lower(),
                'data': data
            }

            # Key: source + date (ì‹œê°„ë³„ ì§‘ê³„ìš©)
            key = f"{cleaned['source']}_{cleaned['timestamp'].strftime('%Y%m%d_%H')}"
            print(f"{key}\t{json.dumps(cleaned)}")

        except Exception as e:
            continue

if __name__ == "__main__":
    mapper()

```

```python
# mapreduce/cleaner_reducer.py
import sys
import json
from collections import defaultdict

def reducer():
    """ì‹œê°„ëŒ€ë³„ ë°ì´í„° ì§‘ê³„ ë° ì¤‘ë³µ ì œê±°"""
    current_key = None
    data_bucket = []

    for line in sys.stdin:
        key, value = line.strip().split('\t', 1)

        if current_key != key:
            if current_key:
                # ì´ì „ í‚¤ ë°ì´í„° ì²˜ë¦¬
                deduplicated = remove_duplicates(data_bucket)
                print(json.dumps({
                    'key': current_key,
                    'count': len(deduplicated),
                    'data': deduplicated
                }))

            current_key = key
            data_bucket = []

        data_bucket.append(json.loads(value))

    # ë§ˆì§€ë§‰ í‚¤ ì²˜ë¦¬
    if current_key:
        deduplicated = remove_duplicates(data_bucket)
        print(json.dumps({
            'key': current_key,
            'count': len(deduplicated),
            'data': deduplicated
        }))

def remove_duplicates(data_list):
    """ì¤‘ë³µ ì œê±° (URL ë˜ëŠ” ì œëª© ê¸°ì¤€)"""
    seen = set()
    unique = []

    for item in data_list:
        # ë‰´ìŠ¤ì˜ ê²½ìš° URLë¡œ ì¤‘ë³µ ì²´í¬
        if 'url' in item.get('data', {}):
            identifier = item['data']['url']
        # íŠ¸ë Œë“œì˜ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì²´í¬
        else:
            identifier = item['timestamp']

        if identifier not in seen:
            seen.add(identifier)
            unique.append(item)

    return unique

if __name__ == "__main__":
    reducer()

```

### **Scrapyd ìŠ¤ì¼€ì¤„ë§ ì„¤ì •**

```python
# scheduler.py (ë¼ì¦ˆë² ë¦¬íŒŒì´ Master Node)
import schedule
import time
from scrapyd_api import ScrapydAPI

scrapyd = ScrapydAPI('http://localhost:6800')

def schedule_crawlers():
    """í¬ë¡¤ë§ ì‘ì—… ì£¼ê¸°ë³„ ì‹¤í–‰"""

    # 5ë¶„ë§ˆë‹¤: ì‹¤ì‹œê°„ ë°ì´í„°
    schedule.every(5).minutes.do(lambda: scrapyd.schedule('crypto', 'upbit_trends'))
    schedule.every(5).minutes.do(lambda: scrapyd.schedule('crypto', 'saveticker'))

    # 10ë¶„ë§ˆë‹¤: ë‰´ìŠ¤
    schedule.every(10).minutes.do(lambda: scrapyd.schedule('crypto', 'coinness_news'))

    # 1ì‹œê°„ë§ˆë‹¤: AI ë¶„ì„
    schedule.every(1).hours.do(lambda: scrapyd.schedule('crypto', 'perplexity_finance'))

    # ë§¤ì¼ 1íšŒ: ê³µí¬Â·íƒìš• ì§€ìˆ˜
    schedule.every().day.at("00:00").do(lambda: scrapyd.schedule('crypto', 'cnn_fear_greed'))

    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    schedule_crawlers()

```

---

## ğŸ’¾ **5. ì™¸ë¶€ ì„œë²„ ë°ì´í„° ì²˜ë¦¬**

### **5.1 HDFS â†’ ì™¸ë¶€ ì„œë²„ ì „ì†¡**

```python
# external_server/data_fetcher.py
import subprocess
import os
from datetime import datetime

class HDFSFetcher:
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ HDFSì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""

    def __init__(self, hdfs_host='raspberry-master', hdfs_port=9000):
        self.hdfs_host = hdfs_host
        self.hdfs_port = hdfs_port

    def fetch_cleaned_data(self, date=None):
        """ì •ì œëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        if not date:
            date = datetime.now().strftime('%Y%m%d')

        remote_path = f"/cleaned/{date}/"
        local_path = f"./data/raw/{date}/"

        # HDFSì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        cmd = f"hdfs dfs -get {remote_path} {local_path}"
        result = subprocess.run(cmd, shell=True, capture_output=True)

        if result.returncode == 0:
            print(f"âœ“ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
            return local_path
        else:
            print(f"âœ— ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            return None

    def fetch_via_rest_api(self):
        """REST APIë¥¼ í†µí•œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ëŒ€ì•ˆ)"""
        import requests

        api_url = f"http://{self.hdfs_host}:50070/webhdfs/v1/cleaned/?op=LISTSTATUS"
        response = requests.get(api_url)

        if response.status_code == 200:
            files = response.json()['FileStatuses']['FileStatus']
            return files
        else:
            return None

```

### **5.2 MariaDB ë°ì´í„°ë² ì´ìŠ¤ ì ì¬**

```sql
-- ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” êµ¬ì¡°

-- 1. ì›ì‹œ ë‰´ìŠ¤ í…Œì´ë¸”
CREATE TABLE raw_news (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source VARCHAR(50) NOT NULL,
    title TEXT NOT NULL,
    url TEXT,
    published_at DATETIME,
    keywords JSON,
    collected_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    INDEX(source, published_at)
);

-- 2. ì‹œì¥ íŠ¸ë Œë“œ í…Œì´ë¸”
CREATE TABLE market_trends (
    id INT AUTO_INCREMENT PRIMARY KEY,
    source VARCHAR(50),
    symbol VARCHAR(20),
    volume_24h DECIMAL(20, 2),
    price DECIMAL(15, 2),
    change_24h DECIMAL(5, 2),
    timestamp DATETIME,
    INDEX(symbol, timestamp)
);

-- 3. ê°ì„± ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
CREATE TABLE sentiment_analysis (
    id INT AUTO_INCREMENT PRIMARY KEY,
    news_id INT,
    sentiment_score DECIMAL(4, 2), -- -1.0 ~ 1.0
    sentiment_label VARCHAR(20), -- positive/negative/neutral
    confidence DECIMAL(3, 2),
    analyzed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (news_id) REFERENCES raw_news(id)
);

-- 4. ê¸°ìˆ ì  ì§€í‘œ í…Œì´ë¸”
CREATE TABLE technical_indicators (
    id INT AUTO_INCREMENT PRIMARY KEY,
    symbol VARCHAR(20),
    timestamp DATETIME,
    rsi DECIMAL(5, 2),
    macd DECIMAL(10, 4),
    macd_signal DECIMAL(10, 4),
    bb_upper DECIMAL(15, 2),
    bb_middle DECIMAL(15, 2),
    bb_lower DECIMAL(15, 2),
    volume DECIMAL(20, 2),
    INDEX(symbol, timestamp)
);

-- 5. ê³µí¬Â·íƒìš• ì§€ìˆ˜ í…Œì´ë¸”
CREATE TABLE fear_greed_index (
    id INT AUTO_INCREMENT PRIMARY KEY,
    value INT, -- 0-100
    classification VARCHAR(20), -- Extreme Fear ~ Extreme Greed
    timestamp DATE,
    UNIQUE(timestamp)
);

-- 6. ì•”í˜¸í™”í íŠ¹í™” ì¸ì‚¬ì´íŠ¸ í…Œì´ë¸”
CREATE TABLE crypto_insights (
    id INT AUTO_INCREMENT PRIMARY KEY,
    insight_type VARCHAR(50), -- trend_reversal, volume_spike, sentiment_shift
    symbol VARCHAR(20),
    description TEXT,
    severity VARCHAR(20), -- low/medium/high/critical
    related_news JSON,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    INDEX(symbol, created_at)
);

```

```python
# external_server/db_loader.py
import mysql.connector
import json
from datetime import datetime

class DataLoader:
    """MariaDBì— ë°ì´í„° ì ì¬"""

    def __init__(self, db_config):
        self.db_config = db_config

    def load_news(self, news_data):
        """ë‰´ìŠ¤ ë°ì´í„° ì ì¬"""
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor()

        query = """
        INSERT INTO raw_news (source, title, url, published_at, keywords)
        VALUES (%s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE title=title
        """

        for article in news_data:
            values = (
                article['source'],
                article['title'],
                article.get('url'),
                article.get('published'),
                json.dumps(article.get('keywords', []))
            )
            cursor.execute(query, values)

        conn.commit()
        cursor.close()
        conn.close()
        print(f"âœ“ {len(news_data)}ê°œ ë‰´ìŠ¤ ì ì¬ ì™„ë£Œ")

    def load_market_trends(self, trend_data):
        """ì‹œì¥ íŠ¸ë Œë“œ ë°ì´í„° ì ì¬"""
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor()

        query = """
        INSERT INTO market_trends (source, symbol, volume_24h, price, change_24h, timestamp)
        VALUES (%s, %s, %s, %s, %s, %s)
        """

        for trend in trend_data:
            values = (
                trend['source'],
                trend['symbol'],
                trend['volume_24h'],
                trend['price'],
                trend['change_24h'],
                trend['timestamp']
            )
            cursor.execute(query, values)

        conn.commit()
        cursor.close()
        conn.close()
        print(f"âœ“ {len(trend_data)}ê°œ íŠ¸ë Œë“œ ì ì¬ ì™„ë£Œ")

```

### **5.3 NLP ê°ì„± ë¶„ì„**

```python
# external_server/sentiment_analyzer.py
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import mysql.connector

class CryptoSentimentAnalyzer:
    """ì•”í˜¸í™”í ë‰´ìŠ¤ ê°ì„± ë¶„ì„"""

    def __init__(self, model_name='ProsusAI/finbert'):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)

    def analyze_news(self, news_id, text):
        """ë‹¨ì¼ ë‰´ìŠ¤ ê°ì„± ë¶„ì„"""
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=1)

        # FinBERT: [positive, negative, neutral]
        sentiment_map = {0: 'positive', 1: 'negative', 2: 'neutral'}
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()

        # ì ìˆ˜ ê³„ì‚° (-1.0 ~ 1.0)
        if sentiment_map[predicted_class] == 'positive':
            score = confidence
        elif sentiment_map[predicted_class] == 'negative':
            score = -confidence
        else:
            score = 0.0

        return {
            'news_id': news_id,
            'sentiment_score': round(score, 2),
            'sentiment_label': sentiment_map[predicted_class],
            'confidence': round(confidence, 2)
        }

    def batch_analyze(self, db_config):
        """DBì˜ ëª¨ë“  ë¯¸ë¶„ì„ ë‰´ìŠ¤ ì²˜ë¦¬"""
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor(dictionary=True)

        # ë¯¸ë¶„ì„ ë‰´ìŠ¤ ì¡°íšŒ
        cursor.execute("""
            SELECT n.id, n.title
            FROM raw_news n
            LEFT JOIN sentiment_analysis s ON n.id = s.news_id
            WHERE s.id IS NULL
            LIMIT 100
        """)

        news_list = cursor.fetchall()

        for news in news_list:
            result = self.analyze_news(news['id'], news['title'])

            # ê°ì„± ë¶„ì„ ê²°ê³¼ ì €ì¥
            insert_query = """
            INSERT INTO sentiment_analysis (news_id, sentiment_score, sentiment_label, confidence)
            VALUES (%s, %s, %s, %s)
            """
            cursor.execute(insert_query, (
                result['news_id'],
                result['sentiment_score'],
                result['sentiment_label'],
                result['confidence']
            ))

        conn.commit()
        cursor.close()
        conn.close()
        print(f"âœ“ {len(news_list)}ê°œ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ì™„ë£Œ")

```

### **5.4 ì•”í˜¸í™”í íŠ¹í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±**

```python
# external_server/insight_generator.py
import mysql.connector
from datetime import datetime, timedelta

class CryptoInsightGenerator:
    """ì•”í˜¸í™”í ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±"""

    def __init__(self, db_config):
        self.db_config = db_config

    def detect_sentiment_shift(self):
        """ê°ì„± ê¸‰ë³€ ê°ì§€ (24ì‹œê°„ ë‚´ Â±30% ë³€í™”)"""
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        query = """
        SELECT
            symbol,
            AVG(CASE WHEN timestamp >= NOW() - INTERVAL 6 HOUR
                THEN sentiment_score ELSE NULL END) as recent_sentiment,
            AVG(CASE WHEN timestamp >= NOW() - INTERVAL 24 HOUR
                AND timestamp < NOW() - INTERVAL 6 HOUR
                THEN sentiment_score ELSE NULL END) as past_sentiment
        FROM (
            SELECT
                'BTC' as symbol,
                s.sentiment_score,
                n.published_at as timestamp
            FROM raw_news n
            JOIN sentiment_analysis s ON n.id = s.news_id
            WHERE n.keywords LIKE '%Bitcoin%'
            AND n.published_at >= NOW() - INTERVAL 24 HOUR
        ) as sentiment_data
        GROUP BY symbol
        """

        cursor.execute(query)
        results = cursor.fetchall()

        insights = []
        for row in results:
            if row['recent_sentiment'] and row['past_sentiment']:
                change = (row['recent_sentiment'] - row['past_sentiment']) / abs(row['past_sentiment']) * 100

                if abs(change) >= 30:
                    insight = {
                        'insight_type': 'sentiment_shift',
                        'symbol': row['symbol'],
                        'description': f"{row['symbol']} ê°ì„± {change:+.1f}% ê¸‰ë³€ ê°ì§€ (ìµœê·¼ 6ì‹œê°„ vs ì´ì „ 18ì‹œê°„)",
                        'severity': 'high' if abs(change) >= 50 else 'medium',
                        'related_news': []
                    }
                    insights.append(insight)

        # DB ì €ì¥
        self._save_insights(insights)

        cursor.close()
        conn.close()
        return insights

    def detect_volume_spike(self):
        """ê±°ë˜ëŸ‰ ê¸‰ì¦ ê°ì§€ (í‰ê·  ëŒ€ë¹„ 150% ì´ìƒ)"""
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        query = """
        SELECT
            symbol,
            MAX(volume_24h) as recent_volume,
            AVG(volume_24h) as avg_volume
        FROM market_trends
        WHERE timestamp >= NOW() - INTERVAL 7 DAY
        GROUP BY symbol
        HAVING MAX(volume_24h) > AVG(volume_24h) * 1.5
        """

        cursor.execute(query)
        results = cursor.fetchall()

        insights = []
        for row in results:
            spike_ratio = row['recent_volume'] / row['avg_volume']
            insight = {
                'insight_type': 'volume_spike',
                'symbol': row['symbol'],
                'description': f"{row['symbol']} ê±°ë˜ëŸ‰ {spike_ratio:.1f}ë°° ê¸‰ì¦ (7ì¼ í‰ê·  ëŒ€ë¹„)",
                'severity': 'critical' if spike_ratio >= 2.0 else 'high',
                'related_news': []
            }
            insights.append(insight)

        self._save_insights(insights)

        cursor.close()
        conn.close()
        return insights

    def detect_trend_reversal(self):
        """ì¶”ì„¸ ë°˜ì „ ê°ì§€ (RSI + MACD ë™ì‹œ ì‹ í˜¸)"""
        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor(dictionary=True)

        query = """
        SELECT
            symbol,
            rsi,
            macd,
            macd_signal
        FROM technical_indicators
        WHERE timestamp = (SELECT MAX(timestamp) FROM technical_indicators)
        """

        cursor.execute(query)
        results = cursor.fetchall()

        insights = []
        for row in results:
            # RSI ê³¼ë§¤ë„ + MACD ê³¨ë“ í¬ë¡œìŠ¤
            if row['rsi'] < 30 and row['macd'] > row['macd_signal']:
                insight = {
                    'insight_type': 'trend_reversal',
                    'symbol': row['symbol'],
                    'description': f"{row['symbol']} ë°˜ë“± ì‹ í˜¸ (RSI {row['rsi']:.1f}, MACD ê³¨ë“ í¬ë¡œìŠ¤)",
                    'severity': 'high',
                    'related_news': []
                }
                insights.append(insight)

            # RSI ê³¼ë§¤ìˆ˜ + MACD ë°ë“œí¬ë¡œìŠ¤
            elif row['rsi'] > 70 and row['macd'] < row['macd_signal']:
                insight = {
                    'insight_type': 'trend_reversal',
                    'symbol': row['symbol'],
                    'description': f"{row['symbol']} í•˜ë½ ì‹ í˜¸ (RSI {row['rsi']:.1f}, MACD ë°ë“œí¬ë¡œìŠ¤)",
                    'severity': 'high',
                    'related_news': []
                }
                insights.append(insight)

        self._save_insights(insights)

        cursor.close()
        conn.close()
        return insights

    def _save_insights(self, insights):
        """ì¸ì‚¬ì´íŠ¸ DB ì €ì¥"""
        if not insights:
            return

        conn = mysql.connector.connect(**self.db_config)
        cursor = conn.cursor()

        query = """
        INSERT INTO crypto_insights (insight_type, symbol, description, severity, related_news)
        VALUES (%s, %s, %s, %s, %s)
        """

        for insight in insights:
            cursor.execute(query, (
                insight['insight_type'],
                insight['symbol'],
                insight['description'],
                insight['severity'],
                json.dumps(insight['related_news'])
            ))

        conn.commit()
        cursor.close()
        conn.close()

```

---

## ğŸ“Š **6. ëŒ€ì‹œë³´ë“œ ì‹œìŠ¤í…œ (Flask + React)**

### **6.1 Backend API (Flask)**

```python
# external_server/api/app.py
from flask import Flask, jsonify, request
from flask_cors import CORS
import mysql.connector
from datetime import datetime, timedelta

app = Flask(__name__)
CORS(app)

DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'your_password',
    'database': 'cointicker'
}

@app.route('/api/dashboard/summary', methods=['GET'])
def get_dashboard_summary():
    """ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì •ë³´"""
    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = cursor(dictionary=True)

    # ìµœì‹  ê³µí¬Â·íƒìš• ì§€ìˆ˜
    cursor.execute("""
        SELECT value, classification
        FROM fear_greed_index
        ORDER BY timestamp DESC
        LIMIT 1
    """)
    fear_greed = cursor.fetchone()

    # ìµœê·¼ 24ì‹œê°„ ê°ì„± í‰ê· 
    cursor.execute("""
        SELECT AVG(sentiment_score) as avg_sentiment
        FROM sentiment_analysis
        WHERE analyzed_at >= NOW() - INTERVAL 24 HOUR
    """)
    sentiment = cursor.fetchone()

    # ê±°ë˜ëŸ‰ Top 5
    cursor.execute("""
        SELECT symbol, volume_24h, change_24h
        FROM market_trends
        WHERE timestamp >= NOW() - INTERVAL 1 HOUR
        ORDER BY volume_24h DESC
        LIMIT 5
    """)
    top_volume = cursor.fetchall()

    # ìµœì‹  ì¸ì‚¬ì´íŠ¸
    cursor.execute("""
        SELECT insight_type, symbol, description, severity
        FROM crypto_insights
        ORDER BY created_at DESC
        LIMIT 10
    """)
    insights = cursor.fetchall()

    cursor.close()
    conn.close()

    return jsonify({
        'fear_greed_index': fear_

```

```python
        'fear_greed_index': fear_greed,
        'sentiment_average': round(sentiment['avg_sentiment'], 2) if sentiment['avg_sentiment'] else 0,
        'top_volume_coins': top_volume,
        'latest_insights': insights
    })

@app.route('/api/charts/sentiment-timeline', methods=['GET'])
def get_sentiment_timeline():
    """ì‹œê°„ëŒ€ë³„ ê°ì„± ì¶”ì´"""
    hours = request.args.get('hours', 24, type=int)

    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = conn.cursor(dictionary=True)

    query = """
    SELECT
        DATE_FORMAT(n.published_at, '%Y-%m-%d %H:00:00') as hour,
        AVG(s.sentiment_score) as avg_sentiment,
        COUNT(*) as news_count
    FROM raw_news n
    JOIN sentiment_analysis s ON n.id = s.news_id
    WHERE n.published_at >= NOW() - INTERVAL %s HOUR
    GROUP BY hour
    ORDER BY hour
    """

    cursor.execute(query, (hours,))
    results = cursor.fetchall()

    cursor.close()
    conn.close()

    return jsonify({
        'timeline': [
            {
                'timestamp': row['hour'],
                'sentiment': round(row['avg_sentiment'], 2),
                'count': row['news_count']
            }
            for row in results
        ]
    })

@app.route('/api/charts/technical-indicators/<symbol>', methods=['GET'])
def get_technical_indicators(symbol):
    """íŠ¹ì • ì½”ì¸ì˜ ê¸°ìˆ ì  ì§€í‘œ"""
    hours = request.args.get('hours', 24, type=int)

    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = conn.cursor(dictionary=True)

    query = """
    SELECT
        timestamp,
        rsi,
        macd,
        macd_signal,
        bb_upper,
        bb_middle,
        bb_lower,
        volume
    FROM technical_indicators
    WHERE symbol = %s
    AND timestamp >= NOW() - INTERVAL %s HOUR
    ORDER BY timestamp
    """

    cursor.execute(query, (symbol, hours))
    results = cursor.fetchall()

    cursor.close()
    conn.close()

    return jsonify({
        'symbol': symbol,
        'indicators': [
            {
                'timestamp': row['timestamp'].isoformat(),
                'rsi': float(row['rsi']) if row['rsi'] else None,
                'macd': {
                    'value': float(row['macd']) if row['macd'] else None,
                    'signal': float(row['macd_signal']) if row['macd_signal'] else None
                },
                'bollinger': {
                    'upper': float(row['bb_upper']) if row['bb_upper'] else None,
                    'middle': float(row['bb_middle']) if row['bb_middle'] else None,
                    'lower': float(row['bb_lower']) if row['bb_lower'] else None
                },
                'volume': float(row['volume']) if row['volume'] else None
            }
            for row in results
        ]
    })

@app.route('/api/insights/recent', methods=['GET'])
def get_recent_insights():
    """ìµœì‹  ì¸ì‚¬ì´íŠ¸ ëª©ë¡"""
    limit = request.args.get('limit', 20, type=int)
    severity = request.args.get('severity', None, type=str)

    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = conn.cursor(dictionary=True)

    query = """
    SELECT
        insight_type,
        symbol,
        description,
        severity,
        created_at
    FROM crypto_insights
    WHERE 1=1
    """
    params = []

    if severity:
        query += " AND severity = %s"
        params.append(severity)

    query += " ORDER BY created_at DESC LIMIT %s"
    params.append(limit)

    cursor.execute(query, params)
    results = cursor.fetchall()

    cursor.close()
    conn.close()

    return jsonify({
        'insights': [
            {
                'type': row['insight_type'],
                'symbol': row['symbol'],
                'description': row['description'],
                'severity': row['severity'],
                'timestamp': row['created_at'].isoformat()
            }
            for row in results
        ]
    })

@app.route('/api/news/latest', methods=['GET'])
def get_latest_news():
    """ìµœì‹  ë‰´ìŠ¤ + ê°ì„± ì ìˆ˜"""
    limit = request.args.get('limit', 50, type=int)

    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = conn.cursor(dictionary=True)

    query = """
    SELECT
        n.id,
        n.source,
        n.title,
        n.url,
        n.published_at,
        s.sentiment_score,
        s.sentiment_label
    FROM raw_news n
    LEFT JOIN sentiment_analysis s ON n.id = s.news_id
    ORDER BY n.published_at DESC
    LIMIT %s
    """

    cursor.execute(query, (limit,))
    results = cursor.fetchall()

    cursor.close()
    conn.close()

    return jsonify({
        'news': [
            {
                'id': row['id'],
                'source': row['source'],
                'title': row['title'],
                'url': row['url'],
                'published_at': row['published_at'].isoformat(),
                'sentiment': {
                    'score': float(row['sentiment_score']) if row['sentiment_score'] else None,
                    'label': row['sentiment_label']
                }
            }
            for row in results
        ]
    })

@app.route('/api/trending/searches', methods=['GET'])
def get_trending_searches():
    """ì¸ê¸° ê²€ìƒ‰ì–´ (Upbit Trends)"""
    conn = mysql.connector.connect(**DB_CONFIG)
    cursor = conn.cursor(dictionary=True)

    # ìµœê·¼ ìˆ˜ì§‘ëœ Upbit íŠ¸ë Œë“œì—ì„œ ê²€ìƒ‰ì–´ ì¶”ì¶œ
    query = """
    SELECT keywords
    FROM raw_news
    WHERE source = 'upbit'
    AND collected_at >= NOW() - INTERVAL 1 HOUR
    ORDER BY collected_at DESC
    LIMIT 1
    """

    cursor.execute(query)
    result = cursor.fetchone()

    cursor.close()
    conn.close()

    if result and result['keywords']:
        import json
        keywords = json.loads(result['keywords'])
        return jsonify({'trending_searches': keywords})
    else:
        return jsonify({'trending_searches': []})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)

```

### **6.2 Frontend Dashboard (React)**

```jsx
// external_server/frontend/src/App.js
import React, { useState, useEffect } from 'react';
import axios from 'axios';
import {
  LineChart, Line, BarChart, Bar, XAxis, YAxis,
  CartesianGrid, Tooltip, Legend, ResponsiveContainer
} from 'recharts';
import './App.css';

const API_BASE = 'http://localhost:5000/api';

function App() {
  const [summary, setSummary] = useState(null);
  const [sentimentTimeline, setSentimentTimeline] = useState([]);
  const [insights, setInsights] = useState([]);
  const [news, setNews] = useState([]);
  const [selectedCoin, setSelectedCoin] = useState('BTCUSDT');
  const [technicalData, setTechnicalData] = useState([]);

  useEffect(() => {
    fetchDashboardData();
    const interval = setInterval(fetchDashboardData, 60000); // 1ë¶„ë§ˆë‹¤ ì—…ë°ì´íŠ¸
    return () => clearInterval(interval);
  }, []);

  useEffect(() => {
    fetchTechnicalIndicators(selectedCoin);
  }, [selectedCoin]);

  const fetchDashboardData = async () => {
    try {
      const [summaryRes, sentimentRes, insightsRes, newsRes] = await Promise.all([
        axios.get(`${API_BASE}/dashboard/summary`),
        axios.get(`${API_BASE}/charts/sentiment-timeline?hours=24`),
        axios.get(`${API_BASE}/insights/recent?limit=10`),
        axios.get(`${API_BASE}/news/latest?limit=20`)
      ]);

      setSummary(summaryRes.data);
      setSentimentTimeline(sentimentRes.data.timeline);
      setInsights(insightsRes.data.insights);
      setNews(newsRes.data.news);
    } catch (error) {
      console.error('ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨:', error);
    }
  };

  const fetchTechnicalIndicators = async (symbol) => {
    try {
      const response = await axios.get(
        `${API_BASE}/charts/technical-indicators/${symbol}?hours=24`
      );
      setTechnicalData(response.data.indicators);
    } catch (error) {
      console.error('ê¸°ìˆ ì  ì§€í‘œ ë¡œë“œ ì‹¤íŒ¨:', error);
    }
  };

  const getSeverityColor = (severity) => {
    const colors = {
      critical: '#dc3545',
      high: '#fd7e14',
      medium: '#ffc107',
      low: '#28a745'
    };
    return colors[severity] || '#6c757d';
  };

  const getSentimentColor = (score) => {
    if (score > 0.3) return '#28a745'; // ê¸ì •
    if (score < -0.3) return '#dc3545'; // ë¶€ì •
    return '#6c757d'; // ì¤‘ë¦½
  };

  if (!summary) {
    return <div className="loading">ë°ì´í„° ë¡œë”© ì¤‘...</div>;
  }

  return (
    <div className="App">
      <header className="dashboard-header">
        <h1>ğŸª™ ì½”ì¸í‹°ì»¤ (CoinTicker)</h1>
        <p>ì‹¤ì‹œê°„ ì•”í˜¸í™”í ì‹œì¥ ë™í–¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ</p>
      </header>

      {/* ìš”ì•½ íŒ¨ë„ */}
      <div className="summary-panel">
        <div className="summary-card">
          <h3>ê³µí¬Â·íƒìš• ì§€ìˆ˜</h3>
          <div className="fear-greed-value">
            {summary.fear_greed_index?.value || 'N/A'}
          </div>
          <div className="fear-greed-label">
            {summary.fear_greed_index?.classification || 'N/A'}
          </div>
        </div>

        <div className="summary-card">
          <h3>24ì‹œê°„ í‰ê·  ê°ì„±</h3>
          <div
            className="sentiment-value"
            style={{ color: getSentimentColor(summary.sentiment_average) }}
          >
            {summary.sentiment_average > 0 ? '+' : ''}
            {summary.sentiment_average}
          </div>
          <div className="sentiment-label">
            {summary.sentiment_average > 0.3 ? 'ê¸ì •' :
             summary.sentiment_average < -0.3 ? 'ë¶€ì •' : 'ì¤‘ë¦½'}
          </div>
        </div>

        <div className="summary-card wide">
          <h3>ê±°ë˜ëŸ‰ Top 5</h3>
          <table className="top-volume-table">
            <thead>
              <tr>
                <th>ì½”ì¸</th>
                <th>24h ê±°ë˜ëŸ‰</th>
                <th>24h ë³€ë™</th>
              </tr>
            </thead>
            <tbody>
              {summary.top_volume_coins.map((coin, idx) => (
                <tr key={idx}>
                  <td>{coin.symbol}</td>
                  <td>${(coin.volume_24h / 1e9).toFixed(2)}B</td>
                  <td style={{ color: coin.change_24h >= 0 ? '#28a745' : '#dc3545' }}>
                    {coin.change_24h >= 0 ? '+' : ''}{coin.change_24h}%
                  </td>
                </tr>
              ))}
            </tbody>
          </table>
        </div>
      </div>

      {/* ì°¨íŠ¸ ì„¹ì…˜ */}
      <div className="charts-section">
        <div className="chart-container">
          <h2>24ì‹œê°„ ê°ì„± ì¶”ì´</h2>
          <ResponsiveContainer width="100%" height={300}>
            <LineChart data={sentimentTimeline}>
              <CartesianGrid strokeDasharray="3 3" />
              <XAxis
                dataKey="timestamp"
                tickFormatter={(value) => new Date(value).getHours() + ':00'}
              />
              <YAxis domain={[-1, 1]} />
              <Tooltip />
              <Legend />
              <Line
                type="monotone"
                dataKey="sentiment"
                stroke="#8884d8"
                name="ê°ì„± ì ìˆ˜"
              />
              <Line
                type="monotone"
                dataKey="count"
                stroke="#82ca9d"
                name="ë‰´ìŠ¤ ê°œìˆ˜"
                yAxisId="right"
              />
            </LineChart>
          </ResponsiveContainer>
        </div>

        <div className="chart-container">
          <h2>ê¸°ìˆ ì  ì§€í‘œ - {selectedCoin}</h2>
          <div className="coin-selector">
            <button onClick={() => setSelectedCoin('BTCUSDT')}>BTC</button>
            <button onClick={() => setSelectedCoin('ETHUSDT')}>ETH</button>
            <button onClick={() => setSelectedCoin('BNBUSDT')}>BNB</button>
          </div>
          <ResponsiveContainer width="100%" height={300}>
            <LineChart data={technicalData}>
              <CartesianGrid strokeDasharray="3 3" />
              <XAxis
                dataKey="timestamp"
                tickFormatter={(value) => new Date(value).getHours() + ':00'}
              />
              <YAxis />
              <Tooltip />
              <Legend />
              <Line type="monotone" dataKey="rsi" stroke="#ff7300" name="RSI" />
              <Line type="monotone" dataKey="macd.value" stroke="#387908" name="MACD" />
            </LineChart>
          </ResponsiveContainer>
        </div>
      </div>

      {/* ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜ */}
      <div className="insights-section">
        <h2>ğŸ” ìµœì‹  ì¸ì‚¬ì´íŠ¸</h2>
        <div className="insights-grid">
          {insights.map((insight, idx) => (
            <div
              key={idx}
              className="insight-card"
              style={{ borderLeft: `4px solid ${getSeverityColor(insight.severity)}` }}
            >
              <div className="insight-header">
                <span className="insight-type">{insight.type}</span>
                <span className="insight-symbol">{insight.symbol}</span>
              </div>
              <div className="insight-description">{insight.description}</div>
              <div className="insight-footer">
                <span
                  className="insight-severity"
                  style={{ backgroundColor: getSeverityColor(insight.severity) }}
                >
                  {insight.severity.toUpperCase()}
                </span>
                <span className="insight-time">
                  {new Date(insight.timestamp).toLocaleString()}
                </span>
              </div>
            </div>
          ))}
        </div>
      </div>

      {/* ë‰´ìŠ¤ í”¼ë“œ */}
      <div className="news-section">
        <h2>ğŸ“° ìµœì‹  ë‰´ìŠ¤</h2>
        <div className="news-list">
          {news.map((article) => (
            <div key={article.id} className="news-item">
              <div className="news-header">
                <span className="news-source">{article.source}</span>
                {article.sentiment.score !== null && (
                  <span
                    className="news-sentiment"
                    style={{
                      backgroundColor: getSentimentColor(article.sentiment.score),
                      color: 'white',
                      padding: '2px 8px',
                      borderRadius: '4px',
                      fontSize: '0.85rem'
                    }}
                  >
                    {article.sentiment.label} ({article.sentiment.score.toFixed(2)})
                  </span>
                )}
              </div>
              <div className="news-title">
                <a href={article.url} target="_blank" rel="noopener noreferrer">
                  {article.title}
                </a>
              </div>
              <div className="news-time">
                {new Date(article.published_at).toLocaleString()}
              </div>
            </div>
          ))}
        </div>
      </div>
    </div>
  );
}

export default App;

```

### **6.3 CSS ìŠ¤íƒ€ì¼**

```css
/* external_server/frontend/src/App.css */
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
  background: #f5f7fa;
  color: #333;
}

.App {
  max-width: 1400px;
  margin: 0 auto;
  padding: 20px;
}

.dashboard-header {
  text-align: center;
  margin-bottom: 30px;
  padding: 20px;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border-radius: 10px;
}

.dashboard-header h1 {
  font-size: 2.5rem;
  margin-bottom: 10px;
}

.summary-panel {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 20px;
  margin-bottom: 30px;
}

.summary-card {
  background: white;
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
  text-align: center;
}

.summary-card.wide {
  grid-column: span 2;
}

.fear-greed-value {
  font-size: 3rem;
  font-weight: bold;
  margin: 15px 0;
  color: #667eea;
}

.sentiment-value {
  font-size: 2.5rem;
  font-weight: bold;
  margin: 15px 0;
}

.top-volume-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 10px;
}

.top-volume-table th,
.top-volume-table td {
  padding: 10px;
  text-align: left;
  border-bottom: 1px solid #eee;
}

.charts-section {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));
  gap: 20px;
  margin-bottom: 30px;
}

.chart-container {
  background: white;
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.coin-selector {
  margin: 15px 0;
  display: flex;
  gap: 10px;
}

.coin-selector button {
  padding: 8px 16px;
  border: none;
  background: #667eea;
  color: white;
  border-radius: 5px;
  cursor: pointer;
  transition: background 0.3s;
}

.coin-selector button:hover {
  background: #5568d3;
}

.insights-section {
  margin-bottom: 30px;
}

.insights-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(350px, 1fr));
  gap: 15px;
  margin-top: 15px;
}

.insight-card {
  background: white;
  padding: 15px;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.1);
}

.insight-header {
  display: flex;
  justify-content: space-between;
  margin-bottom: 10px;
}

.insight-type {
  font-size: 0.85rem;
  color: #666;
  text-transform: uppercase;
}

.insight-symbol {
  font-weight: bold;
  color: #667eea;
}

.insight-description {
  margin: 10px 0;
  line-height: 1.5;
}

.insight-footer {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-top: 10px;
}

.insight-severity {
  padding: 4px 10px;
  border-radius: 4px;
  color: white;
  font-size: 0.75rem;
  font-weight: bold;
}

.insight-time {
  font-size: 0.85rem;
  color: #999;
}

.news-section {
  background: white;
  padding: 20px;
  border-radius: 10px;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

.news-list {
  margin-top: 15px;
}

.news-item {
  padding: 15px;
  border-bottom: 1px solid #eee;
}

.news-item:last-child {
  border-bottom: none;
}

.news-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 8px;
}

.news-source {
  font-size: 0.85rem;
  color: #667eea;
  font-weight: 600;
  text-transform: uppercase;
}

.news-title a {
  color: #333;
  text-decoration: none;
  font-size: 1.05rem;
  line-height: 1.5;
}

.news-title a:hover {
  color: #667eea;
}

.news-time {
  font-size: 0.85rem;
  color: #999;
  margin-top: 5px;
}

.loading {
  text-align: center;
  padding: 50px;
  font-size: 1.5rem;
  color: #667eea;
}

@media (max-width: 768px) {
  .summary-card.wide {
    grid-column: span 1;
  }

  .charts-section {
    grid-template-columns: 1fr;
  }

  .insights-grid {
    grid-template-columns: 1fr;
  }
}

```

---

## ğŸ”„ **7. ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìë™í™”**

### **7.1 í†µí•© ìŠ¤ì¼€ì¤„ëŸ¬ (ì™¸ë¶€ ì„œë²„)**

```python
# external_server/scheduler/main_scheduler.py
import schedule
import time
from data_fetcher import HDFSFetcher
from db_loader import DataLoader
from sentiment_analyzer import CryptoSentimentAnalyzer
from insight_generator import CryptoInsightGenerator
import json
import os

DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'your_password',
    'database': 'cointicker'
}

class CoinTickerPipeline:
    """ì½”ì¸í‹°ì»¤ ì „ì²´ íŒŒì´í”„ë¼ì¸ ìë™í™”"""

    def __init__(self):
        self.hdfs_fetcher = HDFSFetcher(hdfs_host='raspberry-master')
        self.db_loader = DataLoader(DB_CONFIG)
        self.sentiment_analyzer = CryptoSentimentAnalyzer()
        self.insight_generator = CryptoInsightGenerator(DB_CONFIG)

    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print(f"{'='*60}\n")

        try:
            # Step 1: HDFSì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            print("Step 1: HDFS ë°ì´í„° fetch...")
            data_path = self.hdfs_fetcher.fetch_cleaned_data()

            if not data_path:
                print("âœ— ë°ì´í„° fetch ì‹¤íŒ¨")
                return

            # Step 2: JSON íŒŒì¼ íŒŒì‹± ë° DB ì ì¬
            print("\nStep 2: ë°ì´í„° íŒŒì‹± ë° DB ì ì¬...")
            self._load_data_to_db(data_path)

            # Step 3: NLP ê°ì„± ë¶„ì„
            print("\nStep 3: NLP ê°ì„± ë¶„ì„...")
            self.sentiment_analyzer.batch_analyze(DB_CONFIG)

            # Step 4: ì¸ì‚¬ì´íŠ¸ ìƒì„±
            print("\nStep 4: ì¸ì‚¬ì´íŠ¸ ìƒì„±...")
            sentiment_insights = self.insight_generator.detect_sentiment_shift()
            volume_insights = self.insight_generator.detect_volume_spike()
            trend_insights = self.insight_generator.detect_trend_reversal()

            total_insights = len(sentiment_insights) + len(volume_insights) + len(trend_insights)
            print(f"âœ“ {total_insights}ê°œ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")

            # Step 5: ì•Œë¦¼ ë°œì†¡ (Critical ì¸ì‚¬ì´íŠ¸ë§Œ)
            print("\nStep 5: ì•Œë¦¼ ë°œì†¡...")
            self._send_alerts(sentiment_insights + volume_insights + trend_insights)

            print(f"\n{'='*60}")
            print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            print(f"{'='*60}\n")

        except Exception as e:
            print(f"âœ— íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")

    def _load_data_to_db(self, data_path):
        """JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ DBì— ì ì¬"""
        news_data = []
        trend_data = []

        # JSON íŒŒì¼ ì½ê¸°
        for filename in os.listdir(data_path):
            if not filename.endswith('.json'):
                continue

            with open(os.path.join(data_path, filename), 'r', encoding='utf-8') as f:
                try:
                    data = json.load(f)

                    # ë°ì´í„° íƒ€ì…ë³„ ë¶„ë¥˜
                    if data.get('source') in ['coinness', 'perplexity']:
                        # ë‰´ìŠ¤ ë°ì´í„°
                        for article in data.get('articles', []):
                            news_data.append(article)

                    elif data.get('source') in ['upbit', 'saveticker']:
                        # íŠ¸ë Œë“œ/ì‹œì¥ ë°ì´í„°
                        for trend in data.get('top_volume', []):
                            trend_data.append({
                                'source': data['source'],
                                **trend,
                                'timestamp': data['timestamp']
                            })

                except json.JSONDecodeError:
                    continue

        # DB ì ì¬
        if news_data:
            self.db_loader.load_news(news_data)
        if trend_data:
            self.db_loader.load_market_trends(trend_data)

    def _send_alerts(self, insights):
        """Critical ì¸ì‚¬ì´íŠ¸ ì•Œë¦¼ ë°œì†¡"""
        critical_insights = [i for i in insights if i['severity'] == 'critical']

        if not critical_insights:
            print("ë°œì†¡í•  Critical ì•Œë¦¼ ì—†ìŒ")
            return

        # ì´ë©”ì¼/Slack ì•Œë¦¼
        from alert_notifier import AlertNotifier
        notifier = AlertNotifier(
            email_config={...},
            slack_webhook='https://...'
        )

        for insight in critical_insights:
            message = f"""
ğŸš¨ ê¸´ê¸‰ ì•Œë¦¼: {insight['symbol']}

ìœ í˜•: {insight['insight_type']}
ì„¤ëª…: {insight['description']}
ì‹¬ê°ë„: {insight['severity'].upper()}
            """
            notifier.send_email("ì½”ì¸í‹°ì»¤ ê¸´ê¸‰ ì•Œë¦¼", message)
            notifier.send_slack(message)

        print(f"âœ“ {len(critical_insights)}ê°œ ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")

def main():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸"""
    pipeline = CoinTickerPipeline()

    # ìŠ¤ì¼€ì¤„ ë“±ë¡
    schedule.every(30).minutes.do(pipeline.run_full_pipeline)  # 30ë¶„ë§ˆë‹¤ ì „ì²´ íŒŒì´í”„ë¼ì¸

    # ì²« ì‹¤í–‰
    pipeline.run_full_pipeline()

    # ë¬´í•œ ë£¨í”„
    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    main()

```

---

## ğŸ“‹ **8. PPT 5ì¥ ìš”ì•½ (í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ)**

### **ìŠ¬ë¼ì´ë“œ 1: í”„ë¡œì íŠ¸ ê°œìš”**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ì½”ì¸í‹°ì»¤ (CoinTicker)
   ì•”í˜¸í™”í ì‹œì¥ ë™í–¥ ì‹¤ì‹œê°„ ë¶„ì„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í•µì‹¬ ëª©í‘œ
ì•”í˜¸í™”í ì‹œì¥ì˜ ë‰´ìŠ¤Â·ê°ì„±Â·ê¸°ìˆ  ì§€í‘œë¥¼ í†µí•© ë¶„ì„í•˜ì—¬
íˆ¬ììì—ê²Œ ìœ ì˜ë¯¸í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ

ìˆ˜ì§‘ ì†ŒìŠ¤
â€¢ Upbit Trends (ê±°ë˜ëŸ‰Â·ê²€ìƒ‰ì–´)
â€¢ Coinness (ë‰´ìŠ¤)
â€¢ SaveTicker/Yahoo (ê°€ê²©Â·ì§€í‘œ)
â€¢ Perplexity (AI ë¶„ì„)
â€¢ CNN Fear & Greed Index

ê¸°ëŒ€ íš¨ê³¼
ì •ë³´ ìˆ˜ì§‘ ì‹œê°„ 100% ì ˆê°
ì˜ì‚¬ê²°ì • ì†ë„ 75% í–¥ìƒ

```

### **ìŠ¬ë¼ì´ë“œ 2: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   2-Tier ë¶„ì‚°

```

êµ¬ì¡°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° (4ëŒ€)]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : ë°ì´í„° ìˆ˜ì§‘ & ì €ì¥ ì „ë‹´

- Scrapy: 5ê°œ ì‚¬ì´íŠ¸ ë³‘ë ¬ í¬ë¡¤ë§
â€¢ Hadoop HDFS: ë¶„ì‚° ì €ì¥
â€¢ MapReduce: ê¸°ì´ˆ ì •ì œ
(ì¤‘ë³µ ì œê±°, í˜•ì‹ í†µì¼)

ì£¼ê¸°: 5~30ë¶„ ìë™ ì‹¤í–‰

```
     â†“ SSH/REST API

```

[ì™¸ë¶€ ì„œë²„ (ì¼ë°˜ PC)]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì—­í• : ë°ì´í„° ë¶„ì„ & ëŒ€ì‹œë³´ë“œ

- MariaDB: ì •ì œ ë°ì´í„° ì €ì¥
â€¢ NLP ê°ì„±ë¶„ì„: FinBERT
â€¢ ê¸°ìˆ ì  ì§€í‘œ: RSI, MACD ë“±
â€¢ Flask API + React ëŒ€ì‹œë³´ë“œ
â€¢ ì‹¤ì‹œê°„ ì•Œë¦¼: Email/Slack

```

### **ìŠ¬ë¼ì´ë“œ 3: ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**

```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë°ì´í„° íë¦„ (30ë¶„ ì£¼ê¸°)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£ ìˆ˜ì§‘ (ë¼ì¦ˆë² ë¦¬íŒŒì´)
Scrapy â†’ 5ê°œ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
â†’ HDFS ì›ë³¸ ì €ì¥ (/raw/)

2ï¸âƒ£ ì •ì œ (ë¼ì¦ˆë² ë¦¬íŒŒì´)
MapReduce â†’ ì¤‘ë³µ ì œê±°
â†’ HDFS ì •ì œ ì €ì¥ (/cleaned/)

3ï¸âƒ£ ì „ì†¡ (ì™¸ë¶€ ì„œë²„)
HDFS fetch â†’ MariaDB ì ì¬

4ï¸âƒ£ ë¶„ì„ (ì™¸ë¶€ ì„œë²„)
â€¢ NLP ê°ì„±ë¶„ì„ (-1 ~ +1 ì ìˆ˜)
â€¢ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
â€¢ ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±:
- ê°ì„± ê¸‰ë³€ (Â±30% ì´ìƒ)
- ê±°ë˜ëŸ‰ ê¸‰ì¦ (1.5ë°° ì´ìƒ)
- ì¶”ì„¸ ë°˜ì „ (RSI+MACD ì‹ í˜¸)

5ï¸âƒ£ ì‹œê°í™” (ì™¸ë¶€ ì„œë²„)
React ëŒ€ì‹œë³´ë“œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

```

### **ìŠ¬ë¼ì´ë“œ 4: í•µì‹¬ ê¸°ëŠ¥**

```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ëŒ€ì‹œë³´ë“œ ì£¼ìš” í™”ë©´
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ì‹œì¥ ìš”ì•½
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê³µí¬Â·íƒìš• ì§€ìˆ˜: 65 (íƒìš•) â”‚
â”‚ 24h í‰ê·  ê°ì„±: +0.42 (ê¸ì •) â”‚
â”‚ ê±°ë˜ëŸ‰ Top 5: BTC/ETH/BNB â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2. ì‹¤ì‹œê°„ ì°¨íŠ¸
â€¢ ê°ì„± ì¶”ì´ (ì‹œê°„ëŒ€ë³„)
â€¢ ê¸°ìˆ ì  ì§€í‘œ (RSI/MACD)
â€¢ ê±°ë˜ëŸ‰ ë³€í™”
3. ì¸ì‚¬ì´íŠ¸ ì•Œë¦¼
ğŸ”´ Critical: BTC ê±°ë˜ëŸ‰ 2.1ë°° ê¸‰ì¦
ğŸŸ¡ High: ETH ê°ì„± +45% ì „í™˜
ğŸŸ¢ Medium: MACD ê³¨ë“ í¬ë¡œìŠ¤
4. ë‰´ìŠ¤ í”¼ë“œ
ê° ë‰´ìŠ¤ë§ˆë‹¤ ê°ì„± ì ìˆ˜ í‘œì‹œ
(-0.8 ë¶€ì • ~ +0.7 ê¸ì •)

```

### **ìŠ¬ë¼ì´ë“œ 5: ê¸°ëŒ€ íš¨ê³¼ & í™•ì¥ì„±**

```

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì •ëŸ‰ì  ì„±ê³¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

êµ¬ë¶„          | ê¸°ì¡´     | ë„ì… í›„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì •ë³´ ìˆ˜ì§‘     | 30~60ë¶„  | 0ë¶„ (ìë™)
ì˜ì‚¬ê²°ì •      | 10~20ë¶„  | 2~5ë¶„
ë°ì´í„° ì²˜ë¦¬   | 50ê°œ/ì¼  | 2,500ê°œ/ì¼
ìœ„í—˜ ê°ì§€     | ì‚¬í›„ëŒ€ì‘ | ì‚¬ì „ì•Œë¦¼

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
í™•ì¥ ê°€ëŠ¥ì„±
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë‹¨ê¸° (3ê°œì›”)
â€¢ ë” ë§ì€ ê±°ë˜ì†Œ ì¶”ê°€ (ë°”ì´ë‚¸ìŠ¤, ì—…ë¹„íŠ¸ API)
â€¢ í…”ë ˆê·¸ë¨ ë´‡ ì—°ë™

ì¤‘ê¸° (6ê°œì›”)
â€¢ ë¨¸ì‹ ëŸ¬ë‹ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸
â€¢ í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ì¶”ì²œ

ì¥ê¸° (1ë…„)
â€¢ ìë™ ë§¤ë§¤ ì—°ë™
â€¢ SaaS ì„œë¹„ìŠ¤ ì „í™˜

```

---

## ğŸ› ï¸ **9. êµ¬í˜„ ë¡œë“œë§µ (3ê°œì›”)**

### **Phase 1: ì¸í”„ë¼ êµ¬ì¶• (Week 1-2)**

```

[ë¼ì¦ˆë² ë¦¬íŒŒì´ ì„¤ì •]
âœ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ 4ëŒ€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°
âœ“ Hadoop í´ëŸ¬ìŠ¤í„° êµ¬ì„±

- Master: NameNode, YARN
- Workers: DataNode Ã—3
âœ“ Scrapyd ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸

[ì™¸ë¶€ ì„œë²„ ì„¤ì •]
âœ“ MariaDB ì„¤ì¹˜ ë° í…Œì´ë¸” ìƒì„±
âœ“ Python í™˜ê²½ êµ¬ì„±

- Flask/FastAPI
- Transformers (FinBERT)
- pandas, numpy, ta-lib
âœ“ React ê°œë°œ í™˜ê²½ ì„¤ì •

```

### **Phase 2: í¬ë¡¤ë§ ê°œë°œ (Week 3-5)**

```

[Scrapy ìŠ¤íŒŒì´ë” ê°œë°œ]
âœ“ Upbit Trends Spider

- ê±°ë˜ëŸ‰ ìˆœìœ„
- ì¸ê¸° ê²€ìƒ‰ì–´

âœ“ Coinness News Spider

- ë‰´ìŠ¤ í—¤ë“œë¼ì¸
- ë°œí–‰ ì‹œê°„, URL

âœ“ SaveTicker/Yahoo Spider

- ê°€ê²© ë°ì´í„°
- ê±°ë˜ëŸ‰

âœ“ Perplexity Finance Spider

- AI ë¶„ì„ ìš”ì•½

âœ“ CNN Fear & Greed Spider

- ê³µí¬Â·íƒìš• ì§€ìˆ˜

[MapReduce ì‘ì—…]
âœ“ Mapper: ë°ì´í„° ì •ì œ
âœ“ Reducer: ì¤‘ë³µ ì œê±° ë° ì§‘ê³„
âœ“ ìŠ¤ì¼€ì¤„ë§ ìë™í™”

```

### **Phase 3: ë¶„ì„ ì—”ì§„ (Week 6-8)**

```

[ë°ì´í„° ì „ì†¡]
âœ“ HDFS â†’ ì™¸ë¶€ ì„œë²„ fetch êµ¬í˜„
âœ“ JSON íŒŒì‹± ë° DB ì ì¬

[NLP ê°ì„±ë¶„ì„]
âœ“ FinBERT ëª¨ë¸ í†µí•©
âœ“ ë°°ì¹˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
âœ“ ê°ì„± ì ìˆ˜ DB ì €ì¥

[ê¸°ìˆ ì  ì§€í‘œ]
âœ“ RSI, MACD, ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚°
âœ“ ì§€í‘œ DB ì €ì¥

[ì¸ì‚¬ì´íŠ¸ ìƒì„±]
âœ“ ê°ì„± ê¸‰ë³€ ê°ì§€
âœ“ ê±°ë˜ëŸ‰ ê¸‰ì¦ ê°ì§€
âœ“ ì¶”ì„¸ ë°˜ì „ ê°ì§€

```

### **Phase 4: ëŒ€ì‹œë³´ë“œ ê°œë°œ (Week 9-11)**

```

[Backend API]
âœ“ Flask REST API êµ¬í˜„

- /api/dashboard/summary
- /api/charts/sentiment-timeline
- /api/charts/technical-indicators
- /api/insights/recent
- /api/news/latest

[Frontend]
âœ“ React ì»´í¬ë„ŒíŠ¸ ê°œë°œ

- ìš”ì•½ íŒ¨ë„
- ì°¨íŠ¸ (Recharts)
- ì¸ì‚¬ì´íŠ¸ ì¹´ë“œ
- ë‰´ìŠ¤ í”¼ë“œ
âœ“ ë°˜ì‘í˜• ë””ìì¸
âœ“ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (60ì´ˆ ì£¼ê¸°)

```

### **Phase 5: ì•Œë¦¼ & ìµœì í™” (Week 12)**

```

[ì•Œë¦¼ ì‹œìŠ¤í…œ]
âœ“ ì´ë©”ì¼ ì•Œë¦¼ (Gmail SMTP)
âœ“ Slack ì›¹í›… ì—°ë™
âœ“ Critical ì¸ì‚¬ì´íŠ¸ ìë™ ë°œì†¡

[ì„±ëŠ¥ ìµœì í™”]
âœ“ DB ì¸ë±ìŠ¤ ìµœì í™”
âœ“ API ì‘ë‹µ ì†ë„ ê°œì„ 
âœ“ í”„ë¡ íŠ¸ì—”ë“œ ë²ˆë“¤ ìµœì í™”

[í…ŒìŠ¤íŠ¸]
âœ“ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
âœ“ ì¥ì•  ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
âœ“ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

```

---

## ğŸ“Š **10. ê¸°ìˆ  ìŠ¤íƒ ì •ë¦¬**

### **ë¼ì¦ˆë² ë¦¬íŒŒì´ (ë°ì´í„° ìˆ˜ì§‘ì¸µ)**

```

OS: Raspberry Pi OS (Debian ê¸°ë°˜)

í¬ë¡¤ë§
â€¢ Scrapy 2.11+
â€¢ Scrapyd (ìŠ¤ì¼€ì¤„ëŸ¬)
â€¢ BeautifulSoup4
â€¢ Requests

ë¶„ì‚° ì²˜ë¦¬
â€¢ Hadoop 3.3+

- HDFS
- YARN
- MapReduce

ìŠ¤ì¼€ì¤„ë§
â€¢ Python schedule
â€¢ Cron

ë„¤íŠ¸ì›Œí¬
â€¢ SSH
â€¢ REST API (HDFS WebHDFS)

```

### **ì™¸ë¶€ ì„œë²„ (ë¶„ì„ & ëŒ€ì‹œë³´ë“œì¸µ)**

```

OS: Ubuntu 22.04 / macOS / Windows

ë°ì´í„°ë² ì´ìŠ¤
â€¢ MariaDB 10.11+
ë˜ëŠ” PostgreSQL 15+

Backend
â€¢ Python 3.10+

- Flask 3.0+ / FastAPI 0.104+
- SQLAlchemy
- mysql-connector-python

NLP & ë¶„ì„
â€¢ Transformers (Hugging Face)

- FinBERT
â€¢ pandas
â€¢ numpy
â€¢ ta-lib (ê¸°ìˆ ì  ì§€í‘œ)

Frontend
â€¢ Node.js 18+
â€¢ React 18+
â€¢ Recharts (ì°¨íŠ¸)
â€¢ Axios (HTTP)
â€¢ CSS3

ì•Œë¦¼
â€¢ smtplib (ì´ë©”ì¼)
â€¢ requests (Slack ì›¹í›…)

```

---

## âš™ï¸ **11. ì£¼ìš” ì„¤ì • íŒŒì¼**

### **config.yaml (ì „ì²´ ì„¤ì •)**

```yaml
# config.yaml

# ë¼ì¦ˆë² ë¦¬íŒŒì´ ì„¤ì •
raspberry_pi:
  master:
    hostname: raspberry-master
    ip: 192.168.1.100
    hdfs_port: 9000
    webhdfs_port: 50070
  workers:
    - hostname: raspberry-worker1
      ip: 192.168.1.101
    - hostname: raspberry-worker2
      ip: 192.168.1.102
    - hostname: raspberry-worker3
      ip: 192.168.1.103

# í¬ë¡¤ë§ ì„¤ì •
crawling:
  schedule:
    upbit: "*/5 * * * *"      # 5ë¶„ë§ˆë‹¤
    coinness: "*/10 * * * *"  # 10ë¶„ë§ˆë‹¤
    saveticker: "*/5 * * * *" # 5ë¶„ë§ˆë‹¤
    perplexity: "0 * * * *"   # 1ì‹œê°„ë§ˆë‹¤
    cnn: "0 0 * * *"          # ë§¤ì¼ ìì •

  user_agent: "CoinTicker/1.0"
  timeout: 30
  retry: 3

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
database:
  host: localhost
  port: 3306
  user: cointicker
  password: ${DB_PASSWORD}  # í™˜ê²½ë³€ìˆ˜
  database: cointicker
  charset: utf8mb4

# NLP ì„¤ì •
nlp:
  model_name: ProsusAI/finbert
  batch_size: 32
  max_length: 512

# ì¸ì‚¬ì´íŠ¸ ì„ê³„ê°’
insights:
  sentiment_shift_threshold: 0.30  # Â±30%
  volume_spike_ratio: 1.5          # 1.5ë°°
  rsi_oversold: 30
  rsi_overbought: 70

# ì•Œë¦¼ ì„¤ì •
alerts:
  email:
    smtp_server: smtp.gmail.com
    smtp_port: 587
    sender: ${EMAIL_SENDER}
    password: ${EMAIL_PASSWORD}
    recipients:
      - alert@example.com

  slack:
    webhook_url: ${SLACK_WEBHOOK}
    channel: "#cointicker-alerts"

# API ì„¤ì •
api:
  host: 0.0.0.0
  port: 5000
  debug: false
  cors_origins:
    - http://localhost:3000
    - https://cointicker.example.com

# í”„ë¡ íŠ¸ì—”ë“œ ì„¤ì •
frontend:
  api_base_url: http://localhost:5000/api
  refresh_interval: 60  # ì´ˆ

```

---

## ğŸš€ **12. ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ**

### **ë¼ì¦ˆë² ë¦¬íŒŒì´ ì„¤ì •**

```bash
# 1. Hadoop ì„¤ì¹˜ (ëª¨ë“  ë…¸ë“œ)
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
tar -xzf hadoop-3.3.6.tar.gz
sudo mv hadoop-3.3.6 /opt/hadoop

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
echo 'export HADOOP_HOME=/opt/hadoop' >> ~/.bashrc
echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' >> ~/.bashrc
source ~/.bashrc

# 2. Hadoop ì„¤ì • (Master ë…¸ë“œ)
# core-site.xml, hdfs-site.xml, yarn-site.xml ë“± ì„¤ì •
# (ì„¤ì • íŒŒì¼ì€ ë³„ë„ ì œê³µ)

# 3. HDFS ì´ˆê¸°í™” ë° ì‹œì‘
hdfs namenode -format
start-dfs.sh
start-yarn.sh

# 4. Scrapy ì„¤ì¹˜ (ëª¨ë“  ë…¸ë“œ)
pip3 install scrapy scrapyd scrapyd-client

# 5. Scrapyd ì‹œì‘
scrapyd &

# 6. í¬ë¡¤ëŸ¬ ë°°í¬
cd scrapy_project
scrapyd-deploy

# 7. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
python3 scheduler.py &

```

### **ì™¸ë¶€ ì„œë²„ ì„¤ì •**

```bash
# 1. MariaDB ì„¤ì¹˜
sudo apt install mariadb-server
sudo mysql_secure_installation

# 2. ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
mysql -u root -p
CREATE DATABASE cointicker CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER 'cointicker'@'localhost' IDENTIFIED BY 'your_password';
GRANT ALL PRIVILEGES ON cointicker.* TO 'cointicker'@'localhost';
FLUSH PRIVILEGES;
EXIT;

# 3. í…Œì´ë¸” ìƒì„±
mysql -u cointicker -p cointicker < schema.sql

# 4. Python í™˜ê²½ ì„¤ì •
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 5. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘ (DB ë¹„ë°€ë²ˆí˜¸, API í‚¤ ë“±)

# 6. Backend ì‹¤í–‰
cd external_server/api
python app.py

# 7. Frontend ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„)
cd external_server/frontend
npm install
npm start

# 8. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„)
cd external_server/scheduler
python main_scheduler.py

```

---

## ğŸ“ˆ **13. ëª¨ë‹ˆí„°ë§ & ìœ ì§€ë³´ìˆ˜**

### **ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬**

```python
# monitoring/health_check.py
import requests
import subprocess
import smtplib
from email.mime.text import MIMEText

class SystemMonitor:
    """ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§"""

    def check_raspberry_pi_cluster(self):
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„° ìƒíƒœ"""
        nodes = [
            'raspberry-master',
            'raspberry-worker1',
            'raspberry-worker2',
            'raspberry-worker3'
        ]

        status = {}
        for node in nodes:
            # SSH ì—°ê²° í…ŒìŠ¤íŠ¸
            result = subprocess.run(
                ['ssh', node, 'uptime'],
                capture_output=True,
                timeout=10
            )
            status[node] = 'OK' if result.returncode == 0 else 'FAIL'

        return status

    def check_hdfs_health(self):
        """HDFS ìƒíƒœ í™•ì¸"""
        result = subprocess.run(
            ['hdfs', 'dfsadmin', '-report'],
            capture_output=True,
            text=True
        )

        output = result.stdout

        # DataNode ê°œìˆ˜ í™•ì¸
        live_nodes = output.count('Live datanodes')
        expected_nodes = 3

        return {
            'healthy': live_nodes >= expected_nodes,
            'live_nodes': live_nodes,
            'details': output
        }

    def check_database_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
        import mysql.connector

        try:
            conn = mysql.connector.connect(
                host='localhost',
                user='cointicker',
                password='your_password',
                database='cointicker',
                connect_timeout=5
            )

            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM raw_news')
            news_count = cursor.fetchone()[0]

            cursor.close()
            conn.close()

            return {
                'healthy': True,
                'news_count': news_count
            }
        except Exception as e:
            return {
                'healthy': False,
                'error': str(e)
            }

    def check_api_health(self):
        """API ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(
                'http://localhost:5000/api/dashboard/summary',
                timeout=5
            )
            return {
                'healthy': response.status_code == 200,
                'status_code': response.status_code
            }
        except Exception as e:
            return {
                'healthy': False,
                'error': str(e)
            }

    def send_alert_if_unhealthy(self, check_results):
        """ì¥ì•  ë°œìƒ ì‹œ ì•Œë¦¼"""
        unhealthy = [
            name for name, result in check_results.items()
            if not result.get('healthy', True)
        ]

        if unhealthy:
            message = f"""
ì½”ì¸í‹°ì»¤ ì‹œìŠ¤í…œ ì¥ì•  ê°ì§€

ì¥ì•  ì»´í¬ë„ŒíŠ¸:
{chr(10).join(f'â€¢ {name}' for name in unhealthy)}

ìƒì„¸:
{check_results}
            """

            # ì´ë©”ì¼ ë°œì†¡
            self._send_email("ì‹œìŠ¤í…œ ì¥ì•  ì•Œë¦¼", message)

    def _send_email(self, subject, body):
        """ì´ë©”ì¼ ë°œì†¡"""
        msg = MIMEText(body)
        msg['Subject'] = subject
        msg['From'] = 'alert@cointicker.com'
        msg['To'] = 'admin@cointicker.com'

        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login('your_email', 'your_password')
            server.send_message(msg)

# ì‹¤í–‰
if __name__ == "__main__":
    monitor = SystemMonitor()

    results = {
        'raspberry_pi': monitor.check_raspberry_pi_cluster(),
        'hdfs': monitor.check_hdfs_health(),
        'database': monitor.check_database_connection(),
        'api': monitor.check_api_health()
    }

    print("ì‹œìŠ¤í…œ ìƒíƒœ:")
    for component, status in results.items():
        print(f"{component}: {status}")

    monitor.send_alert_if_unhealthy(results)

```

---

## ğŸ¯ **14. ì„±ê³µ ê¸°ì¤€ (KPI)**

```
ë°ì´í„° ìˆ˜ì§‘
âœ“ ì¼ì¼ ìˆ˜ì§‘ ë‰´ìŠ¤: 500+ ê°œ
âœ“ í¬ë¡¤ë§ ì„±ê³µë¥ : > 95%
âœ“ ë°ì´í„° ì •ì œìœ¨: > 90%

ì‹œìŠ¤í…œ ì„±ëŠ¥
âœ“ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œê°„: < 5ë¶„
âœ“ API ì‘ë‹µ ì†ë„: < 500ms
âœ“ ëŒ€ì‹œë³´ë“œ ë¡œë”©: < 2ì´ˆ

ë¶„ì„ ì •í™•ë„
âœ“ ê°ì„±ë¶„ì„ ì •í™•ë„: > 80%
âœ“ ì¸ì‚¬ì´íŠ¸ ìœ íš¨ì„±: > 70%

ì•ˆì •ì„±
âœ“ ì‹œìŠ¤í…œ ê°€ë™ë¥ : > 99%
âœ“ ë°ì´í„° ìœ ì‹¤ë¥ : < 1%

ì‚¬ìš©ì ê²½í—˜
âœ“ ì˜ì‚¬ê²°ì • ì‹œê°„ ë‹¨ì¶•: > 70%
âœ“ ì •ë³´ ìˆ˜ì§‘ ìë™í™”: 100%

```

---

## ğŸ”’ **15. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­**

```
1. ì¸ì¦ & ê¶Œí•œ
âœ“ API JWT í† í° ì¸ì¦
âœ“ DB ì‚¬ìš©ì ê¶Œí•œ ìµœì†Œí™”
âœ“ SSH í‚¤ ê¸°ë°˜ ì¸ì¦

2. ë°ì´í„° ë³´í˜¸
âœ“ í™˜ê²½ë³€ìˆ˜ë¡œ ë¹„ë°€ë²ˆí˜¸ ê´€ë¦¬
âœ“ HTTPS/TLS ì•”í˜¸í™”
âœ“ ë¯¼ê° ì •ë³´ ë¡œê·¸ ì œì™¸

3. í¬ë¡¤ë§ ìœ¤ë¦¬
âœ“ robots.txt ì¤€ìˆ˜
âœ“ Rate Limiting ì ìš©
âœ“ User-Agent ëª…ì‹œ

4. ë°±ì—…
âœ“ DB ì¼ì¼ ë°±ì—…
âœ“ HDFS ìŠ¤ëƒ…ìƒ· ì£¼ê°„ ë°±ì—…
âœ“ ì„¤ì • íŒŒì¼ ë²„ì „ ê´€ë¦¬

```

---

## ğŸ“ **ê²°ë¡ **

**ì½”ì¸í‹°ì»¤(CoinTicker)** í”„ë¡œì íŠ¸ëŠ”:

1. **ëª…í™•í•œ ì—­í•  ë¶„ë¦¬**
    - ë¼ì¦ˆë² ë¦¬íŒŒì´: ë°ì´í„° ìˆ˜ì§‘ & ì €ì¥
    - ì™¸ë¶€ ì„œë²„: ë°ì´í„° ë¶„ì„ & ì‹œê°í™”
2. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**
    - ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€ ìš©ì´
    - ë¶„ì„ ëª¨ë¸ êµì²´ ê°€ëŠ¥
    - ìˆ˜í‰ í™•ì¥ ì§€ì›
3. **ì‹¤ìš©ì  ê¸°ìˆ  ìŠ¤íƒ**
    - ê²€ì¦ëœ ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬
    - ì €ë¹„ìš© í•˜ë“œì›¨ì–´ í™œìš©
    - í•™ìŠµ íš¨ê³¼ ê·¹ëŒ€í™”
4. **ëª…í™•í•œ ê°€ì¹˜ ì œê³µ**
    - ì •ë³´ ìˆ˜ì§‘ ìë™í™”
    - ì˜ì‚¬ê²°ì • ì†ë„ í–¥ìƒ
    - ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ì •ëŸ‰í™”

ì´ ì‹œìŠ¤í…œì„ í†µí•´ **ì•”í˜¸í™”í ì‹œì¥ì˜ ë³µì¡í•œ ì •ë³´ë¥¼ ë‹¨ì¼ ëŒ€ì‹œë³´ë“œì—ì„œ íŒŒì•…**í•˜ê³ , **AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¡œ íˆ¬ì ì˜ì‚¬ê²°ì •ì„ ì§€ì›**í•˜ëŠ” ì™„ì „í•œ í”Œë«í¼ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€