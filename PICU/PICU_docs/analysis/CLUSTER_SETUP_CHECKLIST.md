# PICU í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì ê²€ ë³´ê³ ì„œ

**ì‘ì„± ì¼ì‹œ**: 2025-12-01
**ëª©ì **: í´ëŸ¬ìŠ¤í„° ì—°ê²° ì „ ì „ì²´ êµ¬ì„± ì ê²€ ë° ë¯¸êµ¬í˜„/ëˆ„ë½ ì‚¬í•­ í™•ì¸

---

## ğŸ“‹ ì ê²€ í•­ëª© ìš”ì•½

| í•­ëª©                     | ìƒíƒœ         | ìš°ì„ ìˆœìœ„ | ë¹„ê³                        |
| ------------------------ | ------------ | -------- | -------------------------- |
| IP ì£¼ì†Œ ì¼ê´€ì„±           | âš ï¸ ì£¼ì˜ í•„ìš” | ë†’ìŒ     | ì„¤ì • íŒŒì¼ ê°„ ë¶ˆì¼ì¹˜        |
| ë°°í¬ ìŠ¤í¬ë¦½íŠ¸            | âœ… ì™„ë£Œ      | -        | ëª¨ë“  ë…¸ë“œ ë°°í¬ ê°€ëŠ¥        |
| ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìë™ ì‹œì‘ | âŒ ë¯¸êµ¬í˜„    | ë†’ìŒ     | systemd ì„œë¹„ìŠ¤ í•„ìš”        |
| Tier 2 íŒŒì´í”„ë¼ì¸ ìë™í™” | âŒ ë¯¸êµ¬í˜„    | ë†’ìŒ     | ìŠ¤ì¼€ì¤„ëŸ¬ í•„ìš”              |
| Scrapyd ì„¤ì •             | âŒ ë¯¸êµ¬í˜„    | ì¤‘ê°„     | ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì— ì—†ìŒ       |
| HDFS í´ë¼ì´ì–¸íŠ¸ ì„¤ì •     | âš ï¸ ê°œì„  í•„ìš” | ì¤‘ê°„     | cluster_config.yaml ë¯¸ì‚¬ìš© |
| ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”      | âœ… ì™„ë£Œ      | -        | init_db.py ì¡´ì¬            |
| GUI í†µí•© ê´€ë¦¬            | âœ… ì™„ë£Œ      | -        | ëª¨ë“  ëª¨ë“ˆ í†µí•©ë¨           |

---

## ğŸ” ìƒì„¸ ì ê²€ ê²°ê³¼

### 1. IP ì£¼ì†Œ ì¼ê´€ì„± ë¬¸ì œ âš ï¸

**ë¬¸ì œì **:

- `cluster_config.yaml.example`: `192.168.1.100-103` ì‚¬ìš©
- ì‹¤ì œ `cluster_config.yaml`: `192.168.0.100-103` ì‚¬ìš©
- ëŒ€ë¶€ë¶„ì˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸: `192.168.0.100-103` ì‚¬ìš©

**ì˜í–¥**:

- ì„¤ì • íŒŒì¼ê³¼ ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
- ë¬¸ì„œì™€ ì‹¤ì œ ì„¤ì • ê°„ í˜¼ë€ ê°€ëŠ¥

**ê¶Œì¥ ì¡°ì¹˜**:

1. `cluster_config.yaml.example`ì„ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” IP ëŒ€ì—­(`192.168.0.x`)ìœ¼ë¡œ ìˆ˜ì •
2. ë˜ëŠ” ëª¨ë“  ë¬¸ì„œì™€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ `192.168.1.x`ë¡œ í†µì¼

**ìœ„ì¹˜**:

- `PICU/cointicker/config/cluster_config.yaml.example` (ë¼ì¸ 10, 17, 21, 25)

---

### 2. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìë™ ì‹œì‘ ë¯¸êµ¬í˜„ âŒ

**í˜„ì¬ ìƒíƒœ**:

- `master-node/orchestrator.py`ëŠ” êµ¬í˜„ë˜ì–´ ìˆìŒ
- ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ systemd ì„œë¹„ìŠ¤ ì„¤ì •ì´ ì£¼ì„ ì²˜ë¦¬ë¨
- ìˆ˜ë™ ì‹¤í–‰ë§Œ ê°€ëŠ¥

**ë¬¸ì œì **:

- ë¼ì¦ˆë² ë¦¬íŒŒì´ ì¬ë¶€íŒ… ì‹œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ìë™ìœ¼ë¡œ ì‹œì‘ë˜ì§€ ì•ŠìŒ
- í¬ë¡¤ë§ ì‘ì—…ì´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

**í•„ìš”í•œ ì‘ì—…**:

1. systemd ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„± (`/etc/systemd/system/cointicker-orchestrator.service`)
2. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì„œë¹„ìŠ¤ í™œì„±í™”
3. Scrapyd ì„œë¹„ìŠ¤ë„ í•¨ê»˜ ì„¤ì • (scheduler.py ì‚¬ìš© ì‹œ)

**ì°¸ê³  ìœ„ì¹˜**:

- `PICU/deployment/setup_master.sh` (ë¼ì¸ 213-215, ì£¼ì„ ì²˜ë¦¬ë¨)
- `PICU/cointicker/master-node/orchestrator.py`

**ì˜ˆì‹œ systemd ì„œë¹„ìŠ¤ íŒŒì¼**:

```ini
[Unit]
Description=CoinTicker Pipeline Orchestrator
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/cointicker
Environment="PATH=/home/ubuntu/cointicker/venv/bin:/usr/local/bin:/usr/bin:/bin"
ExecStart=/home/ubuntu/cointicker/venv/bin/python /home/ubuntu/cointicker/master-node/orchestrator.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

---

### 3. Tier 2 íŒŒì´í”„ë¼ì¸ ìë™í™” ë¯¸êµ¬í˜„ âŒ

**í˜„ì¬ ìƒíƒœ**:

- `scripts/run_pipeline.py`ëŠ” êµ¬í˜„ë˜ì–´ ìˆìŒ
- HDFSì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ DBì— ì ì¬í•˜ëŠ” ë¡œì§ ì¡´ì¬
- ìë™ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì—†ìŒ

**ë¬¸ì œì **:

- Tier 1ì—ì„œ HDFSì— ì €ì¥ëœ ë°ì´í„°ê°€ Tier 2 DBë¡œ ìë™ ì „ì†¡ë˜ì§€ ì•ŠìŒ
- ìˆ˜ë™ìœ¼ë¡œë§Œ `run_pipeline.py` ì‹¤í–‰ ê°€ëŠ¥

**í•„ìš”í•œ ì‘ì—…**:

1. Tier 2 ì„œë²„ì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬í˜„
   - cron job ë˜ëŠ” systemd timer
   - ë˜ëŠ” Python ìŠ¤ì¼€ì¤„ëŸ¬ (schedule ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
2. ì‹¤í–‰ ì£¼ê¸° ê²°ì • (ì˜ˆ: 30ë¶„ë§ˆë‹¤ ë˜ëŠ” 1ì‹œê°„ë§ˆë‹¤)

**ì°¸ê³  ìœ„ì¹˜**:

- `PICU/cointicker/scripts/run_pipeline.py`
- `PICU/cointicker/backend/services/data_loader.py`

**ê¶Œì¥ êµ¬í˜„**:

```python
# scripts/run_pipeline_scheduler.py (ìƒˆë¡œ ìƒì„±)
import schedule
import time
from scripts.run_pipeline import run_full_pipeline

# 30ë¶„ë§ˆë‹¤ ì‹¤í–‰
schedule.every(30).minutes.do(run_full_pipeline)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

### 4. Scrapyd ì„¤ì • ë¯¸êµ¬í˜„ âŒ

**í˜„ì¬ ìƒíƒœ**:

- `master-node/scheduler.py`ëŠ” Scrapydë¥¼ ì‚¬ìš©í•˜ë„ë¡ êµ¬í˜„ë¨
- `requirements-master.txt`ì— `scrapyd>=1.3.0` í¬í•¨ë¨
- ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ Scrapyd ì„¤ì¹˜/ì„¤ì •ì´ ì—†ìŒ

**ë¬¸ì œì **:

- Scrapyd ì„œë²„ê°€ ì„¤ì¹˜/ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë©´ scheduler.pyê°€ ë™ì‘í•˜ì§€ ì•ŠìŒ
- Scrapyd ì„¤ì • íŒŒì¼(`scrapyd.conf`)ì´ ì—†ìŒ

**í•„ìš”í•œ ì‘ì—…**:

1. Scrapyd ì„¤ì¹˜ í™•ì¸ (requirements-master.txtì— í¬í•¨ë˜ì–´ ìˆìŒ)
2. Scrapyd ì„¤ì • íŒŒì¼ ìƒì„± (`~/.scrapyd/scrapyd.conf`)
3. Scrapyd ì„œë¹„ìŠ¤ ìë™ ì‹œì‘ ì„¤ì • (systemd)
4. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì— Scrapyd ì„¤ì • ì¶”ê°€

**ì°¸ê³  ìœ„ì¹˜**:

- `PICU/cointicker/master-node/scheduler.py`
- `PICU/requirements/requirements-master.txt` (ë¼ì¸ 6)

**ì˜ˆì‹œ Scrapyd ì„¤ì •**:

```ini
# ~/.scrapyd/scrapyd.conf
[scrapyd]
bind_address = 0.0.0.0
http_port = 6800
eggs_dir = eggs
logs_dir = logs
items_dir = items
jobs_to_keep = 5
dbs_dir = dbs
max_proc = 0
max_proc_per_cpu = 4
finished_to_keep = 100
poll_interval = 5.0
```

---

### 5. HDFS í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ê°œì„  í•„ìš” âš ï¸

**í˜„ì¬ ìƒíƒœ**:

- `shared/hdfs_client.py`ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ `localhost:9000` ì‚¬ìš©
- `cluster_config.yaml`ì˜ ì„¤ì •ì„ ì½ì–´ì˜¤ì§€ ì•ŠìŒ

**ë¬¸ì œì **:

- Tier 2ì—ì„œ HDFSì— ì ‘ì†í•  ë•Œ cluster_config.yamlì˜ ì„¤ì •ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
- í•˜ë“œì½”ë”©ëœ namenode ì£¼ì†Œ ì‚¬ìš©

**ê°œì„  ë°©ì•ˆ**:

1. HDFSClient ì´ˆê¸°í™” ì‹œ cluster_config.yaml ì½ê¸°
2. ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ namenode ì£¼ì†Œ ì„¤ì •

**ì°¸ê³  ìœ„ì¹˜**:

- `PICU/cointicker/shared/hdfs_client.py` (ë¼ì¸ 33)
- `PICU/cointicker/config/cluster_config.yaml` (ë¼ì¸ 34)

**ê°œì„  ì˜ˆì‹œ**:

```python
# shared/hdfs_client.py ìˆ˜ì •
def __init__(self, namenode: str = None, use_java: bool = True):
    if namenode is None:
        # cluster_config.yamlì—ì„œ ì½ê¸°
        config_path = get_cointicker_root() / "config" / "cluster_config.yaml"
        if config_path.exists():
            with open(config_path) as f:
                config = yaml.safe_load(f)
                namenode = config.get("hadoop", {}).get("hdfs", {}).get("namenode", "hdfs://localhost:9000")
        else:
            namenode = "hdfs://localhost:9000"
    # ...
```

---

### 6. ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì ê²€ âœ…

**ìƒíƒœ**: ì™„ë£Œ

**í™•ì¸ ì‚¬í•­**:

- âœ… `setup_all_nodes.sh`: ëª¨ë“  ë…¸ë“œ ë°°í¬ ê°€ëŠ¥
- âœ… `setup_master.sh`: Master Node ë°°í¬ ì™„ë£Œ
- âœ… `setup_worker.sh`: Worker Node ë°°í¬ ì™„ë£Œ
- âœ… requirements íŒŒì¼ ì¡´ì¬ (`requirements-master.txt`, `requirements-worker.txt`)
- âœ… Hadoop ì„¤ì • íŒŒì¼ ìë™ ìƒì„±
- âš ï¸ systemd ì„œë¹„ìŠ¤ ì„¤ì •ì€ ì£¼ì„ ì²˜ë¦¬ë¨ (ìœ„ 2ë²ˆ í•­ëª© ì°¸ê³ )

---

### 7. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” âœ…

**ìƒíƒœ**: ì™„ë£Œ

**í™•ì¸ ì‚¬í•­**:

- âœ… `backend/init_db.py` ì¡´ì¬
- âœ… DB ëª¨ë¸ ì •ì˜ ì™„ë£Œ (`backend/models.py`)
- âœ… DataLoader êµ¬í˜„ ì™„ë£Œ (`backend/services/data_loader.py`)

---

### 8. GUI í†µí•© ê´€ë¦¬ âœ…

**ìƒíƒœ**: ì™„ë£Œ

**í™•ì¸ ì‚¬í•­**:

- âœ… ëª¨ë“  ëª¨ë“ˆ í†µí•© ê´€ë¦¬ ê°€ëŠ¥
- âœ… í´ëŸ¬ìŠ¤í„° ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥
- âœ… Tier 2 ì„œë²„ ê´€ë¦¬ ê¸°ëŠ¥
- âœ… íŒŒì´í”„ë¼ì¸ ì œì–´ ê¸°ëŠ¥
- âœ… ì„¤ì • ì¤‘ì•™ ê´€ë¦¬

---

## ğŸ¯ ìš°ì„ ìˆœìœ„ë³„ ì¡°ì¹˜ ì‚¬í•­

### ë†’ì€ ìš°ì„ ìˆœìœ„ (í…ŒìŠ¤íŠ¸ ì „ í•„ìˆ˜)

1. **IP ì£¼ì†Œ ì¼ê´€ì„± ìˆ˜ì •**

   - `cluster_config.yaml.example` ìˆ˜ì •
   - ë˜ëŠ” ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ í™•ì¸ í›„ cluster_config.yaml ì—…ë°ì´íŠ¸

2. **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìë™ ì‹œì‘ ì„¤ì •**

   - systemd ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„±
   - ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ì— ì„œë¹„ìŠ¤ í™œì„±í™” ì¶”ê°€

3. **Tier 2 íŒŒì´í”„ë¼ì¸ ìë™í™”**
   - ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
   - systemd timer ë˜ëŠ” cron job ì„¤ì •

### ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (í…ŒìŠ¤íŠ¸ ì¤‘ êµ¬í˜„)

4. **Scrapyd ì„¤ì •**

   - Scrapyd ì„¤ì • íŒŒì¼ ìƒì„±
   - Scrapyd ì„œë¹„ìŠ¤ ìë™ ì‹œì‘ ì„¤ì •

5. **HDFS í´ë¼ì´ì–¸íŠ¸ ê°œì„ **
   - cluster_config.yaml ì½ê¸° ê¸°ëŠ¥ ì¶”ê°€

---

## ğŸ“ í…ŒìŠ¤íŠ¸ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Tier 1 (ë¼ì¦ˆë² ë¦¬íŒŒì´ í´ëŸ¬ìŠ¤í„°)

- [ ] ëª¨ë“  ë…¸ë“œ ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
- [ ] SSH í‚¤ ë³µì‚¬ ì™„ë£Œ
- [ ] ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì™„ë£Œ
- [ ] Hadoop NameNode/DataNode ì‹œì‘ í™•ì¸
- [ ] YARN ResourceManager/NodeManager ì‹œì‘ í™•ì¸
- [ ] ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] Scrapy Spider ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] HDFS ì €ì¥ í™•ì¸ (`hdfs dfs -ls /raw/`)
- [ ] MapReduce ì‘ì—… ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

### Tier 2 (ì™¸ë¶€ ì„œë²„)

- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ
- [ ] ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ í™•ì¸
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ì„œë²„ ì‹¤í–‰ í™•ì¸
- [ ] HDFS í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] Tier 2 íŒŒì´í”„ë¼ì¸ ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] GUI ì‹¤í–‰ í™•ì¸

### í†µí•© í…ŒìŠ¤íŠ¸

- [ ] Tier 1 â†’ HDFS ë°ì´í„° ì €ì¥ í™•ì¸
- [ ] Tier 1 â†’ Tier 2 ë°ì´í„° ì „ì†¡ í™•ì¸
- [ ] Tier 2 â†’ DB ì ì¬ í™•ì¸
- [ ] GUIë¥¼ í†µí•œ í´ëŸ¬ìŠ¤í„° ëª¨ë‹ˆí„°ë§ í™•ì¸
- [ ] GUIë¥¼ í†µí•œ íŒŒì´í”„ë¼ì¸ ì œì–´ í™•ì¸

---

## ğŸ”§ ë¹ ë¥¸ ìˆ˜ì • ê°€ì´ë“œ

### 1. IP ì£¼ì†Œ ì¼ê´€ì„± ìˆ˜ì •

```bash
# cluster_config.yaml.example ìˆ˜ì •
cd PICU/cointicker/config
# 192.168.1.x â†’ 192.168.0.xë¡œ ë³€ê²½
```

### 2. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° systemd ì„œë¹„ìŠ¤ ìƒì„±

```bash
# Master Nodeì— ì ‘ì†
ssh ubuntu@raspberry-master

# ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„±
sudo nano /etc/systemd/system/cointicker-orchestrator.service
# (ìœ„ì˜ ì˜ˆì‹œ ë‚´ìš© ë³µì‚¬)

# ì„œë¹„ìŠ¤ í™œì„±í™”
sudo systemctl daemon-reload
sudo systemctl enable cointicker-orchestrator
sudo systemctl start cointicker-orchestrator
```

### 3. Tier 2 íŒŒì´í”„ë¼ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±

```bash
# scripts/run_pipeline_scheduler.py ìƒì„±
# (ìœ„ì˜ ì˜ˆì‹œ ì½”ë“œ ì‚¬ìš©)

# systemd timer ì„¤ì • ë˜ëŠ” cron job ì¶”ê°€
```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [ë°°í¬ ê°€ì´ë“œ](../guides/DEPLOYMENT_GUIDE.md)
- [GUI ê°€ì´ë“œ](../guides/GUI_GUIDE.md)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](../reference/PROJECT_DOCUMENTATION.md)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-12-01
