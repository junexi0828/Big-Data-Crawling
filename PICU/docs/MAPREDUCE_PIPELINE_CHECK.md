# MapReduce íŒŒì´í”„ë¼ì¸ ì ê²€ ë³´ê³ ì„œ

## ğŸ“‹ ì „ì²´ íŒŒì´í”„ë¼ì¸ íë¦„

```
1. Scrapy Spider (í¬ë¡¤ë§)
   â†“
2. Kafka Pipeline â†’ Kafka í† í”½ (cointicker.raw.*)
   â†“
3. Kafka Consumer â†’ HDFS (/raw/YYYYMMDD/)
   â†“
4. MapReduce ì •ì œ (run_cleaner.sh) â†’ HDFS (/cleaned/YYYYMMDD/)
   â†“
5. DataLoader â†’ MariaDB (raw_news, market_trends, fear_greed_index)
   â†“
6. Backend API â†’ Frontend
```

## âœ… ì—°ê²° ìƒíƒœ ì ê²€ ê²°ê³¼

### 1. ë°ì´í„° ìš´ë°˜: Kafka â†’ HDFS

**ìœ„ì¹˜**: `worker-nodes/kafka/kafka_consumer.py`

**ìƒíƒœ**: âœ… ì •ìƒ ì—°ê²°
- Kafka Consumerê°€ `cointicker.raw.*` í† í”½ êµ¬ë…
- `HDFSUploadManager`ë¥¼ í†µí•´ HDFSì— ì €ì¥
- ì €ì¥ ê²½ë¡œ: `/raw/{source}/{YYYYMMDD}/`
- ìë™ ì¬ì‹œë„ ë¡œì§ í¬í•¨

**ì½”ë“œ ìœ„ì¹˜**:
```python
# kafka_consumer.py:324
success = self.upload_manager.save_to_hdfs(
    items=[data],
    source=source,
    date=datetime.now(),
)
```

### 2. ë°ì´í„° ì •ì œ: MapReduce (run_cleaner.sh)

**ìœ„ì¹˜**: `worker-nodes/mapreduce/run_cleaner.sh`

**ìƒíƒœ**: âœ… ì •ìƒ ì—°ê²°
- ì…ë ¥ ê²½ë¡œ: `/raw/*/{YYYYMMDD}/*`
- ì¶œë ¥ ê²½ë¡œ: `/cleaned/{YYYYMMDD}/cleaned_{YYYYMMDD}.json`
- Mapper/Reducer: `cleaner_mapper.py`, `cleaner_reducer.py`
- HADOOP_HOME ìë™ ê°ì§€ ë¡œì§ í¬í•¨

**ì‹¤í–‰ ê²½ë¡œ**:
1. `orchestrator.py` â†’ `run_mapreduce()` â†’ `run_cleaner.sh`
2. `MapReduceModule` â†’ `run_cleaner()` â†’ `run_cleaner.sh`
3. GUI Control Tab â†’ `run_mapreduce()` â†’ `run_cleaner.sh`

**ë¬¸ì œì **: âš ï¸ `orchestrator.py`ì—ì„œ `capture_output=True` ì‚¬ìš© â†’ launchctl í™˜ê²½ì—ì„œ "Bad file descriptor" ì˜¤ë¥˜ ê°€ëŠ¥

**ìˆ˜ì • ì™„ë£Œ**: `stdout=subprocess.DEVNULL, stderr=subprocess.PIPE`ë¡œ ë³€ê²½

### 3. ë°ì´í„° ì ì¬: HDFS â†’ MariaDB

**ìœ„ì¹˜**: `scripts/run_pipeline.py`, `backend/services/data_loader.py`

**ìƒíƒœ**: âœ… ì •ìƒ ì—°ê²°
- `DataLoader.load_from_hdfs()` ë©”ì„œë“œ ì‚¬ìš©
- HDFS ê²½ë¡œ: `/cleaned/{YYYYMMDD}/cleaned_{YYYYMMDD}.json`
- DB í…Œì´ë¸”: `raw_news`, `market_trends`, `fear_greed_index`
- ì¤‘ë³µ ì²´í¬ í¬í•¨

**ì‹¤í–‰ ê²½ë¡œ**:
1. `orchestrator.py` â†’ `run_data_loader()` â†’ `run_pipeline.py`
2. GUI Control Tab â†’ `run_data_loader()` â†’ `run_pipeline.py`

**ë¬¸ì œì **: âš ï¸ `orchestrator.py`ì—ì„œ `capture_output=True` ì‚¬ìš© â†’ launchctl í™˜ê²½ì—ì„œ "Bad file descriptor" ì˜¤ë¥˜ ê°€ëŠ¥

**ìˆ˜ì • ì™„ë£Œ**: `stdout=subprocess.DEVNULL, stderr=subprocess.PIPE`ë¡œ ë³€ê²½

### 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

**ìœ„ì¹˜**: `master-node/orchestrator.py`

**ìƒíƒœ**: âœ… ì •ìƒ ì—°ê²°
- `run_full_pipeline()` ë©”ì„œë“œë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- Step 1: `run_crawlers()` - í¬ë¡¤ë§
- Step 2: `run_mapreduce()` - MapReduce ì •ì œ
- Step 3: `run_data_loader()` - DB ì ì¬

**ìŠ¤ì¼€ì¤„ë§**:
- í¬ë¡¤ë§: 2ë¶„ë§ˆë‹¤ (`schedule.every(2).minutes`)
- ì „ì²´ íŒŒì´í”„ë¼ì¸: 5ë¶„ë§ˆë‹¤ (`schedule.every(5).minutes`)
- ê³µí¬Â·íƒìš• ì§€ìˆ˜: ë§¤ì¼ ìì • (`schedule.every().day.at("00:00")`)

## ğŸ” ëª¨ë“ˆ ê°„ ì—°ê²° í™•ì¸

### MapReduceModule â†” Orchestrator

**ìƒíƒœ**: âœ… ì •ìƒ
- `MapReduceModule`ì€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
- `orchestrator.py`ëŠ” ì§ì ‘ `run_cleaner.sh` ì‹¤í–‰
- ë‘ ê²½ë¡œ ëª¨ë‘ ì •ìƒ ë™ì‘

### MapReduceModule â†” GUI

**ìƒíƒœ**: âœ… ì •ìƒ
- GUI Control Tabì—ì„œ MapReduce ì‹¤í–‰ ê°€ëŠ¥
- `app.py`ì˜ `run_mapreduce()` ë©”ì„œë“œ ì‚¬ìš©
- ìƒíƒœ ëª¨ë‹ˆí„°ë§: `MapReduceModule.get_status()` ì‚¬ìš©

### DataLoader â†” HDFSClient

**ìƒíƒœ**: âœ… ì •ìƒ
- `DataLoader`ê°€ `HDFSClient.get_cleaned_path()` ì‚¬ìš©
- HDFS ê²½ë¡œ ìë™ êµ¬ì„±

## âš ï¸ ë°œê²¬ëœ ë¬¸ì œì  ë° ìˆ˜ì • ì‚¬í•­

### 1. launchctl í™˜ê²½ì—ì„œ stdout/stderr ì²˜ë¦¬

**ë¬¸ì œ**: `orchestrator.py`ì˜ `run_mapreduce()`ì™€ `run_data_loader()`ì—ì„œ `capture_output=True` ì‚¬ìš© ì‹œ launchctl ì„œë¹„ìŠ¤ í™˜ê²½ì—ì„œ "Bad file descriptor" ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥

**ìˆ˜ì •**:
- `stdout=subprocess.DEVNULL`ë¡œ ë³€ê²½
- `stderr=subprocess.PIPE`ë¡œ ì—ëŸ¬ë§Œ ìº¡ì²˜

### 2. MapReduce ìƒíƒœ ëª¨ë‹ˆí„°ë§

**ë¬¸ì œ**: ëŒ€ì‹œë³´ë“œì—ì„œ MapReduce ìƒíƒœê°€ í•­ìƒ `{"running": False}`ë¡œ í‘œì‹œë¨

**ìˆ˜ì •**: `app.py`ì—ì„œ `MapReduceModule.get_status()`ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ë„ë¡ ë³€ê²½

## ğŸ“Š ë°ì´í„° ê²½ë¡œ í™•ì¸

### HDFS ê²½ë¡œ êµ¬ì¡°

```
/raw/
  â”œâ”€â”€ upbit_trends/
  â”‚   â””â”€â”€ 20251208/
  â”‚       â””â”€â”€ upbit_trends_*.json
  â”œâ”€â”€ coinness/
  â”‚   â””â”€â”€ 20251208/
  â”‚       â””â”€â”€ coinness_*.json
  â””â”€â”€ ...

/cleaned/
  â””â”€â”€ 20251208/
      â””â”€â”€ cleaned_20251208.json
```

### ë¡œì»¬ ì„ì‹œ ê²½ë¡œ

```
worker-nodes/mapreduce/data/
  â”œâ”€â”€ input_20251208/
  â”‚   â””â”€â”€ *.json (HDFSì—ì„œ ë‹¤ìš´ë¡œë“œ)
  â””â”€â”€ output_20251208.json (ì •ì œ ê²°ê³¼)
```

## âœ… ìµœì¢… ì ê²€ ê²°ê³¼

| ë‹¨ê³„ | ëª¨ë“ˆ | ìƒíƒœ | ì—°ê²° í™•ì¸ |
|------|------|------|-----------|
| 1. í¬ë¡¤ë§ | Scrapy Spider | âœ… | Kafka Pipeline ì—°ê²°ë¨ |
| 2. ë©”ì‹œì§€ í | Kafka | âœ… | Consumer ì—°ê²°ë¨ |
| 3. HDFS ì €ì¥ | Kafka Consumer | âœ… | HDFSUploadManager ì—°ê²°ë¨ |
| 4. ë°ì´í„° ì •ì œ | MapReduce | âœ… | run_cleaner.sh ì •ìƒ ë™ì‘ |
| 5. DB ì ì¬ | DataLoader | âœ… | HDFSClient ì—°ê²°ë¨ |
| 6. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | Orchestrator | âœ… | ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©ë¨ |

## ğŸ¯ ê¶Œì¥ ì‚¬í•­

1. **ë¡œê·¸ ëª¨ë‹ˆí„°ë§**: MapReduce ì‹¤í–‰ ì‹œ ë¡œê·¸ íŒŒì¼ í™•ì¸ (`logs/orchestrator.log`)
2. **HDFS ê²½ë¡œ í™•ì¸**: ì •ì œ ì „/í›„ ë°ì´í„° ê²½ë¡œ ì •í™•ì„± í™•ì¸
3. **ì—ëŸ¬ ì²˜ë¦¬**: MapReduce ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ ê³ ë ¤
4. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ MapReduce ë³‘ë ¬í™” ê³ ë ¤

