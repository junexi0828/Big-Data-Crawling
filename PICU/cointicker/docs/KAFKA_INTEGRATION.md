# Kafka í†µí•© ê°€ì´ë“œ

CoinTicker í”„ë¡œì íŠ¸ì— Kafka Producer/Consumerë¥¼ í†µí•©í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

KafkaëŠ” Scrapy Spiderì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ê³ , Consumerë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

### ë°ì´í„° íë¦„

```
Scrapy Spider
    â†“
Kafka Producer (KafkaPipeline)
    â†“
Kafka Topic (cointicker.raw.*)
    â†“
Kafka Consumer (kafka_consumer.py)
    â†“
HDFS ì €ì¥ ë˜ëŠ” Backend ì²˜ë¦¬
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. Kafka ì„œë²„ ì„¤ì •

Kafka ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `kafka_project/README.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

```bash
# Kafka ì„œë²„ ì‹œì‘ (ì˜ˆì‹œ)
cd kafka_project
./kafka_streams/start_kafka.sh
```

### 2. ì„¤ì • íŒŒì¼ ìƒì„±

```bash
cd PICU/cointicker/config
cp kafka_config.yaml.example kafka_config.yaml
# kafka_config.yamlì„ í¸ì§‘í•˜ì—¬ ì‹¤ì œ Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ ì„¤ì •
```

### 3. Kafka Pipeline í™œì„±í™”

`worker-nodes/cointicker/settings.py`ì—ì„œ Kafka Pipelineì„ í™œì„±í™”:

```python
ITEM_PIPELINES = {
    "cointicker.pipelines.ValidationPipeline": 300,
    "cointicker.pipelines.DuplicatesPipeline": 400,
    "cointicker.pipelines.HDFSPipeline": 500,
    "cointicker.pipelines.kafka_pipeline.KafkaPipeline": 600,  # ì¶”ê°€
}
```

ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •:

```bash
export KAFKA_BOOTSTRAP_SERVERS="localhost:9092"
export KAFKA_TOPIC_PREFIX="cointicker"
```

### 4. Kafka Consumer ì‹¤í–‰

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
bash worker-nodes/run_kafka_consumer.sh

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰
python worker-nodes/kafka_consumer.py \
    --bootstrap-servers localhost:9092 \
    --topics cointicker.raw.* \
    --group-id cointicker-consumer \
    --hdfs-namenode hdfs://localhost:9000
```

## ğŸ“¦ êµ¬ì„± ìš”ì†Œ

### 1. Kafka Client (`shared/kafka_client.py`)

Kafka Producerì™€ Consumerë¥¼ ìœ„í•œ ê³µí†µ í´ë¼ì´ì–¸íŠ¸:

- `KafkaProducerClient`: ë©”ì‹œì§€ ì „ì†¡
- `KafkaConsumerClient`: ë©”ì‹œì§€ ìˆ˜ì‹ 

### 2. Kafka Pipeline (`worker-nodes/cointicker/pipelines/kafka_pipeline.py`)

Scrapy Pipelineìœ¼ë¡œ êµ¬í˜„ëœ Kafka Producer:

- Spiderì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ Kafkaë¡œ ì „ì†¡
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì› (ê¸°ë³¸ 10ê°œ)
- ìë™ ì¬ì‹œë„ ë° ì˜¤ë¥˜ ì²˜ë¦¬

### 3. Kafka Consumer (`worker-nodes/kafka_consumer.py`)

Kafkaì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤:

- ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìˆ˜ì‹ 
- HDFS ì €ì¥
- í†µê³„ ë° ëª¨ë‹ˆí„°ë§

## âš™ï¸ ì„¤ì •

### Kafka ì„¤ì • íŒŒì¼ (`config/kafka_config.yaml`)

```yaml
kafka:
  bootstrap_servers:
    - "localhost:9092"

  topics:
    raw_prefix: "cointicker.raw"
    processed_prefix: "cointicker.processed"
    insights_prefix: "cointicker.insights"

  producer:
    acks: "all"
    retries: 3
    batch_size: 10
    timeout: 10

  consumer:
    group_id: "cointicker-consumer"
    auto_offset_reset: "earliest"
    enable_auto_commit: true
    timeout: 10
```

### Scrapy ì„¤ì • (`worker-nodes/cointicker/settings.py`)

```python
# Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ
KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"  # ë˜ëŠ” ë¦¬ìŠ¤íŠ¸

# í† í”½ ì ‘ë‘ì‚¬
KAFKA_TOPIC_PREFIX = "cointicker"
```

## ğŸ”§ ì‚¬ìš© ì˜ˆì‹œ

### Producer ì‚¬ìš© (Pipeline ìë™)

Kafka Pipelineì´ í™œì„±í™”ë˜ë©´ Spider ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ Kafkaë¡œ ë°ì´í„°ê°€ ì „ì†¡ë©ë‹ˆë‹¤:

```bash
cd worker-nodes
scrapy crawl upbit_trends
```

### Consumer ì‚¬ìš©

```bash
# ê¸°ë³¸ ì‹¤í–‰
python worker-nodes/kafka_consumer.py

# ì»¤ìŠ¤í…€ ì„¤ì •
python worker-nodes/kafka_consumer.py \
    --bootstrap-servers "192.168.1.100:9092,192.168.1.101:9092" \
    --topics "cointicker.raw.upbit_trends" "cointicker.raw.coinness" \
    --group-id "my-consumer-group" \
    --hdfs-namenode "hdfs://192.168.1.100:9000"
```

### Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from shared.kafka_client import KafkaProducerClient, KafkaConsumerClient

# Producer
producer = KafkaProducerClient(
    bootstrap_servers=["localhost:9092"]
)
producer.connect()
producer.send("cointicker.raw.test", {"key": "value"})
producer.close()

# Consumer
consumer = KafkaConsumerClient(
    bootstrap_servers=["localhost:9092"],
    group_id="test-consumer"
)
consumer.connect(["cointicker.raw.test"])

def process_message(message):
    print(f"Received: {message.value}")

consumer.consume(callback=process_message)
consumer.close()
```

## ğŸ“Š í† í”½ êµ¬ì¡°

### ì›ì‹œ ë°ì´í„° í† í”½

- `cointicker.raw.upbit_trends`: Upbit íŠ¸ë Œë“œ ë°ì´í„°
- `cointicker.raw.coinness`: Coinness ë‰´ìŠ¤ ë°ì´í„°
- `cointicker.raw.saveticker`: SaveTicker ë°ì´í„°
- `cointicker.raw.perplexity`: Perplexity ë¶„ì„ ë°ì´í„°
- `cointicker.raw.cnn_fear_greed`: CNN Fear & Greed Index

### ì²˜ë¦¬ëœ ë°ì´í„° í† í”½

- `cointicker.processed.*`: MapReduceë¡œ ì •ì œëœ ë°ì´í„°

### ì¸ì‚¬ì´íŠ¸ í† í”½

- `cointicker.insights.*`: Backendì—ì„œ ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸

## ğŸ› ë¬¸ì œ í•´ê²°

### Kafka ì—°ê²° ì‹¤íŒ¨

1. **Kafka ì„œë²„ í™•ì¸**:
   ```bash
   # Kafka ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
   ps aux | grep kafka
   ```

2. **ë„¤íŠ¸ì›Œí¬ í™•ì¸**:
   ```bash
   # ë¸Œë¡œì»¤ ì£¼ì†Œ í™•ì¸
   telnet localhost 9092
   ```

3. **ì„¤ì • í™•ì¸**:
   - `bootstrap_servers`ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
   - ë°©í™”ë²½ ì„¤ì • í™•ì¸

### Consumerê°€ ë©”ì‹œì§€ë¥¼ ë°›ì§€ ëª»í•¨

1. **í† í”½ í™•ì¸**:
   ```bash
   # í† í”½ ëª©ë¡ í™•ì¸
   kafka-topics.sh --list --bootstrap-server localhost:9092
   ```

2. **Consumer Group í™•ì¸**:
   ```bash
   # Consumer Group ìƒíƒœ í™•ì¸
   kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
   ```

3. **ì˜¤í”„ì…‹ í™•ì¸**:
   ```bash
   # Consumer Group ì˜¤í”„ì…‹ í™•ì¸
   kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
       --group cointicker-consumer --describe
   ```

### ë©”ì‹œì§€ ì†ì‹¤

1. **Producer ACK ì„¤ì • í™•ì¸**: `acks: "all"` ê¶Œì¥
2. **ì¬ì‹œë„ ì„¤ì • í™•ì¸**: `retries: 3` ì´ìƒ ê¶Œì¥
3. **Consumer ìë™ ì»¤ë°‹ í™•ì¸**: `enable_auto_commit: true`

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Kafka í”„ë¡œì íŠ¸ README](../../../kafka_project/README.md)
- [Kafka ê³µì‹ ë¬¸ì„œ](https://kafka.apache.org/documentation/)
- [kafka-python ë¬¸ì„œ](https://kafka-python.readthedocs.io/)

