"""
ë¡œê·¸ì¸ í›„ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤íŒŒì´ë” (login_quotes)
- ItemLoaderì™€ QuotesItem í™œìš©
- 2-pass ë¡œê·¸ì¸ ë°©ì‹ (CSRF í† í° ì²˜ë¦¬)
- ë¡œê·¸ì¸ í›„ ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§
"""

import scrapy
from scrapy.loader import ItemLoader
from tutorial.items import QuotesItem
from scrapy.http import Request
from scrapy.http import FormRequest


class LoginQuotesSpider(scrapy.Spider):
    name = "login_quotes"
    start_urls = ["http://quotes.toscrape.com"]
    login_url = "http://quotes.toscrape.com/login"

    custom_settings = {
        "DUPEFILTER_CLASS": "scrapy.dupefilters.BaseDupeFilter",
        "COOKIES_ENABLED": True,
    }

    def start_requests(self):
        """ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™"""
        return [Request(self.login_url, callback=self.process_login)]

    def process_login(self, response):
        """CSRF í† í° ì¶”ì¶œ í›„ ë¡œê·¸ì¸ í¼ ì œì¶œ"""
        csrf_token = response.xpath(
            "//input[@name='csrf_token']/@value"
        ).extract_first()
        self.logger.info(f"ğŸ”‘ [process_login] csrf_token: {csrf_token}")

        yield FormRequest.from_response(
            response,
            formdata={
                "csrf_token": csrf_token,
                "username": "user",
                "password": "secret",
            },
            callback=self.parse,
        )

    def parse(self, response):
        """ë¡œê·¸ì¸ í›„ ë©”ì¸ í˜ì´ì§€ í¬ë¡¤ë§"""
        self.logger.info(f"ğŸ“– [parse] called while crawling {response.url}")

        # ë¡œê·¸ì¸ ì„±ê³µ í™•ì¸
        if "Logout" not in response.text:
            self.logger.error("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨!")
            return

        self.logger.info("âœ… ë¡œê·¸ì¸ ì„±ê³µ! ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")

        # quotes ìˆ˜ì§‘
        for q in response.css("div.quote"):
            loader = ItemLoader(item=QuotesItem(), selector=q)
            loader.add_css("quote_content", "span.text::text")
            loader.add_css("author_name", "small.author::text")
            loader.add_css("tags", "div.tags a.tag::text")

            current_quote = loader.load_item()

            # ì‘ê°€ í˜ì´ì§€ URL ì¶”ì¶œ
            author_url = q.css("small.author ~ a::attr(href)").get()
            if author_url:
                current_quote["author_url"] = response.urljoin(author_url)

            yield current_quote

        # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
        next_page = response.css("li.next a::attr(href)").get()
        if next_page:
            self.logger.info(f"â¡ï¸ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™: {next_page}")
            yield response.follow(next_page, callback=self.parse)
