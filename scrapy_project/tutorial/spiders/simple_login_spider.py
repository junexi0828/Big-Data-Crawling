"""
ê°„ë‹¨í•œ ë¡œê·¸ì¸ ì²˜ë¦¬ ë°ëª¨ (1-pass login)
- FormRequestë¡œ ì§ì ‘ ë¡œê·¸ì¸ í¼ ë°ì´í„° ì œì¶œ
- Hidden ë°ì´í„°ê°€ ë³µì¡í•˜ì§€ ì•Šì€ ê²½ìš° ì‚¬ìš©
- DUPEFILTER_CLASS ì„¤ì •ìœ¼ë¡œ ì¤‘ë³µ í•„í„° ë¹„í™œì„±í™”
"""

import scrapy
from scrapy.http import FormRequest


class SimpleLoginSpider(scrapy.Spider):
    name = "simple_login"
    start_urls = ["http://quotes.toscrape.com"]
    login_url = "http://quotes.toscrape.com/login"

    # ì¤‘ë³µ í•„í„° ë¹„í™œì„±í™” ì„¤ì •
    custom_settings = {
        "DUPEFILTER_CLASS": "scrapy.dupefilters.BaseDupeFilter",
        "COOKIES_ENABLED": True,
    }

    def start_requests(self):
        """ê°„ë‹¨í•œ 1-pass ë¡œê·¸ì¸: ì§ì ‘ í¼ ë°ì´í„° ì œì¶œ"""
        return [
            FormRequest(
                self.login_url,
                formdata={"username": "user", "password": "secret"},
                callback=self.parse,
            )
        ]

    def parse(self, response):
        """ë¡œê·¸ì¸ í›„ ë©”ì¸ í˜ì´ì§€ ì²˜ë¦¬"""
        self.logger.info(f"ğŸ  ë©”ì¸ í˜ì´ì§€ ë„ì°©: {response.url}")

        # ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        if "Logout" in response.text:
            self.logger.info("âœ… ê°„ë‹¨ ë¡œê·¸ì¸ ì„±ê³µ!")

            # quotes ìˆ˜ì§‘
            quotes = response.css("div.quote")
            for quote in quotes[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                text = quote.css("span.text::text").get()
                author = quote.css("small.author::text").get()
                tags = quote.css("div.tags a.tag::text").getall()

                yield {
                    "method": "simple_login",
                    "text": text,
                    "author": author,
                    "tags": tags,
                    "login_status": "success",
                }

        else:
            self.logger.error("âŒ ê°„ë‹¨ ë¡œê·¸ì¸ ì‹¤íŒ¨")
            yield {
                "method": "simple_login",
                "login_status": "failed",
                "url": response.url,
                "status": response.status,
            }
