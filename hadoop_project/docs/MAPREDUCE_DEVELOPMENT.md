# MapReduce ê°œë°œ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” Hadoop MapReduce ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [MapReduce ê¸°ë³¸ ê°œë…](#mapreduce-ê¸°ë³¸-ê°œë…)
2. [ê°œë°œ í™˜ê²½ ì„¤ì •](#ê°œë°œ-í™˜ê²½-ì„¤ì •)
3. [MapReduce ê°œë°œ ë‹¨ê³„](#mapreduce-ê°œë°œ-ë‹¨ê³„)
4. [ì˜ˆì œ í”„ë¡œê·¸ë¨](#ì˜ˆì œ-í”„ë¡œê·¸ë¨)
5. [ì‹¤í–‰ ë°©ë²•](#ì‹¤í–‰-ë°©ë²•)

---

## MapReduce ê¸°ë³¸ ê°œë…

### MapReduceë€?

MapReduceëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì‚° í™˜ê²½ì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í”„ë¡œê·¸ë˜ë° ëª¨ë¸ì…ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•:**

1. **ë°ì´í„° ì´ë™ ìµœì†Œí™”**: ì²˜ë¦¬ ì½”ë“œê°€ ë°ì´í„°ê°€ ìˆëŠ” ì„œë²„ë¡œ ì´ë™

   - ê¸°ì¡´ R-DB: ë°ì´í„°ê°€ ì²˜ë¦¬ ë¡œì§ìœ¼ë¡œ ì´ë™
   - MapReduce: í”„ë¡œê·¸ë¨ì´ ë°ì´í„° ë…¸ë“œë¡œ ì´ë™

2. **<Key, Value> ê¸°ë°˜ ì²˜ë¦¬**

   - ì…ë ¥: `<Keyâ‚, Valueâ‚>` â†’ `<Keyâ‚‚, Valueâ‚‚>` ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
   - ì¶œë ¥: `<Keyâ‚‚, List<Valueâ‚‚>>` â†’ `<Keyâ‚ƒ, Valueâ‚ƒ>` ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

3. **Share Nothing êµ¬ì¡°**

   - Map Taskì™€ Reduce Task ê°„ ë°ì´í„° ê³µìœ  ì—†ìŒ
   - ê° ë‹¨ê³„ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ë°ì´í„° ë¸”ë¡ ì²˜ë¦¬
   - ì²˜ë¦¬ ê²°ê³¼ëŠ” HDFSì— ì €ì¥ ë° ë³µì œ

4. **ë°°ì¹˜ ì²˜ë¦¬ì— ìµœì í™”**
   - ì‹¤ì‹œê°„ ì²˜ë¦¬ì—ëŠ” ë¹„íš¨ìœ¨ì  (â†’ Spark: ë§ˆì´í¬ë¡œ ë°°ì¹˜ ì²˜ë¦¬)
   - ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ë°°ì¹˜ ì²˜ë¦¬ì— ê°•ì 

### MapReduce ì²˜ë¦¬ ë‹¨ê³„

**WordCount ì˜ˆì œë¥¼ í†µí•œ ì²˜ë¦¬ íë¦„:**

```
Input â†’ Splitting â†’ Mapping â†’ Shuffling â†’ Reducing â†’ Result
```

1. **Input**: ì›ë³¸ ë°ì´í„°

   ```
   Deer Bear Lake
   Car Car Lake
   Deer Car Bear
   ```

2. **Splitting**: ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë¸”ë¡ìœ¼ë¡œ ë¶„í• 

3. **Mapping**: ê° ë‹¨ì–´ë¥¼ `<word, 1>` í˜•íƒœë¡œ ë³€í™˜

   - `Deer 1`, `Bear 1`, `Lake 1`
   - `Car 1`, `Car 1`, `Lake 1`
   - `Deer 1`, `Car 1`, `Bear 1`

4. **Shuffling**: ê°™ì€ í‚¤ë¥¼ ê°€ì§„ ê°’ë“¤ì„ ê·¸ë£¹í™”

   - `Bear: [1, 1]`
   - `Car: [1, 1, 1]`
   - `Deer: [1, 1]`
   - `Lake: [1, 1]`

5. **Reducing**: ê° í‚¤ì˜ ê°’ë“¤ì„ ì§‘ê³„

   - `Bear 2`
   - `Car 3`
   - `Deer 2`
   - `Lake 2`

6. **Result**: ìµœì¢… ê²°ê³¼ ì¶œë ¥

---

## ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. Eclipse IDEì—ì„œ Maven í”„ë¡œì íŠ¸ ìƒì„±

1. **New Maven Project ìƒì„±**

   - `File â†’ New â†’ Other... â†’ Maven â†’ Maven Project`
   - `Use default Workspace location` ì²´í¬ â†’ `Next`

2. **Archetype ì„ íƒ**

   - Catalog: `Internal`
   - Archetype: `org.apache.maven.archetypes:maven-archetype-quickstart:1.1`

3. **í”„ë¡œì íŠ¸ ì •ë³´ ì…ë ¥**
   - Group Id: `bigdata`
   - Artifact Id: `hadoop.demo`
   - Version: `0.0.1-SNAPSHOT`

### 2. Maven ì˜ì¡´ì„± ì¶”ê°€

`pom.xml`ì— ë‹¤ìŒ ì˜ì¡´ì„±ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```xml
<dependencies>
    <!-- JUnit (í…ŒìŠ¤íŠ¸ìš©) -->
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>3.8.1</version>
        <scope>test</scope>
    </dependency>

    <!-- Log4j SLF4J Binding -->
    <dependency>
        <groupId>org.apache.logging.log4j</groupId>
        <artifactId>log4j-slf4j2-impl</artifactId>
        <version>2.25.0</version>
        <scope>compile</scope>
    </dependency>

    <!-- Apache Hadoop Common -->
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-common</artifactId>
        <version>3.4.1</version>
    </dependency>

    <!-- Apache Hadoop HDFS Client -->
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-hdfs-client</artifactId>
        <version>3.4.1</version>
    </dependency>

    <!-- Apache Hadoop MapReduce Common -->
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-mapreduce-client-common</artifactId>
        <version>3.4.1</version>
        <scope>compile</scope>
    </dependency>

    <!-- Apache Hadoop MapReduce JobClient -->
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
        <version>3.4.1</version>
        <scope>compile</scope>
    </dependency>
</dependencies>
```

### 3. Log4j ì„¤ì •

`src/main/resources/log4j.properties` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```properties
hadoop.root.logger=INFO, CONSOLE
hadoop.console.threshold=INFO
log4j.rootLogger=${hadoop.root.logger}
log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender
log4j.appender.CONSOLE.Threshold=${hadoop.console.threshold}
log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout
log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %-5p [%C]: %m%n
```

ì´ ì„¤ì •ì€ Hadoopì˜ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ë¡œê·¸ ì¶œë ¥ì„ ì œì–´í•©ë‹ˆë‹¤.

---

## MapReduce ê°œë°œ ë‹¨ê³„

### 1. <Key, Value> I/O êµ¬ì¡° ì„¤ê³„

ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  Key-Value ìŒì˜ êµ¬ì¡°ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ (WordCount):**

- Map ì…ë ¥: `<LongWritable, Text>` (ì¤„ ë²ˆí˜¸, ì¤„ ë‚´ìš©)
- Map ì¶œë ¥: `<Text, IntWritable>` (ë‹¨ì–´, 1)
- Reduce ì…ë ¥: `<Text, Iterable<IntWritable>>` (ë‹¨ì–´, [1, 1, ...])
- Reduce ì¶œë ¥: `<Text, IntWritable>` (ë‹¨ì–´, ì´ ê°œìˆ˜)

### 2. Mapper í´ë˜ìŠ¤ êµ¬í˜„

`org.apache.hadoop.mapreduce.Mapper`ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•©ë‹ˆë‹¤.

```java
public static class TokenizerMapper
    extends Mapper<Object, Text, Text, IntWritable> {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context)
            throws IOException, InterruptedException {
        StringTokenizer itr = new StringTokenizer(value.toString());
        while (itr.hasMoreTokens()) {
            word.set(itr.nextToken());
            context.write(word, one);
        }
    }
}
```

### 3. Reducer í´ë˜ìŠ¤ êµ¬í˜„

`org.apache.hadoop.mapreduce.Reducer`ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•©ë‹ˆë‹¤.

```java
public static class IntSumReducer
    extends Reducer<Text, IntWritable, Text, IntWritable> {

    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable<IntWritable> values,
            Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values)
            sum += val.get();
        result.set(sum);
        context.write(key, result);
    }
}
```

### 4. Driver í´ë˜ìŠ¤ ì‘ì„±

`org.apache.hadoop.mapreduce.Job` ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤.

```java
public static void main(String[] args) {
    Configuration conf = new Configuration();
    conf.set("fs.defaultFS", "hdfs://bigpie1:9000");
    conf.set("mapreduce.framework.name", "yarn");
    conf.set("yarn.resourcemanager.hostname", "bigpie1");

    Job job = Job.getInstance(conf, "Word Count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    System.exit(job.waitForCompletion(true) ? 0 : 1);
}
```

### 5. JAR íŒŒì¼ ë¹Œë“œ ë° ì‹¤í–‰

```bash
# Mavenìœ¼ë¡œ ë¹Œë“œ
mvn clean package

# Hadoopì—ì„œ ì‹¤í–‰
$HADOOP_HOME/bin/hadoop jar target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.WordCount \
    /wordcount/input /wordcount/output
```

---

## ì˜ˆì œ í”„ë¡œê·¸ë¨

### 1. WordCount

ë‹¨ì–´ ë¹ˆë„ë¥¼ ê³„ì‚°í•˜ëŠ” MapReduce í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.

**íŒŒì¼ ìœ„ì¹˜**: `examples/src/main/java/bigdata/hadoop/demo/WordCount.java`

**ì‹¤í–‰ ë°©ë²•:**

```bash
# 1. ì…ë ¥ íŒŒì¼ ì¤€ë¹„
hdfs dfs -mkdir -p /wordcount/input
echo "Hello Hadoop Bye Bye" > file01.txt
echo "This is a test for mapreduce" >> file01.txt
echo "Hello Hadoop Bye Hadoop" > file02.txt
echo "This is another test for hadoop" >> file02.txt

# 2. HDFSì— ì—…ë¡œë“œ
hdfs dfs -put file*.txt /wordcount/input

# 3. WordCount ì‹¤í–‰
hadoop jar hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.WordCount \
    /wordcount/input /wordcount/output

# 4. ê²°ê³¼ í™•ì¸
hdfs dfs -cat /wordcount/output/part-r-00000
```

**ì˜ˆìƒ ê²°ê³¼:**

```
Bye        3
Hadoop     3
Hello      2
This       2
a          1
another    1
for        2
hadoop     1
is         2
mapreduce  1
test       2
```

### 2. URLAccess

URLì„ í†µí•´ HDFS íŒŒì¼ì— ì ‘ê·¼í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

**íŒŒì¼ ìœ„ì¹˜**: `examples/src/main/java/bigdata/hadoop/demo/URLAccess.java`

**ì‹¤í–‰ ë°©ë²•:**

```bash
# HDFS ê²½ë¡œë§Œ ì „ë‹¬ (í”„ë¡œí† ì½œê³¼ ì„œë²„ëŠ” ì½”ë“œì—ì„œ ìë™ ì¶”ê°€)
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.URLAccess \
    /user/bigdata/input/README.txt
```

**Eclipseì—ì„œ ì‹¤í–‰:**

1. `Run As â†’ Run Configurations...`
2. `Arguments` íƒ­ì—ì„œ `Program arguments` ì…ë ¥: `/user/bigdata/input/README.txt`
3. ì‹¤í–‰

**ì£¼ì˜ì‚¬í•­:**

- í”„ë¡œê·¸ë¨ ì¸ìëŠ” HDFS ê²½ë¡œë§Œ ì „ë‹¬ (ì˜ˆ: `/user/bigdata/input/README.txt`)
- ì½”ë“œì—ì„œ ìë™ìœ¼ë¡œ `hdfs://bigpie1:9000`ê°€ ì•ì— ë¶™ìŠµë‹ˆë‹¤
- ì‹¤í–‰ ì „ì— í•´ë‹¹ íŒŒì¼ì´ HDFSì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤

### 3. PutFile

ë¡œì»¬ íŒŒì¼ì„ HDFSì— ì—…ë¡œë“œí•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

**íŒŒì¼ ìœ„ì¹˜**: `examples/src/main/java/bigdata/hadoop/demo/PutFile.java`

**ì‹¤í–‰ ë°©ë²•:**

```bash
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.PutFile \
    <local_file_path> <hdfs_file_path>
```

**ì˜ˆì‹œ:**

```bash
# Windows ê²½ë¡œ ì˜ˆì‹œ
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.PutFile \
    C:/Temp/afile.jar \
    hdfs://bigpie1:9000/user/minsky/bfile.jar

# Linux/Mac ê²½ë¡œ ì˜ˆì‹œ
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.PutFile \
    /tmp/local_file.txt \
    hdfs://bigpie1:9000/user/bigdata/remote_file.txt
```

**ì£¼ì˜ì‚¬í•­:**

- ì²« ë²ˆì§¸ ì¸ì: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì˜ íŒŒì¼ ê²½ë¡œ
- ë‘ ë²ˆì§¸ ì¸ì: HDFSì— ì €ì¥í•  ì „ì²´ ê²½ë¡œ (í”„ë¡œí† ì½œ í¬í•¨)
- ì—…ë¡œë“œ ì§„í–‰ ìƒí™©ì€ ì½˜ì†”ì— `.`ë¡œ í‘œì‹œë©ë‹ˆë‹¤

### 4. FileSystemAccess

FileSystem APIë¥¼ ì‚¬ìš©í•˜ì—¬ HDFS íŒŒì¼ì— ì ‘ê·¼í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

**íŒŒì¼ ìœ„ì¹˜**: `examples/src/main/java/bigdata/hadoop/demo/FileSystemAccess.java`

**ì‹¤í–‰ ë°©ë²•:**

```bash
# ì „ì²´ HDFS URI ë˜ëŠ” ê²½ë¡œë§Œ ì „ë‹¬ ê°€ëŠ¥
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.FileSystemAccess \
    hdfs://bigpie1:9000/user/bigdata/input/README.txt

# ë˜ëŠ” ê²½ë¡œë§Œ ì „ë‹¬ (ì½”ë“œì—ì„œ fs.defaultFS ì‚¬ìš©)
java -cp target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.FileSystemAccess \
    /user/bigdata/input/README.txt
```

**Eclipseì—ì„œ ì‹¤í–‰:**

1. `Run As â†’ Run Configurations...`
2. `Arguments` íƒ­ì—ì„œ `Program arguments` ì…ë ¥: `/user/bigdata/input/README.txt`
3. ì‹¤í–‰

---

## ì‹¤í–‰ ë°©ë²•

### 1. ê¸°ë³¸ WordCount ì˜ˆì œ (Hadoop ì œê³µ)

Hadoopì´ ì œê³µí•˜ëŠ” ì˜ˆì œ JARë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# ì˜ˆì œ ëª©ë¡ í™•ì¸
$HADOOP_HOME/bin/hadoop jar \
    $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar

# WordCount ì‹¤í–‰
$HADOOP_HOME/bin/hadoop jar \
    $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar \
    wordcount /wordcount/input /wordcount/output
```

### 2. ì»¤ìŠ¤í…€ MapReduce í”„ë¡œê·¸ë¨ ì‹¤í–‰

**Maven í”„ë¡œì íŠ¸ ë¹Œë“œ:**

```bash
cd examples
mvn clean package
```

**JAR íŒŒì¼ ì‹¤í–‰:**

```bash
# Single-Node Cluster
$HADOOP_HOME/bin/hadoop jar \
    target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.WordCount \
    /wordcount/input /wordcount/output

# Multi-Node Cluster
$HADOOP_HOME/bin/hadoop jar \
    target/hadoop.demo-0.0.1-SNAPSHOT.jar \
    bigdata.hadoop.demo.WordCount \
    /wordcount/input /wordcount/output

# ë˜ëŠ” ê°„ë‹¨í•˜ê²Œ (ë©”ì¸ í´ë˜ìŠ¤ê°€ ì§€ì •ëœ ê²½ìš°)
hadoop jar wc_v2.jar input result
```

### 3. Eclipseì—ì„œ Runnable JAR ìƒì„± ë° ë°°í¬

**Runnable JAR íŒŒì¼ ìƒì„±:**

1. **í”„ë¡œì íŠ¸ ìš°í´ë¦­ â†’ Export â†’ Java â†’ Runnable JAR file**
2. **Launch configuration**: ì‹¤í–‰í•  ë©”ì¸ í´ë˜ìŠ¤ ì„ íƒ (ì˜ˆ: `WordCount - hadoop.demo`)
3. **Export destination**: JAR íŒŒì¼ ì €ì¥ ê²½ë¡œ ì§€ì • (ì˜ˆ: `wc_v2.jar`)
4. **Library handling**: `Copy required libraries into a sub-folder next to the generated JAR` ì„ íƒ
5. **Finish** í´ë¦­

**SFTPë¥¼ í†µí•œ í´ëŸ¬ìŠ¤í„° ë°°í¬:**

```bash
# SFTPë¡œ bigpie1ì— ì—°ê²°
sftp bigdata@bigpie1

# JAR íŒŒì¼ ì „ì†¡
put wc_v2.jar

# ë¼ì´ë¸ŒëŸ¬ë¦¬ í´ë” ì „ì†¡
put -r wc_v2_lib

# ì¢…ë£Œ
exit
```

**í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰:**

```bash
# bigpie1ì— SSH ì ‘ì†
ssh bigdata@bigpie1

# WordCount ì‹¤í–‰
hadoop jar wc_v2.jar input result
```

### 4. ì‹¤í–‰ ê²°ê³¼ í™•ì¸

**ëª…ë ¹ì–´ë¥¼ í†µí•œ í™•ì¸:**

```bash
# ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
hdfs dfs -ls /wordcount/output/

# ê²°ê³¼ íŒŒì¼ í™•ì¸
hdfs dfs -cat /wordcount/output/part-r-00000

# _SUCCESS íŒŒì¼ í™•ì¸ (ì‘ì—… ì„±ê³µ ì—¬ë¶€)
hdfs dfs -cat /wordcount/output/_SUCCESS
```

**ì›¹ UIë¥¼ í†µí•œ í™•ì¸:**

1. **NameNode ì›¹ UI**: `http://bigpie1:9870/`

   - HDFS íŒŒì¼ ì‹œìŠ¤í…œ ë¸Œë¼ìš°ì§•
   - ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸: `/user/bigdata/result`
   - `_SUCCESS` íŒŒì¼ê³¼ `part-r-00000` íŒŒì¼ í™•ì¸
   - íŒŒì¼ í¬ê¸°, ë³µì œ ìˆ˜, ë¸”ë¡ í¬ê¸° ë“± ë©”íƒ€ë°ì´í„° í™•ì¸

2. **ResourceManager ì›¹ UI**: `http://bigpie1:8088/`

   - YARN ì‘ì—… ìƒíƒœ í™•ì¸
   - ì‘ì—… ì´ë ¥ ë° ë¡œê·¸ í™•ì¸
   - ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

3. **JobHistory ì›¹ UI**: `http://bigpie1:19888/`
   - MapReduce ì‘ì—… ì´ë ¥ ìƒì„¸ í™•ì¸
   - ì‘ì—… ì‹¤í–‰ ì‹œê°„, íƒœìŠ¤í¬ ì •ë³´ ë“±

---

## Runtime Environment

### JobTrackerì™€ TaskTracker

**Hadoop 1.x ì•„í‚¤í…ì²˜:**

```
Client
  â†“
JobTracker (NameNode)
  â†“
TaskTracker (DataNode)
  â”œâ”€â”€ Map Tasks
  â””â”€â”€ Reduce Tasks
```

- **JobTracker**: ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ë° ê´€ë¦¬
- **TaskTracker**: ì‹¤ì œ Map/Reduce ì‘ì—… ì‹¤í–‰

**Hadoop 2.x+ (YARN) ì•„í‚¤í…ì²˜:**

```
Client
  â†“
ResourceManager
  â†“
NodeManager
  â”œâ”€â”€ Map Tasks
  â””â”€â”€ Reduce Tasks
```

- **ResourceManager**: ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§
- **NodeManager**: ì»¨í…Œì´ë„ˆ ê´€ë¦¬ ë° ì‘ì—… ì‹¤í–‰

---

## ì°¸ê³  ìë£Œ

- [Apache Hadoop MapReduce Tutorial](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
- [Hadoop API Documentation](https://hadoop.apache.org/docs/current/api/)
- [Maven Repository - Hadoop](https://mvnrepository.com/artifact/org.apache.hadoop)

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Native Library ê²½ê³ 

```
WARN util.NativeCodeLoader: Unable to load native-hadoop library
```

**í•´ê²° ë°©ë²•:** ì´ ê²½ê³ ëŠ” ë¬´ì‹œí•´ë„ ë©ë‹ˆë‹¤. Java í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‘í•©ë‹ˆë‹¤.

### 2. Connection Timeout

```
java.net.ConnectException: Connection refused
```

**í•´ê²° ë°©ë²•:**

- HDFS ë°ëª¬ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: `jps`
- `core-site.xml`ì˜ `fs.defaultFS` ì„¤ì • í™•ì¸
- ë°©í™”ë²½ ì„¤ì • í™•ì¸

### 3. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

```
java.lang.OutOfMemoryError: Java heap space
```

**í•´ê²° ë°©ë²•:**

- `mapred-site.xml`ì—ì„œ ë©”ëª¨ë¦¬ ì„¤ì • ì¦ê°€
- `mapreduce.map.memory.mb`: 256 â†’ 512
- `mapreduce.reduce.memory.mb`: 256 â†’ 512

### 4. Staging Directory ìƒì„± ì‹¤íŒ¨

```
Exception: staging dir/file creation failure
```

**ì›ì¸:** YARN Application Masterê°€ staging ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í•¨

**í•´ê²° ë°©ë²•:**

`mapred-site.xml`ì— ë‹¤ìŒ ì„¤ì • ì¶”ê°€:

```xml
<configuration>
    <!-- Job History ì„¤ì • -->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>bigpie1:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>bigpie1:19888</value>
    </property>

    <!-- Staging Directory ì„¤ì • (ì¤‘ìš”!) -->
    <property>
        <name>yarn.app.mapreduce.am.staging-dir</name>
        <value>/user/${user.name}/.staging</value>
    </property>

    <!-- YARN Application Master ë¦¬ì†ŒìŠ¤ ì„¤ì • -->
    <property>
        <name>yarn.app.mapreduce.am.resource.mb</name>
        <value>512</value>
    </property>

    <!-- Map/Reduce ë©”ëª¨ë¦¬ ì„¤ì • -->
    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>256</value>
    </property>
    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>256</value>
    </property>

    <!-- MapReduce í´ë˜ìŠ¤íŒ¨ìŠ¤ ì„¤ì • -->
    <property>
        <name>mapreduce.application.classpath</name>
        <value>/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

**ì¶”ê°€ í™•ì¸ ì‚¬í•­:**

- ì‚¬ìš©ì ë””ë ‰í† ë¦¬ê°€ HDFSì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸: `hdfs dfs -ls /user/${user.name}`
- Staging ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸: `hdfs dfs -chmod 755 /user/${user.name}/.staging`

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ë³µì¡í•œ MapReduce ì‘ì—… êµ¬í˜„**

   - Secondary Sort
   - Join ì—°ì‚°
   - Aggregation

2. **ì„±ëŠ¥ ìµœì í™”**

   - Combiner ì‚¬ìš©
   - Partitioner ì»¤ìŠ¤í„°ë§ˆì´ì§•
   - InputFormat/OutputFormat ì»¤ìŠ¤í„°ë§ˆì´ì§•

3. **ê³ ê¸‰ ê¸°ëŠ¥**
   - Counters ì‚¬ìš©
   - DistributedCache í™œìš©
   - Multiple Inputs/Outputs
