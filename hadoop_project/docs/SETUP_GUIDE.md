# Hadoop ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [ì‚¬ì „ ì¤€ë¹„ì‚¬í•­](#ì‚¬ì „-ì¤€ë¹„ì‚¬í•­)
2. [Local (Standalone) Mode Setup](#local-standalone-mode-setup)
3. [Single-Node Cluster Mode Setup (w/o YARN)](#single-node-cluster-mode-setup-wo-yarn)
4. [Single-Node Cluster Mode Setup (with YARN)](#single-node-cluster-mode-setup-with-yarn)
5. [Multi-Node Cluster Mode Setup](#multi-node-cluster-mode-setup)

---

## ì‚¬ì „ ì¤€ë¹„ì‚¬í•­

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- **JDK**: v8 ì´ìƒ ë˜ëŠ” v11 ì´ìƒ
- **OS**: Linux+ ë˜ëŠ” Windows with WSL
- **SSH**: íŒ¨ìŠ¤ì›Œë“œ ì—†ëŠ” SSH í™˜ê²½ êµ¬ì„±

### 3ê°€ì§€ ëª¨ë“œ ë¹„êµ

| ëª¨ë“œ                                         | ì„¤ëª…                                            | ìš©ë„               |
| -------------------------------------------- | ----------------------------------------------- | ------------------ |
| **Local (Standalone)**                       | ë‹¨ì¼ Java í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰                       | ë””ë²„ê¹…ìš©           |
| **Single-Node Cluster (Pseudo-Distributed)** | ë‹¨ì¼ ë¨¸ì‹ ì—ì„œ ëª¨ë“  Hadoop ë°ëª¬ ì‹¤í–‰             | í•™ìŠµ, ê°œë°œ, í…ŒìŠ¤íŠ¸ |
| **Multi-Node Cluster (Fully-Distributed)**   | í”„ë¡œë•ì…˜ê¸‰ ì„¤ì • (10 Gbps+ ëŒ€ì—­í­, 16GB+ ë©”ëª¨ë¦¬) | í”„ë¡œë•ì…˜ í™˜ê²½      |

---

## Local (Standalone) Mode Setup

### íŠ¹ì§•

- ë‹¤ìš´ë¡œë“œí•œ ë°”ì´ë„ˆë¦¬ì˜ ê¸°ë³¸ ì„¤ì • ëª¨ë“œ
- ë‹¨ì¼ Java í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰
- ë””ë²„ê¹…ì— ìœ ìš©

### ì„¤ì • ë‹¨ê³„

#### 1. Hadoop ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ

```bash
# Hadoop ë‹¤ìš´ë¡œë“œ (ì˜ˆ: 3.4.1)
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz

# ì••ì¶• í•´ì œ
tar -zxvf hadoop-3.4.1.tar.gz

# Hadoop ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd hadoop-3.4.1
```

#### 2. JAVA_HOME ì„¤ì •

`./etc/hadoop/hadoop-env.sh` ë˜ëŠ” `hadoop-env.cmd` íŒŒì¼ í¸ì§‘:

```bash
# ì˜ˆì‹œ (macOS)
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-11.0.12.jdk/Contents/Home

# ì˜ˆì‹œ (Linux)
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
```

#### 3. ë²„ì „ í™•ì¸

```bash
bin/hadoop version
```

### ì˜ˆì œ ì‹¤í–‰

#### Wordcount ì˜ˆì œ

```bash
# ì…ë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir input

# ìƒ˜í”Œ íŒŒì¼ ìƒì„±
echo "Hello Hadoop Bye Bye This is a test for mapreduce" > input/file01.txt
echo "Hello Hadoop Bye Hadoop This is another test for hadoop" > input/file02.txt

# Wordcount ì‘ì—… ì‹¤í–‰
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar wordcount input output

# ê²°ê³¼ í™•ì¸
cat ./output/part-r-00000
```

#### Pi ì˜ˆì œ (Monte Carlo ì‹œë®¬ë ˆì´ì…˜)

```bash
# Pi ê³„ì‚° (ë§µ ìˆ˜, ë§µë‹¹ í¬ì¸íŠ¸ ìˆ˜)
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar pi 10 1000
```

---

## Single-Node Cluster Mode Setup (w/o YARN)

### íŠ¹ì§•

- ë‹¨ì¼ ë¨¸ì‹ ì—ì„œ ëª¨ë“  Hadoop ë°ëª¬ ì‹¤í–‰
- NameNode, DataNodeë§Œ ì‹¤í–‰ (YARN ì—†ìŒ)
- í•™ìŠµ ë° ê°œë°œì— ì´ìƒì 

### ì„¤ì • ë‹¨ê³„

#### 1. Hadoop ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ

```bash
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz
tar -zxvf hadoop-3.4.1.tar.gz
cd hadoop-3.4.1
```

#### 2. JAVA_HOME ì„¤ì •

`./etc/hadoop/hadoop-env.sh` í¸ì§‘:

```bash
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
```

#### 3. ì„¤ì • íŒŒì¼ í¸ì§‘

##### core-site.xml

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

##### hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

#### 4. íŒ¨ìŠ¤ì›Œë“œ ì—†ëŠ” SSH ë¡œê·¸ì¸ ì„¤ì •

```bash
# RSA í‚¤ ìŒ ìƒì„±
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa

# ìƒì„±ëœ í‚¤ ì¶”ê°€
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

# í‚¤ íŒŒì¼ ë³´í˜¸
chmod 0600 ~/.ssh/authorized_keys

# ë¡œê·¸ì¸ í…ŒìŠ¤íŠ¸
ssh localhost
```

#### 5. íŒŒì¼ì‹œìŠ¤í…œ í¬ë§·

```bash
bin/hdfs namenode -format -force
```

#### 6. NameNode & DataNode ë°ëª¬ ì‹œì‘

```bash
sbin/start-dfs.sh
```

#### 7. NameNode ì›¹ ì¸í„°í˜ì´ìŠ¤ í™•ì¸

ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:

```
http://localhost:9870/
```

#### 8. HDFS ë””ë ‰í† ë¦¬ ìƒì„±

```bash
bin/hdfs dfs -mkdir -p /user/bigdata/input
bin/hdfs dfs -ls
```

#### 9. ìƒ˜í”Œ íŒŒì¼ì„ HDFSì— ì—…ë¡œë“œ

```bash
bin/hdfs dfs -put *.txt input
bin/hdfs dfs -ls input
```

#### 10. Wordcount ì˜ˆì œ ì‹¤í–‰

```bash
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar wordcount input output

# ê²°ê³¼ í™•ì¸ (ë¡œì»¬ë¡œ ê°€ì ¸ì˜¤ê¸°)
bin/hdfs dfs -get output result
cat result/*

# ë˜ëŠ” HDFSì—ì„œ ì§ì ‘ í™•ì¸
bin/hdfs dfs -cat output/*
```

#### 11. ë°ëª¬ ì¤‘ì§€

```bash
sbin/stop-dfs.sh
```

### í”„ë¡œì„¸ìŠ¤ í™•ì¸

```bash
jps
```

ì˜ˆìƒ ì¶œë ¥:

```
93572 Jps
90792 DataNode
90922 SecondaryNameNode
90717 NameNode
```

---

## Single-Node Cluster Mode Setup (with YARN)

### íŠ¹ì§•

- YARNì„ í¬í•¨í•œ ì™„ì „í•œ í´ëŸ¬ìŠ¤í„° ëª¨ë“œ
- ResourceManager, NodeManager ì¶”ê°€ ì‹¤í–‰

### ì¶”ê°€ ì„¤ì • ë‹¨ê³„

#### 1. JDK ì„¤ì¹˜ (v8 ë˜ëŠ” v11)

```bash
# ì˜ˆì‹œ: BellSoft JDK 8 ì„¤ì¹˜
wget https://download.bell-sw.com/java/8u452+11/bellsoft-jdk8u452+11-linux-aarch64.deb
sudo apt install ./bellsoft-jdk8u452+11-linux-aarch64.deb
sudo update-alternatives --config java
```

#### 2. JAVA_HOME ì„¤ì •

`./etc/hadoop/hadoop-env.sh` í¸ì§‘:

```bash
export JAVA_HOME=/usr/lib/jvm/bellsoft-java8-aarch64
```

#### 3. ì„¤ì • íŒŒì¼ í¸ì§‘

##### mapred-site.xml

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>/home/bigdata/hadoop-3.4.1/share/hadoop/mapreduce/*</value>
    </property>
</configuration>
```

##### yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
    </property>
</configuration>
```

#### 4. ResourceManager ë° NodeManager ì‹œì‘

```bash
sbin/start-yarn.sh
```

#### 5. ResourceManager ì›¹ ì¸í„°í˜ì´ìŠ¤ í™•ì¸

ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:

```
http://localhost:8088/
```

#### 6. Wordcount ì˜ˆì œ ì‹¤í–‰

```bash
# ê¸°ì¡´ output í´ë” ì‚­ì œ (ìˆëŠ” ê²½ìš°)
bin/hdfs dfs -rm -r output

# Wordcount ì‹¤í–‰
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.1.jar wordcount input output
```

#### 7. ëª¨ë“  ë°ëª¬ ì¤‘ì§€

```bash
sbin/stop-yarn.sh && sbin/stop-dfs.sh
```

### í”„ë¡œì„¸ìŠ¤ í™•ì¸

```bash
jps
```

ì˜ˆìƒ ì¶œë ¥:

```
3504 Jps
2883 NodeManager
2389 DataNode
2005 ResourceManager
2534 SecondaryNameNode
2313 NameNode
```

---

## Multi-Node Cluster Mode Setup

### ë…¸ë“œ êµ¬ì„± ì˜ˆì‹œ

- **NameNode**: bigpie1
- **DataNode**: bigpie2, bigpie3, bigpie4

### ì„¤ì • ë‹¨ê³„

#### 1. ì‚¬ì „ ì¤€ë¹„ì‚¬í•­

```bash
# Java v8 (ë˜ëŠ” v11), ssh, pdsh ì„¤ì¹˜ í™•ì¸
sudo apt install ssh pdsh
```

#### 2. /etc/hosts íŒŒì¼ í¸ì§‘

ê° ë…¸ë“œì—ì„œ `/etc/hosts` íŒŒì¼ í¸ì§‘:

**bigpie1, bigpie2, bigpie3, bigpie4 ëª¨ë‘ ë™ì¼í•˜ê²Œ:**

```
# ê¸°ë³¸ localhost í•­ëª© ì£¼ì„ ì²˜ë¦¬
#127.0.0.1 localhost
#::1 localhost ip6-localhost ip6-loopback
#ff02::1 ip6-allnodes
#ff02::2 ip6-allrouters

# í´ëŸ¬ìŠ¤í„° IP ì£¼ì†Œ ë° í˜¸ìŠ¤íŠ¸ëª…
192.168.0.40 bigpie1
192.168.0.41 bigpie2
192.168.0.42 bigpie3
192.168.0.43 bigpie4
```

#### 3. SSH ë³„ì¹­ ì„¤ì • (bigpie1 ~ bigpie4)

**bigpie1ì—ì„œ:**

```bash
nano ~/.ssh/config
```

**config íŒŒì¼ ë‚´ìš©:**

```
Host bigpie1
    User bigdata
    Hostname 192.168.0.40

Host bigpie2
    User bigdata
    Hostname 192.168.0.41

Host bigpie3
    User bigdata
    Hostname 192.168.0.42

Host bigpie4
    User bigdata
    Hostname 192.168.0.43
```

**ë‹¤ë¥¸ ë…¸ë“œë¡œ ë³µì‚¬:**

```bash
scp ~/.ssh/config bigpie2:~/.ssh/config
scp ~/.ssh/config bigpie3:~/.ssh/config
scp ~/.ssh/config bigpie4:~/.ssh/config
```

#### 4. íŒ¨ìŠ¤ì›Œë“œ ì—†ëŠ” SSH ì¸ì¦ ì„¤ì •

**bigpie1 ~ bigpie4ì—ì„œ í‚¤ ìƒì„±:**

```bash
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
```

**bigpie1ì—ì„œ í‚¤ ìˆ˜ì§‘:**

```bash
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```

**bigpie2 ~ bigpie4ì—ì„œ bigpie1ë¡œ í‚¤ ë³µì‚¬:**

```bash
ssh-copy-id bigpie1
```

**bigpie1ì—ì„œ ìˆ˜ì§‘ëœ í‚¤ë¥¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ë°°í¬:**

```bash
scp ~/.ssh/authorized_keys bigpie2:~/.ssh/authorized_keys
scp ~/.ssh/authorized_keys bigpie3:~/.ssh/authorized_keys
scp ~/.ssh/authorized_keys bigpie4:~/.ssh/authorized_keys
```

**í…ŒìŠ¤íŠ¸:**

```bash
# bigpie2 ~ bigpie4ì—ì„œ
ssh bigpie1
```

#### 5. í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ëª…ë ¹ì–´ ì¶”ê°€ (bigpie1)

`~/.bashrc` íŒŒì¼ì— ì¶”ê°€:

```bash
function others {
    grep "bigpie" /etc/hosts | awk '{print $2}' | grep -v $(hostname)
}

function cluster_run {
    for x in $(others); do ssh $x "$@"; done
    $@
}

function cluster_reboot {
    cluster_run sudo shutdown -r now
}

function cluster_shutdown {
    cluster_run sudo shutdown now
}

function cluster_scp {
    for x in $(others); do
        cat $1 | ssh $x "sudo tee $1" > /dev/null 2>&1
    done
}
```

**ì ìš©:**

```bash
source .bashrc
cluster_run date  # í…ŒìŠ¤íŠ¸
```

**ë‹¤ë¥¸ ë…¸ë“œë¡œ ë³µì‚¬:**

```bash
cluster_scp ~/.bashrc
# ë˜ëŠ” ê° ë…¸ë“œì—ì„œ: source .bashrc
```

#### 6. Hadoop ì„¤ì¹˜ (bigpie1)

```bash
# Hadoop ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.1/hadoop-3.4.1.tar.gz
sudo tar -zxvf hadoop-3.4.1.tar.gz -C /opt/
sudo mv /opt/hadoop-3.4.1 /opt/hadoop
sudo chown bigdata:bigdata -R /opt/hadoop
```

#### 7. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (bigpie1)

`~/.bashrc`ì— ì¶”ê°€:

```bash
export PDSH_RCMD_TYPE=ssh
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

**ì ìš©:**

```bash
source .bashrc
hadoop version
```

#### 8. JAVA_HOME ì„¤ì • (bigpie1)

`/opt/hadoop/etc/hadoop/hadoop-env.sh` í¸ì§‘:

```bash
export JAVA_HOME=/usr/lib/jvm/bellsoft-java8-aarch64
```

#### 9. Hadoop íŒŒì¼ ë° ì„¤ì • ë³µì‚¬

```bash
# ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
cluster_run sudo mkdir -p /opt/hadoop_tmp/hdfs
cluster_run sudo chown bigdata:bigdata -R /opt/hadoop_tmp
cluster_run sudo mkdir -p /opt/hadoop
cluster_run sudo chown bigdata:bigdata -R /opt/hadoop

# Hadoop íŒŒì¼ ë³µì‚¬
for x in $(others); do rsync -avxP $HADOOP_HOME $x:/opt; done

# .bashrc ë³µì‚¬
cluster_scp ~/.bashrc
```

#### 10. í´ëŸ¬ìŠ¤í„° ì¬ë¶€íŒ…

```bash
cluster_reboot
```

#### 11. ëª¨ë“  ë…¸ë“œì—ì„œ Hadoop ë²„ì „ í™•ì¸

```bash
# bigpie2 ~ bigpie4ì—ì„œ
hadoop version
```

#### 12. ì„¤ì • íŒŒì¼ í¸ì§‘ (bigpie1)

##### core-site.xml

```xml
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://bigpie1:9000</value>
    </property>
</configuration>
```

##### hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_tmp/hdfs/datanode</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop_tmp/hdfs/namenode</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
```

##### mapred-site.xml

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>bigpie1:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>bigpie1:19888</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.resource.mb</name>
        <value>256</value>
    </property>
    <property>
        <name>mapreduce.map.memory.mb</name>
        <value>256</value>
    </property>
    <property>
        <name>mapreduce.reduce.memory.mb</name>
        <value>256</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>
```

**âš ï¸ ì°¸ê³ **: "Java heap space" ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ í¬ê¸° ì¦ê°€ (256 â†’ 384 â†’ 512)

##### yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.acl.enable</name>
        <value>0</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>bigpie1</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>256</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
</configuration>
```

#### 13. ì„¤ì • íŒŒì¼ ë³µì‚¬ (bigpie1)

```bash
cluster_scp /opt/hadoop/etc/hadoop/core-site.xml
cluster_scp /opt/hadoop/etc/hadoop/hdfs-site.xml
cluster_scp /opt/hadoop/etc/hadoop/mapred-site.xml
cluster_scp /opt/hadoop/etc/hadoop/yarn-site.xml
```

#### 14. Master ë° Workers íŒŒì¼ ìƒì„± (bigpie1)

**master íŒŒì¼** (SecondaryNameNodeìš©):

```bash
nano /opt/hadoop/etc/hadoop/master
```

ë‚´ìš©:

```
bigpie1
```

**workers íŒŒì¼** (DataNodeìš©):

```bash
nano /opt/hadoop/etc/hadoop/workers
```

ë‚´ìš©:

```
bigpie2
bigpie3
bigpie4
```

#### 15. NameNode ì´ˆê¸°í™” ë° ì‹œì‘ (bigpie1)

```bash
# ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
hdfs namenode -format -force

# ëª¨ë“  ë°ëª¬ ì‹œì‘
start-dfs.sh && start-yarn.sh
```

#### 16. ë°ëª¬ í™•ì¸ ë° HDFS í…ŒìŠ¤íŠ¸

**bigpie1ì—ì„œ:**

```bash
jps
```

ì˜ˆìƒ ì¶œë ¥:

```
3728 ResourceManager
3376 NameNode
4884 Jps
3525 SecondaryNameNode
```

**bigpie2 ~ bigpie4ì—ì„œ:**

```bash
jps
```

ì˜ˆìƒ ì¶œë ¥:

```
966 DataNode
1051 NodeManager
1197 Jps
```

**HDFS í…ŒìŠ¤íŠ¸:**

```bash
# íŒŒì¼ ë³µì‚¬
hdfs dfs -put /opt/hadoop/*.txt /
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Java heap space ì˜¤ë¥˜

- `mapred-site.xml`ì—ì„œ ë©”ëª¨ë¦¬ í¬ê¸° ì¦ê°€:
  - `yarn.app.mapreduce.am.resource.mb`: 256 â†’ 384 â†’ 512
  - `mapreduce.map.memory.mb`: 256 â†’ 384 â†’ 512
  - `mapreduce.reduce.memory.mb`: 256 â†’ 384 â†’ 512

### SSH ì—°ê²° ë¬¸ì œ

- `~/.ssh/authorized_keys` ê¶Œí•œ í™•ì¸: `chmod 0600 ~/.ssh/authorized_keys`
- SSH ì„¤ì • í™•ì¸: `ssh -v localhost`

### ë°ëª¬ì´ ì‹œì‘ë˜ì§€ ì•ŠìŒ

- ë¡œê·¸ í™•ì¸: `$HADOOP_HOME/logs/`
- JAVA_HOME ì„¤ì • í™•ì¸
- í¬íŠ¸ ì¶©ëŒ í™•ì¸: `netstat -tulpn | grep 9000`

---

## ì°¸ê³  ìë£Œ

- Apache Hadoop ê³µì‹ ë¬¸ì„œ: https://hadoop.apache.org/docs/current/
- Hadoop ì„¤ì • ê°€ì´ë“œ: https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html
