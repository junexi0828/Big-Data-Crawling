#!/usr/bin/env python3
"""
Scrapy ìŠ¤íŒŒì´ë” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import subprocess
import sys
import os
from datetime import datetime


def run_spider(output_format="json", filename=None):
    """ìŠ¤íŒŒì´ë”ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""

    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"quotes_{timestamp}.{output_format}"

    print(f"ğŸ•·ï¸  Scrapy ìŠ¤íŒŒì´ë” ì‹¤í–‰ ì¤‘...")
    print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼: {filename}")
    print(f"ğŸ“Š ì¶œë ¥ í˜•ì‹: {output_format.upper()}")

    # Scrapy ëª…ë ¹ì–´ ì‹¤í–‰
    cmd = ["scrapy", "crawl", "mybot", "-o", filename]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            print("âœ… ìŠ¤íŒŒì´ë” ì‹¤í–‰ ì™„ë£Œ!")
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {filename}")

            # íŒŒì¼ í¬ê¸° í™•ì¸
            if os.path.exists(filename):
                size = os.path.getsize(filename)
                print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {size} bytes")
        else:
            print("âŒ ìŠ¤íŒŒì´ë” ì‹¤í–‰ ì‹¤íŒ¨:")
            print(result.stderr)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    format_arg = sys.argv[1] if len(sys.argv) > 1 else "json"
    filename_arg = sys.argv[2] if len(sys.argv) > 2 else None

    # ì§€ì›ë˜ëŠ” í˜•ì‹ í™•ì¸
    supported_formats = ["json", "csv", "xml", "jl"]

    if format_arg not in supported_formats:
        print(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹: {format_arg}")
        print(f"âœ… ì§€ì›ë˜ëŠ” í˜•ì‹: {', '.join(supported_formats)}")
        sys.exit(1)

    run_spider(format_arg, filename_arg)
